{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\nSecond example: :class:`GridSearchCV` demonstration\n----------------------------------------------------\n\nThis example shows how to use :class:`GridSearchCv` with **PipeGraph** to effectively fit the best model across a number of hyperparameters.\nIt is equivalent to use :class:`GridSearchCv` with :class:`Pipeline`. More complicated cases are shown in the following examples. In this second example we wanted to show how to fit a :class:`GridSearchCV` in a yet simple scenario.\n\nSteps of the **PipeGraph**:\n\n- **scaler**: a preprocessing step using a :class:`MinMaxScaler` object\n- **polynomial_features**: a transformer step\n- **linear_model**: the :class:`LinearRegression` object we want to fit and use for predict.\n\n.. figure:: https://raw.githubusercontent.com/mcasl/PipeGraph/master/examples/images/Diapositiva2.png\n\n    Figure 1. PipeGraph diagram showing the steps and their connections\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Firstly, we import the necessary libraries and create some artificial data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import GridSearchCV\nfrom pipegraph.base import PipeGraphRegressor\n\nimport matplotlib.pyplot as plt\n\nX = 2*np.random.rand(100,1)-1\ny = 40 * X**5 + 3*X*2 +  3*X + 3*np.random.randn(100,1)\n\nscaler = MinMaxScaler()\npolynomial_features = PolynomialFeatures()\nlinear_model = LinearRegression()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Secondly, we define the steps and a ``param_grid`` dictionary as specified by :class:`GridSearchCV`.\nIn this case we just want to explore a few possibilities varying the degree of the polynomials and whether to use or not an intercept at the linear model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "steps = [('scaler', scaler),\n         ('polynomial_features', polynomial_features),\n         ('linear_model', linear_model)]\n\nparam_grid = {'polynomial_features__degree': range(1, 11),\n              'linear_model__fit_intercept': [True, False]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we use ``PipeGraphRegressor`` as estimator for :class:`GridSearchCV` and perform the ``fit`` and ``predict`` operations.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pgraph = PipeGraphRegressor(steps=steps)\ngrid_search_regressor = GridSearchCV(estimator=pgraph, param_grid=param_grid, refit=True)\ngrid_search_regressor.fit(X, y)\ny_pred = grid_search_regressor.predict(X)\n\nplt.scatter(X, y)\nplt.scatter(X, y_pred)\nplt.show()\n\n\ncoef = grid_search_regressor.best_estimator_.get_params()['linear_model'].coef_\ndegree = grid_search_regressor.best_estimator_.get_params()['polynomial_features'].degree\n\nprint('Information about the parameters of the best estimator: \\n degree: {} \\n coefficients: {} '.format(degree, coef))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This example showed how to use :class:`GridSearchCV` with :class:`PipeGraphRegressor` in a simple linear workflow.\n`Next example <example3>` provides detail on how to proceed with a non linear case.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}