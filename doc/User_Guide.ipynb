{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pipegraph User Guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rationale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[scikit-learn](http://scikit-learn.org/stable/) provides a useful set of data preprocessors and machine learning models. The `Pipeline` object can effectively encapsulate a chain of transformers followed by final model. Other functions, like `GridSearchCV` can effectively use `Pipeline` objects to find the set of parameters that provide the best estimator.\n",
    "\n",
    "#### Pipeline + GridSearchCV: an awesome combination\n",
    "Let's consider a simple example to illustrate the advantages of using `Pipeline` and `GridSearchCV`.\n",
    "\n",
    "First let's import the libraries we will use and then let's build some artificial data set following a simple polynomial rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = 2*np.random.rand(100,1)-1\n",
    "y = 40 * X**5 + 3*X*2 +  3*X + 3*np.random.randn(100,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have some data ready, we instantiate the transformers and a regressor we want to fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "polynomial_features = PolynomialFeatures()\n",
    "linear_model = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the steps that form the Pipeline object and then we instantiate such a Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [('scaler', scaler),\n",
    "         ('polynomial_features', polynomial_features),\n",
    "         ('linear_model', linear_model)]\n",
    "\n",
    "pipe = Pipeline(steps=steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can pass this pipeline to `GridSearchCV`. When the `GridSearchCV` object is fitted, the search for the best combination for hyperparameters is performed according to the values provided in the `param_grid` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'polynomial_features__degree': range(1, 11),\n",
    "              'linear_model__fit_intercept': [True, False]}\n",
    "\n",
    "grid_search_regressor = GridSearchCV(estimator=pipe, param_grid=param_grid, refit=True)\n",
    "grid_search_regressor.fit(X, y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can check the results of fitting the Pipeline and the values of the hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3X98XHWd7/HXJ5MfpFabQlFo2i7I\nst0rP9ZK4fpYu6tSa0Gkjai1y7LgD25RvKCihXbxYtt7va10FxBcd+2trKIrEBFK+PUopQjXchel\npZAqWimwa5ugUCBFaGgmmc/9Y84kk8mZnzkzmWTez8ejJPM9Z858chI+853P+Z7v19wdERGZ+OrG\nOgAREakMJXwRkRqhhC8iUiOU8EVEaoQSvohIjVDCFxGpEUr4IiI1QglfRKRGKOGLiNSI+rEOIN20\nadP8mGOOGeswRETGlR07dux39yPz7VdVCf+YY45h+/btYx2GiMi4Ymb/Wch+KumIiNQIJXwRkRqh\nhC8iUiOU8EVEaoQSvohIjVDCFxGpEUr4IiI1oqrG4YuI1IKvbtrFzT/fy4A7MTP+5r/O5H+1nVT2\n11XCFxGpoK9u2sXx21exu/FBYiQYoI5/2346X2VV2ZO+SjoiIhX0Z9tXc37sAeotgRnUW4LzYw/w\nZ9tXl/21lfBFRCro3NhWzIa3mSXby00JX0SkgmIkimqPkhK+iEgFJSw87WZrj5ISvohIBcXmfgrP\naPOgvdw0SkdEpJI+fA0GsON74ANgMeyUT8KHryn7Syvhi4hU2oevqUiCzxRZScfMYma208zuDh4f\na2Y/N7OnzexWM2uM6rVERKR4UdbwvwD8Ou3xN4Br3f144BXgMxG+loiIFCmShG9mM4CzgI3BYwNO\nB24Ldvk+0BbFa4mISGmi6uFfB1wOgwNJjwB63L0/eLwPaI3otUREpASjTvhm9mHgBXffkd4csmvm\nSKTU85eZ2XYz2/7iiy+ONhwREckiih7+e4BFZvYfwC0kSznXAS1mlhoFNAPoDnuyu29w97nuPvfI\nI4+MIBwREQkz6oTv7ivdfYa7HwMsBR50978Ffgp8LNjtAuDO0b6WiIiUrpx32l4BXGZme0jW9L9b\nxtcSEZE8Ir3xyt0fAh4Kvn8WOC3K44uISOk0l46ISNQ62+HaE2FVS/JrZ/tYRwRoagURkchs2tnF\nE/ds4O/j36LRglHpB/YycMfFxABOXjKW4amHLyIShU07u1h5+y4ujW8cSvaBmMc5dNfyMYpsiBK+\niEgE1m/ezYKBh5nKa6HbG+M9FY5oJCV8EZEIzH11C//QsGHE8oWDQm89rSwlfBGRCKxu/MGIUk66\nA/bmCkYTTglfRCQCU/hj1m2HPMb9s75UwWjCKeGLiEQgayXHYXn8Ir75wpyKxhNGCV9EJAKHGqaE\ntr/sk+lIzKO7p7fCEY2kcfgiIiXYtLOL9Zt3093Ty/SWZv46fgGr/J9osoHBfQ55jNX95wMwvaV5\nrEIdpIQvIlKk1Jj73ngyuXf19HIz7+b1un4ur29nur1Etx/B1f1L6EjMo7khxvKFs8c4aiV8EZGi\nrd+8ezDZp+tIzKOjb96wtpgZa885ibY5Y78GlBK+iEgB0ks4hQ6pb26IVU2yByV8EZG8Mks42bQ0\nN/CmpvrBuv7yhbOrJtmDEr6ISF5hJZxFdduCev1+un0a17GUeYsurqoEn0kJX0Qkj8whlYvqtrGu\nYSOTrA+AGbafdbGN1Mf+AhjbGTFz0Th8EZE8ModUXl7fPpjsU+oH3oCtayoZVtGU8EVE8li+cDbN\nDbHBx9Ntf/iOB/ZVKKLSKOGLiOTRNqeVteecRGtLMwa8YEeG7zhlRkXjKpZq+CIiBWib0zp0Qbbz\ndbjrUoin1fYbmmH+VWMTXIGU8EVECtHZnqzRH9iX7Mn/xbnw9P1Dj+dfNeZLGOajhC8ikk9n+/Ae\n/YG98OSP4Ozrqz7Jp1MNX0Qkn61rhpdvIPm4ykflZFLCFxHJJ9vomyoflZNJCV9EJJvOdrj2RLIu\nSFvlo3IyqYYvIhIms26faRyMysmkHr6ISJiwun3KlJnj7oItqIcvIjJSZ3tyJE4ogy/9sqLhREUJ\nX0Qk3d2XwfYbs28fZ3X7dCrpiIikdLYHyT78Im2vN/LYcZdUNqYIKeGLiKRsXUO2ZO8OV8Qv5ItP\nHV/ZmCKkko6ISMAP7MOybOvyaXQk5mE9WS7kjgPq4YuIBP7AtND2hMPV/ckROZlz448nSvgiIoG1\nfR/noDcOa0s4/GDgA3Qk5tHcEGP5wtljFN3ojbqkY2YzgZuAo4AEsMHdv2lmhwO3AscA/wEscfdX\nRvt6IiJR2LSzi/Wbdw9bcHz7Wxaw4lWCtWpfotuP4Or+JXQk5tFahYuSF8vcs9wyXOgBzI4Gjnb3\nx83szcAOoA34JPCyu68zsxXAVHe/Itex5s6d69u3bx9VPCIi+Wza2cXK23cNW5i8uSHGR09p5Sc7\nuka0rz3npKpO9Ga2w93n5ttv1D18d38eeD74/o9m9mugFVgMvC/Y7fvAQ0DOhC8iErWwnvz6zbtZ\nMPAwlze2M9320+3TuLp/CT/9zQLWnnPSiP2rOdkXI9JROmZ2DDAH+DnwtuDNAHd/3szemuU5y4Bl\nALNmzYoyHBGpcZk9+a6eXlbevosFAw+zrmHj4ELkM2w/6xo2svJVaJtzOsBg0l+/eTfAhEj6oy7p\nDB7IbDLwMPB1d7/dzHrcvSVt+yvuPjXXMVTSEZHRyOzNH+zr55WD8RH7PdJ0Ka0hC5H/niN5dPHD\noeWeai7rFFrSiWSUjpk1AD8B/s3dbw+a/xDU91N1/heieC0RkTCp3nxXTy9OsjefnuwX1W1jW+Ol\nPNt0LtMZmewB3sZ+1m/ePSzZA/TGBwZ7+uPZqBO+mRnwXeDX7n5N2qYO4ILg+wuAO0f7WiIi2YQl\n6pRFddtY17CRGXX7qTOwLHdX2ZQZdGe5sSpb+3gSRQ//PcDfAaeb2RPBvw8B64AFZvY0sCB4LCJS\nFrkS8uX17YP1+qyC+e2z3Vg1nm+4SolilM42yHo38vzRHl9EpBDTW5rpCkn6i+u20VoXXsJJsuQM\nmPOvgpOXsHwgfMjmeL7hKkVz6YjIhLB84ewRiXpR3TbWNmzM2iNlyswRc9unLsxOxKGZSvgiMiGk\nEvKX259kIBh9mKuU0x87jPosSxS2zWmdEAk+kxK+iIx7X920i5t/vncw0S+q28bl9e2hQy8hOdXx\niviFzBt4D22VDHSMKeGLyLj21U27+OGjvwNgdf2NnBfbSh2edSQOJKc6vq3vL/n3zbsnZE8+GyV8\nERnXbv55cu3Z1fU3cn7sgZyJHuCgNw5OdTwRhloWQwlfRMa1AfeCkr17smefmv0SJsZQy2Io4YvI\nuLam/l/5uwJ69t1MY17f9YOPJ8pQy2JoARQRGdf+tn5r3mRPQzPdp1xOa0szBrS2NFf13Djloh6+\niIwL6ROj/UPzTXyE+6nzBLEcz3GH/lgzDWdfz6knL+GRRRULtyop4YtI1Uuf5nh1/Y2ck8hfwnHg\n2WOWctynvlORGMcDJXwRqXrpC5a02v78JRzA5n6G4z58Tf4da4gSvohUvbmvbmFt2oIlYZxgUi+L\nwSmfBCX7EZTwRaQiwpYazHvRtLMdtq7husa92efDCQx4HfWrX4ks3olIo3REpOzCFidZefsuNu3s\nyv6kzna461I4kD/Zu8OddR+MMuQJST18ESm7bKtIfbn9yWH7DOv9P7QG4rnvhHWHAeq4OTGfN7ep\nhJOPEr6IhCqpBJNFtikMBtz54q1PsKhuG7fWtzO9aT/dB6dx3R1LWVy3L2fP/qA3siJ+IR2JeTTE\njPUlRVZbVNIRkRFKKsHkkGsKg8zlB2fU7WeNbeAAk0P3d2BfYtpgsgeID/iEWHO23JTwRWSEqBfy\nXr5wNs0Nw2+RSi0q/s2Gb48YfTPJ+hhIeHLZwXQNzXyx72Lm9V0/mOxTam0itFKopCNSpChLHdUq\n6oW82+a00rr3bqbvuJqj2Y9jeacwnlr3Opy9AbaugQP7Bpch3H7vNAiJo9YmQiuFEr5IEdLv+ISh\nUgcwoZJ+tvVhS06qd1/GqY/fCOZBg+fcHeCN5qOYdPISOHnJsPaJvOZsuamkI1KEqEsd1SqsBFNy\nUu1sh+03UkiST+mPHcakM9eEbmub08rac06q+YnQSqEevkgRspU0unp62bSza8IknVIX8n6s4zvM\nfHw9b/UXecGOZO+7lnPqMzdQTLJnyszkWrMZPfvM+CbKua4kJXyRImQrdQATrrRTcFIN7ob1A3s5\nxaHOAIOjeJEpO76KW1/eG6eA5AXas6/PmehldJTwRYqwfOHsEfXjlFRpp1wJvxwXiws5ZuY+173j\n6WSv/cA+aJ4Kfa/BQDKpZ16EbbY++r2OekvkDqT5cDjzG0r2ZaaEL1KkwxrqQhM+lG9oYDkuFhdy\nzE07u3j9ji/wsG0l1pQg0Wv4DoYuvva+nPd16khw0BuHDb304OnWMhPylG8kOkr4IgXKTJBhyjU0\nMNfF4lITfuYxF9Vt43JrZ/qdL8H9U2HgEIv7Xgcb6rnHiqnFB55nGt+IL+Hy+nam20t0+xFc3b+E\nHW9ZwCNfOj3nc2thCGwlKeHLmBsv/1OHJd105RwaGPW4eEhOOdzReBOH22uDbYMlmaDnboP/KU2v\nN/LIn1zMludOoKNv6Eap5oYYa/Ocq1oZAltJSvgypsbT/9S5kmtrhG9UYW+AkY+L72xnfeN3aCT7\nG1ipEsGHgBfsSPaespwliy6isYQ39XJ8qql1Svgypsbif+pSP1FkS7qtLc08siJ3aaKY2MLeAD96\nSis/2dGV9Wajon+mrWsiS/aHPMbrNNPC68PLNStO56hgn1KGUZbjU02tU8KXMVXp/6lH84kibIRO\nsWWcfIk52xvgT3/zImvPOSn0uZt2drHtjm9zK7cMm20SLs7+Mx3YV3DMmdzhdZqYRN9ggk+f16aQ\nck0hIv9UI0r4MrYq+T/1pp1dfLn9SQZ8+IXHQj9RFHIzUq6EXsibTWZd/RUmsyp+PvYqtN13Hm19\nr8NhwBsGXZ+GOdfwxD0bWGMbBkfBzLD9rPENXH1PPW1zVof+LAebj2JS7/PFnD7cIYHxw4H5rBn4\nDAl3prc08/4/P5LW37wY+TWYKN5gZTglfAlV7gupqeN39fRiDL8Pc1Slihyvt/L2XSOSfUrYJ4ps\nr53t9fMl9PSFuKfbfrp9Glf3L2H95sbkMUPq6ofzGtc0/HPyYmpfeuwO278LwIV9dzKpbuRskxf2\n/RAIT/hXxz/BSr+BJhv+aWJwXdjmw2HgEH7odQBe9sms7j9/sCdvOM+tOyv02FEp9W5fyU4JX0Yo\n94XUzOOnkowz/OJnlHHkG2GT+YmilNd+4p4NbLONHN6U7J0nghkh2QS+CbYBNAyNhJlh+1nXsJGV\nrwKcnrWuXm85hkLu+B7T68Jvappe91LWp33/tdN4ue4ivlY/8tPEXYl5TD+smeVnzh58Ux5x7AqV\nVTSFQrTKnvDN7Azgm0AM2Oju68r9mjI65b6QGnb8VLJPv/gZZRy5rgmMKBN0tvPeOy/jqbo/QlOy\nKVXKeOKeE2m7/6a0G46Ct6rmw7ky/goNdUPJuZAx65Osj5WNPwbWllZX9wHeaD46tDzzRvNRTMry\ntOktzXT0zBs2VDJdV08vX7r1iWFvxikqq4xfZU34ZhYD/glYAOwDHjOzDnd/qpyvK6NT7guphR4/\nyjgumPwLvhL/F97EG4NtTvKmoO5TLufUOWckGzvbGbjjYqYSHzb+PIZzfuwBEvGt0J9RWgHofZmG\nEserv439QGl1dSzGpDPX0H/nJdQPDP1suWabhNxTRKSkT2Qc9glMxp9yT498GrDH3Z919z7gFmBx\nmV9TRinbx/WoPsYXevwpzQ2h+w1r72yHa0+EVVNg9eHJr9eemGxP2+eqgRuYbG9gwV2jZslJvlpt\nP6fu+trQ/lvXEPN46OuaQSxXeaVENmUGkKyrH/LYiO39bgz4yHcTd3hm1sfh5CXUL74BpswELDnb\n5OIb8s42mT7FcD7pn8CU7Mevcif8VmBv2uN9QZtUsUjnQh/F8c/0n/HLpk/zXNO5PNd0Ls80ncvq\n+huTNfDOdvjGsfjt/w0OBH9iHvRWD+yFuy4dlsTrPMeY83hvclUlGNVwxZI0NCfnkiFZV18ev4iX\nEpNxTyb0l30yl8U/x5fin+M1P2ywfcDhpoEPcP4fPpE8zslL4Eu/hFU9ya8FzE3TNqeVR1acznPr\nzqK1gDdzjX8f/8pdww/rPAzrIpnZMmAZwKxZs8oczsQUxUiWzGN89JRWflqGoXYwfPTF3Fe3sLrx\nB0zhj9idwP3BrInA//RvDZtlMQacH3uAY+PPw13PQrw3e+80lcRPXlJYEk/tM2XG0BtImXhQI7Ep\nwycOy1ZXb2luoKc3TsehkfV2iygJF1Li0fj38a/cCX8fMDPt8QygO30Hd98AbACYO3du9J+XJ7hi\nR5OEvTkAI47xkx1dZV1FqC32CG12BTRmzLbY+zJsuhia3hw6pa4Z/FXsVxBedRmumCQelFWYfxUD\nd1wcWtZJjUPPVtbp83oOeYzJdghIG6WT5hAxLo9fFDpxWLZx56sWncCqjl/R0zsypqiScPqbcL6h\nsjJ+lTvhPwYcb2bHAl3AUuDcMr9mTSlmJEu2N4em+pHT/ZZ1eoPO9mTJJZ6ld5qIFzTtbj4HU6NU\n5l8Fmz4LiSy917SyCicvIQa8cvtltPgfh0IKRuk8d9iJrGoIGaUzZSZPHncJX3zq+ME304N9/bxy\nMMv1gJCeeb5x5+W+CSl9COR4mdBOilPWhO/u/Wb234HNJD+R3+juvyrna9aaYkayZHtzGPXc7p3t\ncN8VQ0kw32IWW9dkT/YFKOQi40Fv5Or4J1gFQ3Hc/UXoe334jhllFYL9Hx54T2iCXXvWSZDl7tVT\ngUcWDT0+dsU9WePL1jPPNu680jchafz7xFT2cfjufi9wb7lfp1YVMzVBsRfdCioXdLbDnZ+HgbQ7\nPVNlGQhP+gXU1A81tBDre3VEWceBF454N2/Z/zjNGQtqJEiOQugK7mC969BpyYSfiqPARTZSvdve\n+AAxMwbcSxqOOCWovYcppWeuJCyjVe5ROlJmxYyoyZbAp05qGHaMRXXbeLzpIra98ZHkMMdvHDt8\nmGO6rWuGJ/uURHxo5EumVL08m7oG1vonuSz+2REjU263Mzjn9Su4In4h+xLTSLixLzGNL8Qv5rhD\nP+LYQz9iXt/1dCTmlVTfTpW9Um+iA+6D57PYZJu53F/KmxpjStwyJjS1wjhXzEf9bBcFv3b2CbTu\nvZuZj6/nbf5icgRJ+hNz9dhz9dazbZt/VfYaflAO+v6P3oTDiJEpBtDbSxfZ7xJN/Vyl9KKjvLu3\nJ0v9/mBf9HPQixRCCX8CKPSjftibw3XveJpT7/67oV56tgJ5qseemfBzjIA5mO3W/tQxtq5JvilM\nmTGijj793gdzlqrCtsXMBmdwDJvFcvVdvxq8iNrS3MCqRSeMOG9R3t2r6X2l2ijh15i22CO0Na2B\nw/aBTYXHX4FC1ykN6bE/dtwl/MWOv6fR+oe1H/LY0EXTMHlq6vmmxg29oJplGOmmnV0sv+1J4gND\nP2dPb5zlP34SGD58Ncokrel9pdqohl9LUsMhD+wFPBhVU8StDyG19y8+dTxfiS/jZR+6O/SlxGSW\nxy/i+6+dVnKombf+t7Y0Dyb0XNvCrN+8e1iyT4knnPWbdw9ri/Iu42LjFCk39fBrySiGQx7yGE2p\nseppunuCenrIXaCF3K6fS65SVTEjVnKVYzK3RT38USNrpJoo4deSIuaJSV8n5GWfzA2NF7IqpAST\nrQRilDb0sByyxZjalklJWiYqlXQmksGZI1tGzhgJ+YdDBtzhZ4kTODY1zNG/yzvPWha6b1gJxIC/\nffesqkmayxfOpiE28mp0Q51VzZuSSCWohz8O5L3NPfNOVxiaMRKGLo6GDIfstwb6E04TyYuuCeBH\niQVc07AMi8fzljTGwzJ0qVgKGaUjMpGZZ1njcyzMnTvXt2/fPtZhVJXM+W9g+IiUZ/71Io79z1uy\nf1SbMjM5XW5KZ/vgcMiDzUex8sBHuDMRXn9PX32qXDRni8jomdkOd5+bbz/18KtcthuBnrhnA2fe\n+z3e3teT9Y5OAD+wb/jQ+rThkAvWPUhXoryrW+VS7rVzRWQ41fCrXGbiXVS3jR2Ny/ha/Dqa4rmT\nPcAfmFbwsdNlW20qSrnuahWR6CnhV7n0USSL6raxrmEjR9S9ljfRQ3LGyLV9Hy/o2JkKOf5olXvt\nXBEZTgm/yi1fOJuPNf4/tjVeyjcbvs0kC5moLEPq5qcV8QvZ/pYFOY+dTbZ5YKJU7rVzRWQ4Jfwq\n1xZ7hHUNG5lRt7+gXnciWOv0lL4NbIm9N2dSb5vTSkuW0k0lkm65184VkeGU8Kvd1jXUD7yRdzd3\neIXJXGmXsqr/0wXfxr9q0QljlnQ19YBIZWlYZrVb1UKu+W4csHwrTOWhoZEi45uGZU4UWaYfdk+u\n7HQdS5n3wYtpO7n0BK2pBERqg0o61W7+VclFttMc9Ea+EL+YeX3Xc1vfX2oYo4gURD38Csssn3zh\nrTv569/9M2/1F3nBjmTvu5Zz6qKLhp6QtlhIomcf3X4EV/cvoSPt7lgNYxSRQijhV1DmnaWnvLqF\nxb3fockGwOAoXmTqjpU8BiOT/slL+Kt1uVeBEhHJRSWdCsq8s/Rr9Tclk32aJhvgTx8PX/xbwxhF\nZDTUwy+DbKNeMksvh9troc9v8fD28TAzpYhUL/XwI5Yq23T19OIMTQi2aWcX01uaWVS3jW2Nl/Js\n07klHb9tTiuPrDidaz/xTgC+dOsTvGfdg2za2RXhTyEiE5F6+BHLNSHYde94mhN3bKQ5z/QIPfZm\npubYrlkmRaQU6uFHLNeEYKc+c0PeZN/n9ex51//IuY9mmRSRUijhRyznhGBZ1pR1IOHG7zmSJ0/5\n38NH6ITQLJMiUgol/IjlHEmTZU1ZmzKTutU9HLVqT95kD5plUkRKo4QfsZwTgoXcNUtDc7K9CBqe\nKSKl0EXbMsg6N03aXbMc2Jfs8c+/quhJzzQ8U0RKodkyyyFtofBSk7qISKE0W+ZY6WyHuy6FeHAB\n9cDe5GNQ0heRMaUaftS2rhlK9inx3mS7iMgYGlXCN7P1ZvYbM+s0szvMrCVt20oz22Nmu81s4ehD\nHSeyDL3M2i4iUiGj7eFvAU5095OB3wIrAczsHcBS4ATgDODbZhbLepSJJMvQy6ztIiIVMqqE7+73\nu3t/8PBRIJXVFgO3uPshd38O2AOcNprXGjciGnopIhK1KGv4nwbuC75vBdLX5dsXtE18Jy+Bs6+H\nKTMBS349+3pdsBWRMZd3lI6ZPQAcFbLpSne/M9jnSqAf+LfU00L2Dx3/aWbLgGUAs2bNKiDkKpJt\n+GXqn4hIFcmb8N39A7m2m9kFwIeB+T40qH8fMDNttxlAd5bjbwA2QHIcfgExV4fOdvrvvIT6gTeS\njw/sTT4GJXsRqUqjHaVzBnAFsMjdD6Zt6gCWmlmTmR0LHA/8YjSvVW0O3nfVULIP1A+8wcH7VKsX\nkeo02huvvgU0AVvMDOBRd/+su//KzNqBp0iWej7v7gM5jjPuHNb7+6LaRUTG2qgSvrv/aY5tXwe+\nPprjV7PuxBHMqNsf3j4G8YiI5KM7bUu0sfE8DnrjsLaD3sjGxvPGKCIRkdyU8Ev0zrOWcZUvY19i\nGgk39iWmcZUv451nLRvr0EREQmnytBIlpyK+mE9snq8pikVkXFDCH4Ws896LiFQhlXRERGqEEr6I\nSI1QwhcRqRFK+CIiNUIJX0SkRijhZ9PZDteeCKtakl8728c6IhGRUdGwzDBaiFxEJiD18MNoIXIR\nmYCU8MNoIXIRmYCU8DN1toNlOS1aiFxExjEl/HSp2n3I1P293shjx10yBkGJiERDCT+lsx3u+OzI\n2j3Q73VcEb+QLz51/BgEJiISjZofpbNpZxdP3LOBy+PfZpKFL8pVh9ORmIf1jHwzEBEZL2o64W/a\n2cXK23exxX7IpLq+rPt1+xEATG9prlRoIiKRq+mSzvrNu+mNDzDdRi5VmHLQG7m6fwnNDTGWL5xd\nwehERKJV0wm/OyjRdPu00O39XseK+IXc43/F2nNO0tz3IjKu1XRJZ3pLM6e8uoVJ9gbuYDa07aA3\nsiJ+IVti7+UflexFZAKo6YR/3Tue5sQdG2m2ofq9O7zsk1ndfz4/O+z9rD37BCV7EZkQarqkc+oz\nNwxL9pDs5fdyGB2JeUxqrFeyF5EJo6YTfrapEqbbS8BQjV9EZCKozYSfmvoYD92sYZgiMhHVXg2/\ns53+Oy+hfuCN0M0ahikiE1XNJfyD913FpJBk78AfOJK18Y+z4y0LWLtwtur3IjKh1EzC37Szi/Wb\nd/Oz3ufBRm53jKNW7eGblQ9NRKQiaqKGn5pCoaunN+tNVt2JIyoclYhIZdVEwk9NoQBwdf8SDnrj\nsO0HvZGNjeeNRWgiIhVTEyWd9OGVHYl5EIfL69uZbi/R7UdwHUuZd9ayMYxQRKT8aiLhT29ppisj\n6Xf0zQOgtaWZ5bpAKyI1oCYS/vKFs3n9ji/wCdtKjAQD1HGrz+dNH/mmEr2I1IyaSPhtXf+I120Z\nHJxTT4JzbQvW9Y8w55oxjU1EpFIiuWhrZl8xMzezacFjM7PrzWyPmXWa2buieJ2S7fjeiJGYFrSL\niNSKUSd8M5sJLAB+l9Z8JnB88G8Z8M+jfZ1RCVmUPGe7iMgEFEUP/1rgcoZPTLMYuMmTHgVazOzo\nCF6rNBYrrl1EZAIaVcI3s0VAl7s/mbGpFdib9nhf0DY2TvnkiGnSPGgXEakVeS/amtkDwFEhm64E\n/h74YNjTQtpCp6Y0s2Ukyz7MmjUrXzgl2dT6ZV7/xe9GjtJp/TJtZXlFEZHqY+7hUwTnfaLZScBW\n4GDQNAPoBk4DVgMPufvNwb67gfe5+/O5jjl37lzfvn17SfHk8p51Dw4bh5/S2tLMIytOj/z1REQq\nycx2uPvcfPuVXNJx913u/ladR6y+AAAHxklEQVR3P8bdjyFZtnmXu/8e6ADOD0brvBs4kC/Zl1O2\nhUy0wImI1JJyjcO/F/gQsIfkJ4BPlel1CpJ5p216u4hIrYhs8rSgp78/+N7d/fPufpy7n+Tu0ddp\nirB84WyaG4aPyNECJyJSa2rjTttg+oT1m3fT3dPLdM2fIyI1qCYSPiSTvhK8iNSympgPX0REJlgP\nP7WMoco2IiIjTZiEn1rGMLWyVVdPLytv3wWgpC8iwgQq6azfvJsFAw+zrfFSnm06l22Nl7Jg4GHW\nb9491qGJiFSFCZPw5766hXUNG5lRt586gxl1+1nXsJG5r24Z69BERKrChEn4Kxt/zCTrG9Y2yfpY\n2fjjMYpIRKS6TJiE/zb2F9UuIlJrJkzCtykzimoXEak1EybhM/8qaMiYG6ehOdkuIiITKOGfvATO\nvh6mzAQs+fXs65PtIiIyccbhA8nkrgQvIhJq4vTwRUQkJyV8EZEaoYQvIlIjlPBFRGqEEr6ISI1Q\nwhcRqRFK+CIiNUIJX0SkRpi7j3UMg8zsReA/R3mYaVB1M6ZVY0yguIpRjTGB4ipGNcYE0cT1J+5+\nZL6dqirhR8HMtrv73LGOI101xgSKqxjVGBMormJUY0xQ2bhU0hERqRFK+CIiNWIiJvwNYx1AiGqM\nCRRXMaoxJlBcxajGmKCCcU24Gr6IiISbiD18EREJMS4Tvpl93Mx+ZWYJM8t6ddvMzjCz3Wa2x8xW\npLUfa2Y/N7OnzexWM2uMIKbDzWxLcMwtZjY1ZJ/3m9kTaf/eMLO2YNv3zOy5tG3vHG1MhcYV7DeQ\n9todae2Rn6tC4zKzd5rZvwe/604z+0TatsjOV7a/k7TtTcHPvic4F8ekbVsZtO82s4WlxlBCTJeZ\n2VPBedlqZn+Sti30d1mhuD5pZi+mvf6FadsuCH7fT5vZBRWO69q0mH5rZj1p28pyvszsRjN7wcx+\nmWW7mdn1QcydZvautG3lOVfuPu7+Af8FmA08BMzNsk8MeAZ4O9AIPAm8I9jWDiwNvv8X4HMRxHQ1\nsCL4fgXwjTz7Hw68DEwKHn8P+FgZzlVBcQGvZWmP/FwVGhfwZ8DxwffTgeeBlijPV66/k7R9Lgb+\nJfh+KXBr8P07gv2bgGOD48QqFNP70/52PpeKKdfvskJxfRL4Vpa/92eDr1OD76dWKq6M/S8BbqzA\n+fpr4F3AL7Ns/xBwH2DAu4Gfl/tcjcsevrv/2t1359ntNGCPuz/r7n3ALcBiMzPgdOC2YL/vA20R\nhLU4OFahx/wYcJ+7H4zgtXMpNq5BZTxXBcXl7r9196eD77uBF4C8N5cUKfTvJEestwHzg3OzGLjF\n3Q+5+3PAnuB4ZY/J3X+a9rfzKDAjgtcddVw5LAS2uPvL7v4KsAU4Y4zi+hvg5oheOyt3/78kO3XZ\nLAZu8qRHgRYzO5oynqtxmfAL1ArsTXu8L2g7Auhx9/6M9tF6m7s/DxB8fWue/Zcy8o/u68FHu2vN\nrCmCmIqJ6zAz225mj6bKTJTvXBUTFwBmdhrJ3tszac1RnK9sfyeh+wTn4gDJc1PIc8sVU7rPkOwp\npoT9LqNQaFwfDX4vt5nZzCKfW864CEpfxwIPpjWX63zlky3usp2rql3T1sweAI4K2XSlu99ZyCFC\n2jxH+6hiKuT5acc5GjgJ2JzWvBL4PcmktgG4AlhTwbhmuXu3mb0deNDMdgGvhuxX8LCuiM/XD4AL\n3D0RNJd8vjIPH9KW+TNG/reUR8HHNbPzgLnAe9OaR/wu3f2ZsOeXIa67gJvd/ZCZfZbkJ6PTC3xu\nOeNKWQrc5u4DaW3lOl/5VPrvqnoTvrt/YJSH2AfMTHs8A+gmOWdFi5nVB721VPuoYjKzP5jZ0e7+\nfJCgXshxqCXAHe4eTzv288G3h8zsX4GvFBJTVHEFJRPc/VkzewiYA/yEEs9VVHGZ2VuAe4CvBh97\nU8cu+XxlyPZ3ErbPPjOrB6aQ/KheyHPLFRNm9gGSb57vdfdDqfYsv8soEljeuNz9pbSH/wf4Rtpz\n35fx3IciiKmguNIsBT6f3lDG85VPtrjLdq4mcknnMeB4S44yaST5i+7w5FWRn5KsoQNcABTyiSGf\njuBYhRxzRA0xSHqpunkbEHplvxxxmdnUVEnEzKYB7wGeKuO5KjSuRuAOknXOH2dsi+p8hf6d5Ij1\nY8CDwbnpAJZachTPscDxwC9KjKOomMxsDvAdYJG7v5DWHvq7jCCmQuM6Ou3hIuDXwfebgQ8G8U0F\nPsjwT7hljSuIbTbJi6D/ntZWzvOVTwdwfjBa593AgaAjU75zVY6r0+X+B3yE5LvgIeAPwOagfTpw\nb9p+HwJ+S/Ld+sq09reT/B9zD/BjoCmCmI4AtgJPB18PD9rnAhvT9jsG6ALqMp7/ILCLZOL6ITA5\nonOVNy7gL4PXfjL4+plynqsi4joPiANPpP17Z9TnK+zvhGR5aFHw/WHBz74nOBdvT3vulcHzdgNn\nRvg3ni+mB4K//dR56cj3u6xQXGuBXwWv/1Pgz9Oe++ngHO4BPlXJuILHq4B1Gc8r2/ki2al7Pvgb\n3kfyWstngc8G2w34pyDmXaSNOCzXudKdtiIiNWIil3RERCSNEr6ISI1QwhcRqRFK+CIiNUIJX0Sk\nRijhi4jUCCV8EZEaoYQvIlIj/j86ByEdsFW47AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14e7ddb4e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = grid_search_regressor.predict(X)\n",
    "plt.scatter(X, y)\n",
    "plt.scatter(X, y_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information about the parameters of the best estimator: \n",
      " degree: 5 \n",
      " coefficients: [[    0.           367.70119171 -1268.80359517  2317.54328323\n",
      "  -2185.95097095   859.89592783]] \n"
     ]
    }
   ],
   "source": [
    "coef = grid_search_regressor.best_estimator_.get_params()['linear_model'].coef_\n",
    "degree = grid_search_regressor.best_estimator_.get_params()['polynomial_features'].degree\n",
    "\n",
    "print('Information about the parameters of the best estimator: \\n degree: {} \\n coefficients: {} '.format(degree, coef))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline weaknesses:\n",
    "From this example we can learn that `Pipeline` and `GridSearchCV` are very useful tools to consider when attempting to fit models. As far as the needs of the user can be satisfied by a set of transformers followed by a final model, this approach seems to be highly convenient. Additional advantages of such approach are the **parallel computation** and **memoization** capabilities of GridSearchCV.\n",
    "\n",
    "Unfortunately though, current implementation of scikit-learn's `Pipeline`:\n",
    "- Does not allow postprocessors after the final model\n",
    "- Does not allow extracting information about intermediate results\n",
    "- The X is transformed on every transformer but the following step can not have access to X variable values beyond the previous step\n",
    "- Only allows single path workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pipegraph goals:\n",
    "[pipegraph](https://github.com/mcasl/PipeGraph) was programmed in order to allow researchers and practitioners to:\n",
    "- Use multiple path workflows\n",
    "- Have access to every variable value produced by any step of the workflow\n",
    "- Use an arbitraty number of models and transformers in the way the user prefers\n",
    "- Express the model as a graph consisting of transformers, regressors, classifiers or custom blocks\n",
    "- Build new custom block in an easy way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of the library\n",
    "\n",
    "### Main interface: The PipeGraphRegressor and PipeGraphClassifier classes\n",
    "`pipegraph` provides the user two main classes: `PipeGraphRegressor` and `PipeGraphClassifier`. They both provide a familiar interface to the raw `PipeGraph` class that most users will not need to use. The `PipeGraph` class provides greater versatility allowing an arbitrary number of inputs and outputs and may be the base class for those users facing applications with such special needs. Most users, though, will be happy using just the former two classes provided as main interface to operate the library.\n",
    "\n",
    "As the names intend to imply, `PipeGraphRegressor` is the class to use for regression models and `PipeGraphClassifier` is intended for classification problems. Indeed, the only difference between these two classes is the default scoring function that has been chosen accordingly to scikit-learn defaults for each case. Apart from that, both classes share the same code. It must be noticed though, that any of these classes can comprise a plethora of different regressors or clasiffiers. It is the final step the one that will define whether we are defining a classification or regression problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From a single path workflow to a graph with multiple paths: Understanding connections\n",
    "Theses two classes provide an interface as similar to scikit-learn's `Pipeline` as possible in order to ease their use to those already familiar with scikit-learn. There is a slight but important difference that empowers these two classes: the `PipeGraph` related classes accept extra information about which input variables are needed by each step, thus allowing multiple path workflows. \n",
    "\n",
    "To clarify the usage of these connections, let's start using `pipegraph` with a simple example that could be otherwise perfectly expressed using a scikit-learn's `Pipeline` as well. In this simple case, the data is transformed using a `MinMaxScaler` transformer and the preprocessed data is fed to a `LinearRegression` model. Figure 1 shows the steps of this PipeGraphRegressor and the connections between them: which input variables each one accepts and their origin, that is, if they are provided by a previous step, like the output of `scaler`, named `predict`, that is used by `linear_model`'s `X` variable; or `y` which is not calculated by any previous block but is passed by the user in the `fit` or `predict` method calls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/mcasl/PipeGraph/master/doc/images/figure1.png\" width=\"400\" />\n",
    "Figure 1. PipeGraph diagram showing the steps and their connections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first simple example of `pipegraph` the last step is a regressor, and thus the `PipeGraphRegressor` class is the most adequate class to choose. But other than that, we define the steps as usual for a standard `Pipeline`: as a list of tuples (label, sklearn object). We are not introducing yet any information at all about the connections, in which case the `PipeGraphRegressor` object is built considering that the steps follow a linear workflow in the same way as a standard `Pipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PipeGraphRegressor(fit_connections={'scaler': {'X': 'X'}, 'linear_model': {'X': ('scaler', 'predict'), 'y': 'y'}},\n",
       "          log_level=None,\n",
       "          predict_connections={'scaler': {'X': 'X'}, 'linear_model': {'X': ('scaler', 'predict'), 'y': 'y'}},\n",
       "          steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('linear_model', LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pipegraph import PipeGraphRegressor\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "linear_model = LinearRegression()\n",
    "steps = [('scaler', scaler),\n",
    "         ('linear_model', linear_model)]\n",
    "\n",
    "pgraph = PipeGraphRegressor(steps=steps)\n",
    "pgraph.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the printed output shows, the internal links displayed by the `fit_connections` and `predict_connections` parameters are in line with those we saw in Figure 1 and those expected by a single path pipeline. As we did not specify these values, they were created by `PipeGRaphRegressor.__init__()` method as a comodity. We can have a look at these values by directly inspecting the attributes values. As `PipeGraphRegressor` and `PipeGraphClassifier` are wrappers of a `PipeGraph` object stored in the `_pipegraph` attribute, we have to dig a bit deeper to find the `fit_connections`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'linear_model': {'X': ('scaler', 'predict'), 'y': 'y'}, 'scaler': {'X': 'X'}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pgraph._pipegraph.fit_connections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 2 surely will help understading the syntax used by the connections dictionary. It goes like this:\n",
    "- The keys of the top level entries of the dictionary must be the same as those of the previously defined steps.\n",
    "- The values assocciated to these keys define the variables from other steps that are going to be considered as inputs for the current step. They are dictionaries themselves, where:\n",
    "\n",
    "   - The keys of the nested dictionary represent the input variables as named at the current step.\n",
    "   - The values assocciated to these keys define the steps that hold the desired information and the variables as named at that step. This information can be written as:\n",
    "\n",
    "     - A tuple with the label of the step in position 0 followed by the name of the output variable in position 1.\n",
    "     - A string:\n",
    "         - If the string value is one of the labels from the steps, then it is interpreted as tuple, as previously, with the label of the step in position 0 and 'predict' as name of the output variable in position 1.\n",
    "         - Otherwise, it is considered to be a variable from an external source, such as those provided by the user while invoking the ``fit``, ``predict`` or ``fit_predict`` methods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Figure 2. Illustration of the connections of the PipeGraph](https://raw.githubusercontent.com/mcasl/PipeGraph/master/examples/images/Diapositiva1-2.png)\n",
    "\n",
    "Figure 2. Illustration of the connections of the PipeGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The choice of name 'predict' for default output variables was made for convenience reasons as it will be illustrated later on. The developers preferred using always the same word for every block even though it might not be a regressor nor a classifier.\n",
    "\n",
    "Finally, let's get the predicted values from this `PipeGraphRegressor` for illustrative purposes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJQpjjDGhLFEYY4wJZYnCGGNMqP8Pf662NOCb4egAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14e7ed757f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = pgraph.predict(X)\n",
    "plt.scatter(X, y, label='Original Data')\n",
    "plt.scatter(X, y_pred, label='Predicted Data')\n",
    "plt.title('Plots of original and predicted data')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True)\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Value of Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `GridSearchCV` compatibility requirements\n",
    "\n",
    "Both `PipeGraphRegressor`and `PipeGraphClassifier` are compatible with `GridSearchCV` provided the last step can be scored, either:\n",
    "- by using `PipeGraphRegressor` or `PipeGraphClassifier` default scoring functions,\n",
    "- by implementing a custom scoring function capable of handling that last step inputs and outputs,\n",
    "- by using a `NeutralRegressor` or `NeutralClassifier` block as final step.\n",
    "\n",
    "Those pipegraphs with a last step from scikit-learn's estimators set will work perfectly well using `PipeGraphRegressor` or `PipeGraphClassifier` default scoring functions. The other two alternative cover those cases in which a custom block with non standard inputs is provided. In that case, choosing a neutral regressor or classifier is usually a much simpler approach than writing customs scoring function. `NeutralRegressor` or `NeutralClassifier` are two classes provided for users convenience so that no special scoring function is needed. They just allow the user to pick some variables from other previous steps as `X` and `y` and provide compatibility to use a default scoring function.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example using default scoring functions\n",
    "We will show more complex examples in what follows, but let's first illustrate with a simple example how to use `GrisSearchCV` with the default scoring functions. Figure 3 shows the steps of the model:\n",
    "- **scaler**: a preprocessing step using a `MinMaxScaler` object,\n",
    "- **polynomial_features**: a transformer step that  generates a new feature matrix consisting of all polynomial combinations of the features with degree less than or equal to the specified one,\n",
    "- **linear_model**: the `LinearRegression` object we want to fit.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/mcasl/PipeGraph/master/doc/images/figure2.png\" width=\"700\" />\n",
    "\n",
    "Figure 3. Using a PipeGraphRegressor object as estimator by GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we import the necessary libraries and create some artificial data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "X = 2*np.random.rand(100,1)-1\n",
    "y = 40 * X**5 + 3*X*2 +  3*X + 3*np.random.randn(100,1)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "polynomial_features = PolynomialFeatures()\n",
    "linear_model = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondly, we define the steps and a ``param_grid`` dictionary as specified by `GridSearchCV`.\n",
    "In this case we just want to explore a few possibilities varying the degree of the polynomials and whether to use or not an intercept at the linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [('scaler', scaler),\n",
    "         ('polynomial_features', polynomial_features),\n",
    "         ('linear_model', linear_model)]\n",
    "\n",
    "param_grid = {'polynomial_features__degree': range(1, 11),\n",
    "              'linear_model__fit_intercept': [True, False]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we use ``PipeGraphRegressor`` as estimator for `GridSearchCV` and perform the ``fit`` and ``predict`` operations. As  the last steps, a linear regressor from scikit-learn,  already works with the default scoring functions, no extra efforts are needed to make it compatible with `GridSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14e7ef71b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information about the parameters of the best estimator: \n",
      " degree: 5 \n",
      " coefficients: [[    0.           406.41597554 -1520.18534981  2972.8702036  -2907.35716696\n",
      "   1138.32000687]] \n"
     ]
    }
   ],
   "source": [
    "pgraph = PipeGraphRegressor(steps=steps)\n",
    "grid_search_regressor = GridSearchCV(estimator=pgraph, param_grid=param_grid, refit=True)\n",
    "grid_search_regressor.fit(X, y)\n",
    "y_pred = grid_search_regressor.predict(X)\n",
    "\n",
    "plt.scatter(X, y)\n",
    "plt.scatter(X, y_pred)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "coef = grid_search_regressor.best_estimator_.get_params()['linear_model'].coef_\n",
    "degree = grid_search_regressor.best_estimator_.get_params()['polynomial_features'].degree\n",
    "\n",
    "print('Information about the parameters of the best estimator: \\n degree: {} \\n coefficients: {} '.format(degree, coef))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example showed how to use `GridSearchCV` with `PipeGraphRegressor` in a simple single path workflow with default scoring functions. Let's explore in next section a more complex example.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple path workflow\n",
    "\n",
    "Untill now, all the examples we showed displayed a single path sequence of steps and thus they could have been equally easily done using sickit-learn standard `Pipeline`. We are going to show now an example illustrating a case in which a varying vector is injected to a linear regression model as ``sample_weight`` in order to evaluate them and obtain the sample_weight that generates the best results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's imagine we have a sample_weight vector and different powers of the vector are needed to be evaluated to check which power provides the best general model. The steps of this model, as shown in Figure 4, are:\n",
    "\n",
    "- **selector**: Featuring a `ColumnSelector` custom step. This is not a scikit-learn original object but a custom class that allows to split an array into columns. In this case, ``X`` augmented data is column-wise divided as specified in a mapping dictionary. We previously created an augmented ``X`` in which all data but ``y`` is concatenated and it will be used by `GridSearchCV` to make the cross validation splits. **selector** step de-concatenates such data.\n",
    "- **custom_power**: Featuring a `CustomPower` custom class. A simple transformation of the input data that is powered to a specified power as indicated in ``param_grid``.\n",
    "- **scaler**: implements `MinMaxScaler` class\n",
    "- **polynomial_features**: Contains a `PolynomialFeatures` object\n",
    "- **linear_model**: Contains a `LinearRegression` model\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/mcasl/PipeGraph/master/doc/images/figure3.png\" width=\"700\" />\n",
    "\n",
    "    Figure 4. A multipath model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " To perform such experiment, the following issues appear:\n",
    "\n",
    "- The shape of the graph is not a single path workflow as those that can be implemented using Pipeline.\n",
    "- More than two variables (typically: ``X`` and ``y``) need to be accordingly split in order to perform the cross validation with GridSearchCV, in this case: ``X``, ``y`` and ``sample_weight``.\n",
    "- The information provided to the  ``sample_weight`` parameter of the LinearRegression step varies on the different scenarios explored by GridSearchCV. In a GridSearchCV with Pipeline, ``sample_weight`` can't vary because it is treated as a ``fit_param`` instead of a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pipegraph.base import PipeGraphRegressor, ColumnSelector, Reshape\n",
    "from pipegraph.demo_blocks import CustomPower\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create an augmented ``X`` in which all data but ``y`` is concatenated. In this case, we concatenate ``X`` and ``sample_weight`` vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(dict(X=np.array([   1,    2,    3,    4,    5,    6,    7,    8,    9,   10,   11]),\n",
    "          sample_weight=np.array([0.01, 0.95, 0.10, 0.95, 0.95, 0.10, 0.10, 0.95, 0.95, 0.95, 0.01])))\n",
    "y = np.array(                    [  10,    4,   20,   16,   25 , -60,   85,   64,   81,  100,  150])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define the steps and we use :class:`PipeGraphRegressor` as estimator for :class:`GridSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "polynomial_features = PolynomialFeatures()\n",
    "linear_model = LinearRegression()\n",
    "custom_power = CustomPower()\n",
    "selector = ColumnSelector(mapping={'X': slice(0, 1),\n",
    "                                   'sample_weight': slice(1,2)})\n",
    "\n",
    "steps = [('selector', selector),\n",
    "         ('custom_power', custom_power),\n",
    "         ('scaler', scaler),\n",
    "         ('polynomial_features', polynomial_features),\n",
    "         ('linear_model', linear_model)]\n",
    "\n",
    "pgraph = PipeGraphRegressor(steps=steps)\n",
    "\n",
    "(pgraph.inject(sink='selector', sink_var='X', source='_External', source_var='X')\n",
    "       .inject('custom_power', 'X', 'selector', 'sample_weight')\n",
    "       .inject('scaler', 'X', 'selector', 'X')\n",
    "       .inject('polynomial_features', 'X', 'scaler')\n",
    "       .inject('linear_model', 'X',  'polynomial_features')\n",
    "       .inject('linear_model', 'y', source_var='y')\n",
    "       .inject('linear_model', 'sample_weight', 'custom_power'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we define ``param_grid`` as expected by :class:`GridSearchCV` exploring a few possibilities of varying parameters.\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'polynomial_features__degree': range(1, 3),\n",
    "              'linear_model__fit_intercept': [True, False],\n",
    "              'custom_power__power': [1, 5, 10, 20, 30]}\n",
    "\n",
    "\n",
    "\n",
    "grid_search_regressor = GridSearchCV(estimator=pgraph, param_grid=param_grid, refit=True)\n",
    "grid_search_regressor.fit(X, y)\n",
    "y_pred = grid_search_regressor.predict(X)\n",
    "\n",
    "plt.scatter(X.loc[:,'X'], y)\n",
    "plt.scatter(X.loc[:,'X'], y_pred)\n",
    "plt.show()\n",
    "\n",
    "power = grid_search_regressor.best_estimator_.get_params()['custom_power']\n",
    "print('Power that obtains the best results in the linear model: \\n {}'.format(power))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example displayed a non linear workflow successfully implemented by **PipeGraph**, while at the same time showing a way to circumvent current limitations of standard :class:`GridSearchCV`, in particular, the retriction on the number of input parameters.\n",
    ":ref:`Next examples <example4>` show more elaborated examples in increasing complexity order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrappers for Scikit-Learn standard objects\n",
    "Consider the following Scikit-Learn common objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "classifier = GaussianNB()\n",
    "scaler = MinMaxScaler() \n",
    "dbscanner = DBSCAN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's load some data to run the examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's fit each of the above defined sklearn objects and get the output produced afterwards by using the corresponding method (predict, fit_predict, transform):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DBSCAN(algorithm='auto', eps=0.5, leaf_size=30, metric='euclidean',\n",
       "    metric_params=None, min_samples=5, n_jobs=1, p=None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X, y)\n",
    "scaler.fit(X);\n",
    "dbscanner.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.00000000e+000,   1.38496103e-018,   7.25489025e-026],\n",
       "       [  1.00000000e+000,   1.48206242e-017,   2.29743996e-025],\n",
       "       [  1.00000000e+000,   1.07780639e-018,   2.35065917e-026],\n",
       "       [  1.00000000e+000,   1.43871443e-017,   2.89954283e-025],\n",
       "       [  1.00000000e+000,   4.65192224e-019,   2.95961100e-026],\n",
       "       [  1.00000000e+000,   1.52598944e-014,   1.79883402e-021],\n",
       "       [  1.00000000e+000,   1.13555084e-017,   2.79240943e-025],\n",
       "       [  1.00000000e+000,   6.57615274e-018,   2.79021029e-025],\n",
       "       [  1.00000000e+000,   9.12219356e-018,   1.16607332e-025],\n",
       "       [  1.00000000e+000,   3.20344249e-018,   1.12989524e-025],\n",
       "       [  1.00000000e+000,   4.48944985e-018,   5.19388089e-025],\n",
       "       [  1.00000000e+000,   1.65734172e-017,   7.24605453e-025],\n",
       "       [  1.00000000e+000,   1.19023891e-018,   3.06690017e-026],\n",
       "       [  1.00000000e+000,   7.39520546e-020,   1.77972179e-027],\n",
       "       [  1.00000000e+000,   2.58242749e-019,   8.73399972e-026],\n",
       "       [  1.00000000e+000,   3.17746623e-017,   1.73684833e-023],\n",
       "       [  1.00000000e+000,   5.70113578e-017,   4.84010372e-024],\n",
       "       [  1.00000000e+000,   2.42054769e-017,   8.45556661e-025],\n",
       "       [  1.00000000e+000,   6.27645419e-015,   1.06276762e-021],\n",
       "       [  1.00000000e+000,   8.94493797e-018,   7.10691894e-025],\n",
       "       [  1.00000000e+000,   1.12843548e-015,   7.60807373e-023],\n",
       "       [  1.00000000e+000,   6.39726172e-016,   2.98066089e-023],\n",
       "       [  1.00000000e+000,   2.01227309e-020,   1.00676223e-027],\n",
       "       [  1.00000000e+000,   1.88370574e-011,   3.47694606e-019],\n",
       "       [  1.00000000e+000,   9.85315738e-015,   6.06138600e-022],\n",
       "       [  1.00000000e+000,   3.37823264e-016,   6.39532840e-024],\n",
       "       [  1.00000000e+000,   1.76045187e-014,   4.11462407e-022],\n",
       "       [  1.00000000e+000,   7.35980232e-018,   4.42389485e-025],\n",
       "       [  1.00000000e+000,   4.16674318e-018,   1.83083484e-025],\n",
       "       [  1.00000000e+000,   4.59768498e-017,   1.25839903e-024],\n",
       "       [  1.00000000e+000,   1.05032415e-016,   2.32677467e-024],\n",
       "       [  1.00000000e+000,   2.19590125e-014,   6.17650711e-022],\n",
       "       [  1.00000000e+000,   6.53087316e-021,   3.11887725e-027],\n",
       "       [  1.00000000e+000,   3.19701924e-020,   1.42881733e-026],\n",
       "       [  1.00000000e+000,   3.20344249e-018,   1.12989524e-025],\n",
       "       [  1.00000000e+000,   1.31355747e-018,   2.91614269e-026],\n",
       "       [  1.00000000e+000,   3.69675482e-018,   2.51866027e-025],\n",
       "       [  1.00000000e+000,   3.20344249e-018,   1.12989524e-025],\n",
       "       [  1.00000000e+000,   2.08944813e-018,   3.09410939e-026],\n",
       "       [  1.00000000e+000,   9.57268514e-018,   4.26475768e-025],\n",
       "       [  1.00000000e+000,   6.37746927e-018,   1.99216264e-025],\n",
       "       [  1.00000000e+000,   7.48755609e-016,   1.85220582e-024],\n",
       "       [  1.00000000e+000,   6.74316102e-019,   1.54533175e-026],\n",
       "       [  1.00000000e+000,   6.24456357e-011,   1.54295833e-018],\n",
       "       [  1.00000000e+000,   8.14548341e-013,   7.52199540e-020],\n",
       "       [  1.00000000e+000,   1.94244394e-016,   1.96296487e-024],\n",
       "       [  1.00000000e+000,   2.39642309e-018,   3.11909164e-025],\n",
       "       [  1.00000000e+000,   2.30047669e-018,   5.36192288e-026],\n",
       "       [  1.00000000e+000,   2.70414239e-018,   2.86492790e-025],\n",
       "       [  1.00000000e+000,   3.60099614e-018,   1.12304319e-025],\n",
       "       [  1.87127931e-108,   8.04037666e-001,   1.95962334e-001],\n",
       "       [  6.18854779e-101,   9.45169639e-001,   5.48303606e-002],\n",
       "       [  1.52821825e-122,   4.56151317e-001,   5.43848683e-001],\n",
       "       [  2.14997261e-070,   9.99968751e-001,   3.12488556e-005],\n",
       "       [  9.04938222e-107,   9.52441811e-001,   4.75581888e-002],\n",
       "       [  1.29272979e-090,   9.99119627e-001,   8.80372565e-004],\n",
       "       [  2.72490532e-114,   6.58952285e-001,   3.41047715e-001],\n",
       "       [  1.19734767e-034,   9.99999767e-001,   2.33206910e-007],\n",
       "       [  3.02545627e-098,   9.90316309e-001,   9.68369084e-003],\n",
       "       [  1.29477666e-069,   9.99909746e-001,   9.02536083e-005],\n",
       "       [  2.68173680e-041,   9.99999765e-001,   2.35068227e-007],\n",
       "       [  7.51115851e-087,   9.96238286e-001,   3.76171369e-003],\n",
       "       [  6.40165546e-061,   9.99993984e-001,   6.01632484e-006],\n",
       "       [  4.81814146e-105,   9.86090825e-001,   1.39091754e-002],\n",
       "       [  1.72509107e-055,   9.99975387e-001,   2.46126406e-005],\n",
       "       [  1.18941242e-093,   9.80037003e-001,   1.99629974e-002],\n",
       "       [  1.18009940e-098,   9.90687273e-001,   9.31272734e-003],\n",
       "       [  2.31534504e-063,   9.99983663e-001,   1.63372809e-005],\n",
       "       [  5.48394976e-102,   9.94697108e-001,   5.30289217e-003],\n",
       "       [  5.51699136e-059,   9.99993006e-001,   6.99364316e-006],\n",
       "       [  7.43572418e-129,   1.54494085e-001,   8.45505915e-001],\n",
       "       [  2.12417952e-071,   9.99807026e-001,   1.92973847e-004],\n",
       "       [  1.06622383e-120,   9.27077052e-001,   7.29229479e-002],\n",
       "       [  4.79428037e-097,   9.98156519e-001,   1.84348055e-003],\n",
       "       [  2.71707817e-084,   9.98460816e-001,   1.53918416e-003],\n",
       "       [  2.03176962e-093,   9.87471082e-001,   1.25289184e-002],\n",
       "       [  4.95012220e-113,   9.12844444e-001,   8.71555561e-002],\n",
       "       [  2.12531216e-137,   7.52691316e-002,   9.24730868e-001],\n",
       "       [  4.19702663e-100,   9.86480268e-001,   1.35197316e-002],\n",
       "       [  4.63173354e-042,   9.99998762e-001,   1.23794211e-006],\n",
       "       [  2.77274013e-055,   9.99996447e-001,   3.55251831e-006],\n",
       "       [  2.14091116e-048,   9.99998651e-001,   1.34923924e-006],\n",
       "       [  6.63563094e-063,   9.99972348e-001,   2.76523927e-005],\n",
       "       [  2.61124821e-134,   6.12159845e-001,   3.87840155e-001],\n",
       "       [  3.71647418e-098,   9.92476638e-001,   7.52336224e-003],\n",
       "       [  1.13230275e-103,   8.76107551e-001,   1.23892449e-001],\n",
       "       [  1.05786721e-111,   7.99294752e-001,   2.00705248e-001],\n",
       "       [  3.76539608e-089,   9.99385417e-001,   6.14582528e-004],\n",
       "       [  3.07894878e-073,   9.99796270e-001,   2.03730114e-004],\n",
       "       [  4.17712661e-070,   9.99955234e-001,   4.47664632e-005],\n",
       "       [  3.92710689e-082,   9.99873680e-001,   1.26320322e-004],\n",
       "       [  3.30872742e-100,   9.89371467e-001,   1.06285328e-002],\n",
       "       [  8.31545615e-067,   9.99966229e-001,   3.37713204e-005],\n",
       "       [  6.26912483e-035,   9.99999798e-001,   2.02487922e-007],\n",
       "       [  7.66367658e-078,   9.99832329e-001,   1.67671378e-004],\n",
       "       [  1.58557717e-073,   9.99849875e-001,   1.50125137e-004],\n",
       "       [  1.02662082e-077,   9.99714947e-001,   2.85053350e-004],\n",
       "       [  1.72307593e-083,   9.98992363e-001,   1.00763708e-003],\n",
       "       [  4.12872931e-030,   9.99999769e-001,   2.31316897e-007],\n",
       "       [  5.99667528e-074,   9.99847160e-001,   1.52839987e-004],\n",
       "       [  4.13779546e-251,   6.35381030e-011,   1.00000000e+000],\n",
       "       [  5.00845630e-151,   2.50121636e-002,   9.74987836e-001],\n",
       "       [  1.04941686e-218,   1.67915381e-007,   9.99999832e-001],\n",
       "       [  2.13833836e-175,   1.99462374e-003,   9.98005376e-001],\n",
       "       [  7.20399720e-216,   2.30543407e-007,   9.99999769e-001],\n",
       "       [  4.51654712e-271,   2.40976994e-010,   1.00000000e+000],\n",
       "       [  4.59552511e-108,   9.73514345e-001,   2.64856553e-002],\n",
       "       [  2.22191497e-227,   1.34018147e-006,   9.99998660e-001],\n",
       "       [  2.10589122e-190,   4.92901785e-004,   9.99507098e-001],\n",
       "       [  1.20055778e-262,   1.40568402e-012,   1.00000000e+000],\n",
       "       [  3.62359789e-160,   4.12884115e-004,   9.99587116e-001],\n",
       "       [  8.83719953e-165,   2.77742178e-003,   9.97222578e-001],\n",
       "       [  6.87376950e-192,   4.80711862e-006,   9.99995193e-001],\n",
       "       [  4.08220498e-152,   1.28807070e-002,   9.87119293e-001],\n",
       "       [  2.75153031e-187,   1.04253685e-006,   9.99998957e-001],\n",
       "       [  1.44750671e-192,   4.50951786e-007,   9.99999549e-001],\n",
       "       [  2.76680341e-170,   1.87196580e-003,   9.98128034e-001],\n",
       "       [  3.75302289e-285,   1.64574932e-012,   1.00000000e+000],\n",
       "       [  4.69548986e-310,   6.47406861e-013,   1.00000000e+000],\n",
       "       [  5.69697725e-125,   9.58135362e-001,   4.18646381e-002],\n",
       "       [  2.94299535e-219,   1.17116897e-008,   9.99999988e-001],\n",
       "       [  2.82525894e-146,   1.37625971e-002,   9.86237403e-001],\n",
       "       [  1.12237933e-272,   7.58240410e-010,   9.99999999e-001],\n",
       "       [  2.28867567e-136,   1.29986728e-001,   8.70013272e-001],\n",
       "       [  5.61795825e-203,   9.71777952e-007,   9.99999028e-001],\n",
       "       [  8.72622664e-206,   7.39901993e-006,   9.99992601e-001],\n",
       "       [  9.96933448e-131,   1.99928220e-001,   8.00071780e-001],\n",
       "       [  4.66749613e-135,   1.07483532e-001,   8.92516468e-001],\n",
       "       [  6.88743059e-196,   1.09467814e-005,   9.99989053e-001],\n",
       "       [  1.61337601e-181,   7.01805717e-004,   9.99298194e-001],\n",
       "       [  8.55580252e-221,   9.06238440e-007,   9.99999094e-001],\n",
       "       [  1.24722670e-250,   2.96730515e-010,   1.00000000e+000],\n",
       "       [  3.64874362e-203,   1.50788229e-006,   9.99998492e-001],\n",
       "       [  2.19798649e-130,   7.12645144e-001,   2.87354856e-001],\n",
       "       [  3.68949024e-153,   4.86199285e-001,   5.13800715e-001],\n",
       "       [  2.13595212e-251,   8.98578645e-011,   1.00000000e+000],\n",
       "       [  2.75337356e-217,   6.58848819e-009,   9.99999993e-001],\n",
       "       [  1.30868299e-169,   1.90227600e-003,   9.98097724e-001],\n",
       "       [  1.38946382e-129,   1.93183856e-001,   8.06816144e-001],\n",
       "       [  1.71830037e-186,   5.23126458e-006,   9.99994769e-001],\n",
       "       [  5.79667973e-220,   5.01446575e-009,   9.99999995e-001],\n",
       "       [  1.61093140e-184,   4.67798053e-007,   9.99999532e-001],\n",
       "       [  5.00845630e-151,   2.50121636e-002,   9.74987836e-001],\n",
       "       [  2.54029381e-231,   4.42556022e-009,   9.99999996e-001],\n",
       "       [  4.84219075e-234,   1.64602693e-010,   1.00000000e+000],\n",
       "       [  6.47732320e-189,   5.85507961e-007,   9.99999414e-001],\n",
       "       [  5.17352411e-148,   2.54457623e-002,   9.74554238e-001],\n",
       "       [  5.93498263e-166,   3.70166861e-004,   9.99629833e-001],\n",
       "       [  5.58649523e-197,   2.46020434e-007,   9.99999754e-001],\n",
       "       [  9.13863414e-145,   5.60050091e-002,   9.43994991e-001]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.00000000e+00,  -4.11208597e+01,  -5.78855367e+01],\n",
       "       [  0.00000000e+00,  -3.87505119e+01,  -5.67328319e+01],\n",
       "       [  0.00000000e+00,  -4.13716038e+01,  -5.90125166e+01],\n",
       "       [  0.00000000e+00,  -3.87801966e+01,  -5.65000742e+01],\n",
       "       [  0.00000000e+00,  -4.22118362e+01,  -5.87821546e+01],\n",
       "       [ -1.50990331e-14,  -3.18135483e+01,  -4.77671483e+01],\n",
       "       [  0.00000000e+00,  -3.90168287e+01,  -5.65377225e+01],\n",
       "       [  0.00000000e+00,  -3.95630818e+01,  -5.65385104e+01],\n",
       "       [  0.00000000e+00,  -3.92358214e+01,  -5.74109854e+01],\n",
       "       [  0.00000000e+00,  -4.02823057e+01,  -5.74425024e+01],\n",
       "       [  0.00000000e+00,  -3.99448015e+01,  -5.59171461e+01],\n",
       "       [  0.00000000e+00,  -3.86387316e+01,  -5.55841702e+01],\n",
       "       [  0.00000000e+00,  -4.12723776e+01,  -5.87465451e+01],\n",
       "       [  0.00000000e+00,  -4.40508700e+01,  -6.15933405e+01],\n",
       "       [  0.00000000e+00,  -4.28003869e+01,  -5.76999890e+01],\n",
       "       [  0.00000000e+00,  -3.79878625e+01,  -5.24073850e+01],\n",
       "       [  0.00000000e+00,  -3.74032812e+01,  -5.36851061e+01],\n",
       "       [  0.00000000e+00,  -3.82599527e+01,  -5.54298023e+01],\n",
       "       [ -6.21724894e-15,  -3.27019712e+01,  -4.82934105e+01],\n",
       "       [  0.00000000e+00,  -3.92554439e+01,  -5.56035585e+01],\n",
       "       [ -1.11022302e-15,  -3.44179443e+01,  -5.09302471e+01],\n",
       "       [ -6.66133815e-16,  -3.49854914e+01,  -5.18673121e+01],\n",
       "       [  0.00000000e+00,  -4.53524369e+01,  -6.21630580e+01],\n",
       "       [ -1.88369320e-11,  -2.46951950e+01,  -4.25029624e+01],\n",
       "       [ -9.76996262e-15,  -3.22509844e+01,  -4.88549336e+01],\n",
       "       [ -4.44089210e-16,  -3.56240088e+01,  -5.34064744e+01],\n",
       "       [ -1.75415238e-14,  -3.16706208e+01,  -4.92423246e+01],\n",
       "       [  0.00000000e+00,  -3.94504986e+01,  -5.60776068e+01],\n",
       "       [  0.00000000e+00,  -4.00193970e+01,  -5.69598553e+01],\n",
       "       [  0.00000000e+00,  -3.76183937e+01,  -5.50322019e+01],\n",
       "       [  0.00000000e+00,  -3.67922627e+01,  -5.44175592e+01],\n",
       "       [ -2.19824159e-14,  -3.14495987e+01,  -4.88361191e+01],\n",
       "       [  0.00000000e+00,  -4.64777463e+01,  -6.10323244e+01],\n",
       "       [  0.00000000e+00,  -4.48894830e+01,  -5.95103654e+01],\n",
       "       [  0.00000000e+00,  -4.02823057e+01,  -5.74425024e+01],\n",
       "       [  0.00000000e+00,  -4.11737926e+01,  -5.87969507e+01],\n",
       "       [  0.00000000e+00,  -4.01390763e+01,  -5.66409002e+01],\n",
       "       [  0.00000000e+00,  -4.02823057e+01,  -5.74425024e+01],\n",
       "       [  0.00000000e+00,  -4.07096317e+01,  -5.87377123e+01],\n",
       "       [  0.00000000e+00,  -3.91876179e+01,  -5.61142420e+01],\n",
       "       [  0.00000000e+00,  -3.95937603e+01,  -5.68754065e+01],\n",
       "       [ -8.88178420e-16,  -3.48281190e+01,  -5.46456650e+01],\n",
       "       [  0.00000000e+00,  -4.18405880e+01,  -5.94319738e+01],\n",
       "       [ -6.24451602e-11,  -2.34967248e+01,  -4.10128301e+01],\n",
       "       [ -8.14459611e-13,  -2.78361426e+01,  -4.40338704e+01],\n",
       "       [ -2.22044605e-16,  -3.61774145e+01,  -5.45875862e+01],\n",
       "       [  0.00000000e+00,  -4.05725544e+01,  -5.64270855e+01],\n",
       "       [  0.00000000e+00,  -4.06134153e+01,  -5.81878898e+01],\n",
       "       [  0.00000000e+00,  -4.04517469e+01,  -5.65120841e+01],\n",
       "       [  0.00000000e+00,  -4.01653212e+01,  -5.74485852e+01],\n",
       "       [ -2.48052568e+02,  -2.18109163e-01,  -1.62983281e+00],\n",
       "       [ -2.30738394e+02,  -5.63908550e-02,  -2.90351121e+00],\n",
       "       [ -2.80491279e+02,  -7.84930690e-01,  -6.09084226e-01],\n",
       "       [ -1.60415501e+02,  -3.12493439e-05,  -1.03735278e+01],\n",
       "       [ -2.44173908e+02,  -4.87262645e-02,  -3.04580129e+00],\n",
       "       [ -2.06975902e+02,  -8.80760321e-04,  -7.03516537e+00],\n",
       "       [ -2.61492267e+02,  -4.17104153e-01,  -1.07573288e+00],\n",
       "       [ -7.81077843e+01,  -2.33206936e-07,  -1.52713398e+01],\n",
       "       [ -2.24546277e+02,  -9.73088268e-03,  -4.63731216e+00],\n",
       "       [ -1.58620033e+02,  -9.02576814e-05,  -9.31288698e+00],\n",
       "       [ -9.34195242e+01,  -2.35068255e-07,  -1.52633900e+01],\n",
       "       [ -1.98308513e+02,  -3.76880673e-03,  -5.58288066e+00],\n",
       "       [ -1.38601134e+02,  -6.01634294e-06,  -1.20210340e+01],\n",
       "       [ -2.40199046e+02,  -1.40068145e-02,  -4.27520655e+00],\n",
       "       [ -1.26096900e+02,  -2.46129435e-05,  -1.06122504e+01],\n",
       "       [ -2.13966954e+02,  -2.01649503e-02,  -3.91387485e+00],\n",
       "       [ -2.25487740e+02,  -9.35636191e-03,  -4.67637328e+00],\n",
       "       [ -1.44223302e+02,  -1.63374144e-05,  -1.10220609e+01],\n",
       "       [ -2.33161854e+02,  -5.31700240e-03,  -5.23950292e+00],\n",
       "       [ -1.34144688e+02,  -6.99366761e-06,  -1.18705089e+01],\n",
       "       [ -2.95027181e+02,  -1.86759947e+00,  -1.67820115e-01],\n",
       "       [ -1.62730156e+02,  -1.92992469e-04,  -8.55295589e+00],\n",
       "       [ -2.76246088e+02,  -7.57185971e-02,  -2.61835190e+00],\n",
       "       [ -2.21783330e+02,  -1.84518185e-03,  -6.29609989e+00],\n",
       "       [ -1.92417591e+02,  -1.54036992e-03,  -6.47650277e+00],\n",
       "       [ -2.13431507e+02,  -1.26080671e-02,  -4.37971584e+00],\n",
       "       [ -2.58592703e+02,  -9.11897920e-02,  -2.44006076e+00],\n",
       "       [ -3.14700239e+02,  -2.58668517e+00,  -7.82525369e-02],\n",
       "       [ -2.28824133e+02,  -1.36119554e-02,  -4.30360506e+00],\n",
       "       [ -9.51756427e+01,  -1.23794287e-06,  -1.36020601e+01],\n",
       "       [ -1.25622344e+02,  -3.55252462e-06,  -1.25478538e+01],\n",
       "       [ -1.09762853e+02,  -1.34924015e-06,  -1.35159697e+01],\n",
       "       [ -1.43170407e+02,  -2.76527750e-05,  -1.04957983e+01],\n",
       "       [ -3.07586574e+02,  -4.90761846e-01,  -9.47161995e-01],\n",
       "       [ -2.24340564e+02,  -7.55180548e-03,  -4.88974213e+00],\n",
       "       [ -2.37042011e+02,  -1.32266420e-01,  -2.08834144e+00],\n",
       "       [ -2.55530691e+02,  -2.24025500e-01,  -1.60591787e+00],\n",
       "       [ -2.03604220e+02,  -6.14771461e-04,  -7.39456734e+00],\n",
       "       [ -1.66964124e+02,  -2.03750870e-04,  -8.49871441e+00],\n",
       "       [ -1.59751333e+02,  -4.47674653e-05,  -1.00140513e+01],\n",
       "       [ -1.87444075e+02,  -1.26328301e-04,  -8.97668964e+00],\n",
       "       [ -2.29061946e+02,  -1.06854191e-02,  -4.54421312e+00],\n",
       "       [ -1.52155085e+02,  -3.37718907e-05,  -1.02958986e+01],\n",
       "       [ -7.87548415e+01,  -2.02487942e-07,  -1.54125856e+01],\n",
       "       [ -1.77565145e+02,  -1.67685437e-04,  -8.69350458e+00],\n",
       "       [ -1.67627763e+02,  -1.50136407e-04,  -8.80404136e+00],\n",
       "       [ -1.77272780e+02,  -2.85093986e-04,  -8.16283420e+00],\n",
       "       [ -1.90570452e+02,  -1.00814508e-03,  -6.90014722e+00],\n",
       "       [ -6.76595831e+01,  -2.31316924e-07,  -1.52794772e+01],\n",
       "       [ -1.68600092e+02,  -1.52851668e-04,  -8.78611902e+00],\n",
       "       [ -5.76528695e+02,  -2.34793813e+01,  -6.35380637e-11],\n",
       "       [ -3.46079221e+02,  -3.68839303e+00,  -2.53302835e-02],\n",
       "       [ -5.01915316e+02,  -1.55998057e+01,  -1.67915395e-07],\n",
       "       [ -4.02192362e+02,  -6.21729985e+00,  -1.99661565e-03],\n",
       "       [ -4.95383744e+02,  -1.52828267e+01,  -2.30543434e-07],\n",
       "       [ -6.22492812e+02,  -2.21463196e+01,  -2.40977016e-10],\n",
       "       [ -2.47154107e+02,  -2.68427191e-02,  -3.63115200e+00],\n",
       "       [ -5.21888447e+02,  -1.35227055e+01,  -1.34018237e-06],\n",
       "       [ -4.36746429e+02,  -7.61520062e+00,  -4.93023301e-04],\n",
       "       [ -6.03094508e+02,  -2.72904971e+01,  -1.40598644e-12],\n",
       "       [ -3.67126147e+02,  -7.79234360e+00,  -4.12969376e-04],\n",
       "       [ -3.77747570e+02,  -5.88623220e+00,  -2.78128597e-03],\n",
       "       [ -4.40168625e+02,  -1.22454127e+01,  -4.80713017e-06],\n",
       "       [ -3.48586297e+02,  -4.35202467e+00,  -1.29643826e-02],\n",
       "       [ -4.29571255e+02,  -1.37738535e+01,  -1.04253739e-06],\n",
       "       [ -4.41726495e+02,  -1.46119054e+01,  -4.50951887e-07],\n",
       "       [ -3.90421773e+02,  -6.28076617e+00,  -1.87372012e-03],\n",
       "       [ -6.54914190e+02,  -2.71328253e+01,  -1.64490643e-12],\n",
       "       [ -7.12254776e+02,  -2.80658015e+01,  -6.47482068e-13],\n",
       "       [ -2.86083201e+02,  -4.27662147e-02,  -3.17331377e+00],\n",
       "       [ -5.03186707e+02,  -1.82626784e+01,  -1.17116898e-08],\n",
       "       [ -3.35138824e+02,  -4.28580072e+00,  -1.38581796e-02],\n",
       "       [ -6.26187694e+02,  -2.10000206e+01,  -7.58240581e-10],\n",
       "       [ -3.12323599e+02,  -2.04032292e+00,  -1.39246813e-01],\n",
       "       [ -4.65698806e+02,  -1.38441385e+01,  -9.71778424e-07],\n",
       "       [ -4.72166196e+02,  -1.18141630e+01,  -7.39904730e-06],\n",
       "       [ -2.99339133e+02,  -1.60979688e+00,  -2.23053830e-01],\n",
       "       [ -3.09308365e+02,  -2.23041763e+00,  -1.13710314e-01],\n",
       "       [ -4.49376980e+02,  -1.14224651e+01,  -1.09468413e-05],\n",
       "       [ -4.16289573e+02,  -7.26185395e+00,  -7.02052098e-04],\n",
       "       [ -5.06724696e+02,  -1.39139634e+01,  -9.06238851e-07],\n",
       "       [ -5.75425351e+02,  -2.19381967e+01,  -2.96730640e-10],\n",
       "       [ -4.66130391e+02,  -1.34048044e+01,  -1.50788342e-06],\n",
       "       [ -2.98548520e+02,  -3.38771676e-01,  -1.24703740e+00],\n",
       "       [ -3.50990031e+02,  -7.21136687e-01,  -6.65919804e-01],\n",
       "       [ -5.77189946e+02,  -2.31327920e+01,  -8.98578989e-11],\n",
       "       [ -4.98648138e+02,  -1.88379419e+01,  -6.58848798e-09],\n",
       "       [ -3.88867859e+02,  -6.26470421e+00,  -1.90408763e-03],\n",
       "       [ -2.96704559e+02,  -1.64411292e+00,  -2.14659463e-01],\n",
       "       [ -4.27739492e+02,  -1.21608575e+01,  -5.23127826e-06],\n",
       "       [ -5.04811435e+02,  -1.91109390e+01,  -5.01446573e-09],\n",
       "       [ -4.23198845e+02,  -1.45752291e+01,  -4.67798162e-07],\n",
       "       [ -3.46079221e+02,  -3.68839303e+00,  -2.53302835e-02],\n",
       "       [ -5.30964877e+02,  -1.92358690e+01,  -4.42555992e-09],\n",
       "       [ -5.37227545e+02,  -2.25274865e+01,  -1.64602554e-10],\n",
       "       [ -4.33320275e+02,  -1.43507861e+01,  -5.85508133e-07],\n",
       "       [ -3.39139040e+02,  -3.67120606e+00,  -2.57751046e-02],\n",
       "       [ -3.80448261e+02,  -7.90155668e+00,  -3.70235390e-04],\n",
       "       [ -4.51888911e+02,  -1.52178512e+01,  -2.46020464e-07],\n",
       "       [ -3.31662328e+02,  -2.88231414e+00,  -5.76344191e-02]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict_log_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.22222222,  0.625     ,  0.06779661,  0.04166667],\n",
       "       [ 0.16666667,  0.41666667,  0.06779661,  0.04166667],\n",
       "       [ 0.11111111,  0.5       ,  0.05084746,  0.04166667],\n",
       "       [ 0.08333333,  0.45833333,  0.08474576,  0.04166667],\n",
       "       [ 0.19444444,  0.66666667,  0.06779661,  0.04166667],\n",
       "       [ 0.30555556,  0.79166667,  0.11864407,  0.125     ],\n",
       "       [ 0.08333333,  0.58333333,  0.06779661,  0.08333333],\n",
       "       [ 0.19444444,  0.58333333,  0.08474576,  0.04166667],\n",
       "       [ 0.02777778,  0.375     ,  0.06779661,  0.04166667],\n",
       "       [ 0.16666667,  0.45833333,  0.08474576,  0.        ],\n",
       "       [ 0.30555556,  0.70833333,  0.08474576,  0.04166667],\n",
       "       [ 0.13888889,  0.58333333,  0.10169492,  0.04166667],\n",
       "       [ 0.13888889,  0.41666667,  0.06779661,  0.        ],\n",
       "       [ 0.        ,  0.41666667,  0.01694915,  0.        ],\n",
       "       [ 0.41666667,  0.83333333,  0.03389831,  0.04166667],\n",
       "       [ 0.38888889,  1.        ,  0.08474576,  0.125     ],\n",
       "       [ 0.30555556,  0.79166667,  0.05084746,  0.125     ],\n",
       "       [ 0.22222222,  0.625     ,  0.06779661,  0.08333333],\n",
       "       [ 0.38888889,  0.75      ,  0.11864407,  0.08333333],\n",
       "       [ 0.22222222,  0.75      ,  0.08474576,  0.08333333],\n",
       "       [ 0.30555556,  0.58333333,  0.11864407,  0.04166667],\n",
       "       [ 0.22222222,  0.70833333,  0.08474576,  0.125     ],\n",
       "       [ 0.08333333,  0.66666667,  0.        ,  0.04166667],\n",
       "       [ 0.22222222,  0.54166667,  0.11864407,  0.16666667],\n",
       "       [ 0.13888889,  0.58333333,  0.15254237,  0.04166667],\n",
       "       [ 0.19444444,  0.41666667,  0.10169492,  0.04166667],\n",
       "       [ 0.19444444,  0.58333333,  0.10169492,  0.125     ],\n",
       "       [ 0.25      ,  0.625     ,  0.08474576,  0.04166667],\n",
       "       [ 0.25      ,  0.58333333,  0.06779661,  0.04166667],\n",
       "       [ 0.11111111,  0.5       ,  0.10169492,  0.04166667],\n",
       "       [ 0.13888889,  0.45833333,  0.10169492,  0.04166667],\n",
       "       [ 0.30555556,  0.58333333,  0.08474576,  0.125     ],\n",
       "       [ 0.25      ,  0.875     ,  0.08474576,  0.        ],\n",
       "       [ 0.33333333,  0.91666667,  0.06779661,  0.04166667],\n",
       "       [ 0.16666667,  0.45833333,  0.08474576,  0.        ],\n",
       "       [ 0.19444444,  0.5       ,  0.03389831,  0.04166667],\n",
       "       [ 0.33333333,  0.625     ,  0.05084746,  0.04166667],\n",
       "       [ 0.16666667,  0.45833333,  0.08474576,  0.        ],\n",
       "       [ 0.02777778,  0.41666667,  0.05084746,  0.04166667],\n",
       "       [ 0.22222222,  0.58333333,  0.08474576,  0.04166667],\n",
       "       [ 0.19444444,  0.625     ,  0.05084746,  0.08333333],\n",
       "       [ 0.05555556,  0.125     ,  0.05084746,  0.08333333],\n",
       "       [ 0.02777778,  0.5       ,  0.05084746,  0.04166667],\n",
       "       [ 0.19444444,  0.625     ,  0.10169492,  0.20833333],\n",
       "       [ 0.22222222,  0.75      ,  0.15254237,  0.125     ],\n",
       "       [ 0.13888889,  0.41666667,  0.06779661,  0.08333333],\n",
       "       [ 0.22222222,  0.75      ,  0.10169492,  0.04166667],\n",
       "       [ 0.08333333,  0.5       ,  0.06779661,  0.04166667],\n",
       "       [ 0.27777778,  0.70833333,  0.08474576,  0.04166667],\n",
       "       [ 0.19444444,  0.54166667,  0.06779661,  0.04166667],\n",
       "       [ 0.75      ,  0.5       ,  0.62711864,  0.54166667],\n",
       "       [ 0.58333333,  0.5       ,  0.59322034,  0.58333333],\n",
       "       [ 0.72222222,  0.45833333,  0.66101695,  0.58333333],\n",
       "       [ 0.33333333,  0.125     ,  0.50847458,  0.5       ],\n",
       "       [ 0.61111111,  0.33333333,  0.61016949,  0.58333333],\n",
       "       [ 0.38888889,  0.33333333,  0.59322034,  0.5       ],\n",
       "       [ 0.55555556,  0.54166667,  0.62711864,  0.625     ],\n",
       "       [ 0.16666667,  0.16666667,  0.38983051,  0.375     ],\n",
       "       [ 0.63888889,  0.375     ,  0.61016949,  0.5       ],\n",
       "       [ 0.25      ,  0.29166667,  0.49152542,  0.54166667],\n",
       "       [ 0.19444444,  0.        ,  0.42372881,  0.375     ],\n",
       "       [ 0.44444444,  0.41666667,  0.54237288,  0.58333333],\n",
       "       [ 0.47222222,  0.08333333,  0.50847458,  0.375     ],\n",
       "       [ 0.5       ,  0.375     ,  0.62711864,  0.54166667],\n",
       "       [ 0.36111111,  0.375     ,  0.44067797,  0.5       ],\n",
       "       [ 0.66666667,  0.45833333,  0.57627119,  0.54166667],\n",
       "       [ 0.36111111,  0.41666667,  0.59322034,  0.58333333],\n",
       "       [ 0.41666667,  0.29166667,  0.52542373,  0.375     ],\n",
       "       [ 0.52777778,  0.08333333,  0.59322034,  0.58333333],\n",
       "       [ 0.36111111,  0.20833333,  0.49152542,  0.41666667],\n",
       "       [ 0.44444444,  0.5       ,  0.6440678 ,  0.70833333],\n",
       "       [ 0.5       ,  0.33333333,  0.50847458,  0.5       ],\n",
       "       [ 0.55555556,  0.20833333,  0.66101695,  0.58333333],\n",
       "       [ 0.5       ,  0.33333333,  0.62711864,  0.45833333],\n",
       "       [ 0.58333333,  0.375     ,  0.55932203,  0.5       ],\n",
       "       [ 0.63888889,  0.41666667,  0.57627119,  0.54166667],\n",
       "       [ 0.69444444,  0.33333333,  0.6440678 ,  0.54166667],\n",
       "       [ 0.66666667,  0.41666667,  0.6779661 ,  0.66666667],\n",
       "       [ 0.47222222,  0.375     ,  0.59322034,  0.58333333],\n",
       "       [ 0.38888889,  0.25      ,  0.42372881,  0.375     ],\n",
       "       [ 0.33333333,  0.16666667,  0.47457627,  0.41666667],\n",
       "       [ 0.33333333,  0.16666667,  0.45762712,  0.375     ],\n",
       "       [ 0.41666667,  0.29166667,  0.49152542,  0.45833333],\n",
       "       [ 0.47222222,  0.29166667,  0.69491525,  0.625     ],\n",
       "       [ 0.30555556,  0.41666667,  0.59322034,  0.58333333],\n",
       "       [ 0.47222222,  0.58333333,  0.59322034,  0.625     ],\n",
       "       [ 0.66666667,  0.45833333,  0.62711864,  0.58333333],\n",
       "       [ 0.55555556,  0.125     ,  0.57627119,  0.5       ],\n",
       "       [ 0.36111111,  0.41666667,  0.52542373,  0.5       ],\n",
       "       [ 0.33333333,  0.20833333,  0.50847458,  0.5       ],\n",
       "       [ 0.33333333,  0.25      ,  0.57627119,  0.45833333],\n",
       "       [ 0.5       ,  0.41666667,  0.61016949,  0.54166667],\n",
       "       [ 0.41666667,  0.25      ,  0.50847458,  0.45833333],\n",
       "       [ 0.19444444,  0.125     ,  0.38983051,  0.375     ],\n",
       "       [ 0.36111111,  0.29166667,  0.54237288,  0.5       ],\n",
       "       [ 0.38888889,  0.41666667,  0.54237288,  0.45833333],\n",
       "       [ 0.38888889,  0.375     ,  0.54237288,  0.5       ],\n",
       "       [ 0.52777778,  0.375     ,  0.55932203,  0.5       ],\n",
       "       [ 0.22222222,  0.20833333,  0.33898305,  0.41666667],\n",
       "       [ 0.38888889,  0.33333333,  0.52542373,  0.5       ],\n",
       "       [ 0.55555556,  0.54166667,  0.84745763,  1.        ],\n",
       "       [ 0.41666667,  0.29166667,  0.69491525,  0.75      ],\n",
       "       [ 0.77777778,  0.41666667,  0.83050847,  0.83333333],\n",
       "       [ 0.55555556,  0.375     ,  0.77966102,  0.70833333],\n",
       "       [ 0.61111111,  0.41666667,  0.81355932,  0.875     ],\n",
       "       [ 0.91666667,  0.41666667,  0.94915254,  0.83333333],\n",
       "       [ 0.16666667,  0.20833333,  0.59322034,  0.66666667],\n",
       "       [ 0.83333333,  0.375     ,  0.89830508,  0.70833333],\n",
       "       [ 0.66666667,  0.20833333,  0.81355932,  0.70833333],\n",
       "       [ 0.80555556,  0.66666667,  0.86440678,  1.        ],\n",
       "       [ 0.61111111,  0.5       ,  0.69491525,  0.79166667],\n",
       "       [ 0.58333333,  0.29166667,  0.72881356,  0.75      ],\n",
       "       [ 0.69444444,  0.41666667,  0.76271186,  0.83333333],\n",
       "       [ 0.38888889,  0.20833333,  0.6779661 ,  0.79166667],\n",
       "       [ 0.41666667,  0.33333333,  0.69491525,  0.95833333],\n",
       "       [ 0.58333333,  0.5       ,  0.72881356,  0.91666667],\n",
       "       [ 0.61111111,  0.41666667,  0.76271186,  0.70833333],\n",
       "       [ 0.94444444,  0.75      ,  0.96610169,  0.875     ],\n",
       "       [ 0.94444444,  0.25      ,  1.        ,  0.91666667],\n",
       "       [ 0.47222222,  0.08333333,  0.6779661 ,  0.58333333],\n",
       "       [ 0.72222222,  0.5       ,  0.79661017,  0.91666667],\n",
       "       [ 0.36111111,  0.33333333,  0.66101695,  0.79166667],\n",
       "       [ 0.94444444,  0.33333333,  0.96610169,  0.79166667],\n",
       "       [ 0.55555556,  0.29166667,  0.66101695,  0.70833333],\n",
       "       [ 0.66666667,  0.54166667,  0.79661017,  0.83333333],\n",
       "       [ 0.80555556,  0.5       ,  0.84745763,  0.70833333],\n",
       "       [ 0.52777778,  0.33333333,  0.6440678 ,  0.70833333],\n",
       "       [ 0.5       ,  0.41666667,  0.66101695,  0.70833333],\n",
       "       [ 0.58333333,  0.33333333,  0.77966102,  0.83333333],\n",
       "       [ 0.80555556,  0.41666667,  0.81355932,  0.625     ],\n",
       "       [ 0.86111111,  0.33333333,  0.86440678,  0.75      ],\n",
       "       [ 1.        ,  0.75      ,  0.91525424,  0.79166667],\n",
       "       [ 0.58333333,  0.33333333,  0.77966102,  0.875     ],\n",
       "       [ 0.55555556,  0.33333333,  0.69491525,  0.58333333],\n",
       "       [ 0.5       ,  0.25      ,  0.77966102,  0.54166667],\n",
       "       [ 0.94444444,  0.41666667,  0.86440678,  0.91666667],\n",
       "       [ 0.55555556,  0.58333333,  0.77966102,  0.95833333],\n",
       "       [ 0.58333333,  0.45833333,  0.76271186,  0.70833333],\n",
       "       [ 0.47222222,  0.41666667,  0.6440678 ,  0.70833333],\n",
       "       [ 0.72222222,  0.45833333,  0.74576271,  0.83333333],\n",
       "       [ 0.66666667,  0.45833333,  0.77966102,  0.95833333],\n",
       "       [ 0.72222222,  0.45833333,  0.69491525,  0.91666667],\n",
       "       [ 0.41666667,  0.29166667,  0.69491525,  0.75      ],\n",
       "       [ 0.69444444,  0.5       ,  0.83050847,  0.91666667],\n",
       "       [ 0.66666667,  0.54166667,  0.79661017,  1.        ],\n",
       "       [ 0.66666667,  0.41666667,  0.71186441,  0.91666667],\n",
       "       [ 0.55555556,  0.20833333,  0.6779661 ,  0.75      ],\n",
       "       [ 0.61111111,  0.41666667,  0.71186441,  0.79166667],\n",
       "       [ 0.52777778,  0.58333333,  0.74576271,  0.91666667],\n",
       "       [ 0.44444444,  0.41666667,  0.69491525,  0.70833333]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0, -1,  0,  0,  0,  0,  0,  0,  0,  0,  1,\n",
       "        1,  1,  1,  1,  1,  1, -1,  1,  1, -1,  1,  1,  1,  1,  1,  1,  1,\n",
       "       -1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1, -1,  1,  1,  1,  1,  1, -1,  1,  1,  1,  1, -1,  1,  1,  1,\n",
       "        1,  1,  1, -1, -1,  1, -1, -1,  1,  1,  1,  1,  1,  1,  1, -1, -1,\n",
       "        1,  1,  1, -1,  1,  1,  1,  1,  1,  1,  1,  1, -1,  1,  1, -1, -1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1], dtype=int64)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbscanner.fit_predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen, in order to have access for each object's output, one needs to call different methods. So as to offer a homogeneous interface a collection of adapters is available in PipeGraph. Them all derive from the ```AdapterForSkLearnLikeAdaptee``` baseclass. This class is an adapter for Scikit-Learn objects in order to provide a common interface based on fit and predict methods irrespectively of whether the adapted object provided a ```transform```, ```fit_predict```, or ```predict interface```.\n",
    "\n",
    "As it can be seen from the following code fragment, the ```fit``` and ```predict``` allow for an arbitrary number of positional and keyword based parameters. These will have to be coherent with the adaptees expectations, but at least we are not imposing hard constrains to the adapter's interface.\n",
    "```\n",
    "class AdapterForSkLearnLikeAdaptee(BaseEstimator):\n",
    "    def fit(self, *pargs, **kwargs):\n",
    "       ...\n",
    "    def predict(self, *pargs, **kwargs):\n",
    "       ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those sklearn objects following the ```predict``` protocol can be wrapped into the class ```AdapterForFitPredictAdaptee```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predict': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'predict_log_proba': array([[  0.00000000e+00,  -4.11208597e+01,  -5.78855367e+01],\n",
       "        [  0.00000000e+00,  -3.87505119e+01,  -5.67328319e+01],\n",
       "        [  0.00000000e+00,  -4.13716038e+01,  -5.90125166e+01],\n",
       "        [  0.00000000e+00,  -3.87801966e+01,  -5.65000742e+01],\n",
       "        [  0.00000000e+00,  -4.22118362e+01,  -5.87821546e+01],\n",
       "        [ -1.50990331e-14,  -3.18135483e+01,  -4.77671483e+01],\n",
       "        [  0.00000000e+00,  -3.90168287e+01,  -5.65377225e+01],\n",
       "        [  0.00000000e+00,  -3.95630818e+01,  -5.65385104e+01],\n",
       "        [  0.00000000e+00,  -3.92358214e+01,  -5.74109854e+01],\n",
       "        [  0.00000000e+00,  -4.02823057e+01,  -5.74425024e+01],\n",
       "        [  0.00000000e+00,  -3.99448015e+01,  -5.59171461e+01],\n",
       "        [  0.00000000e+00,  -3.86387316e+01,  -5.55841702e+01],\n",
       "        [  0.00000000e+00,  -4.12723776e+01,  -5.87465451e+01],\n",
       "        [  0.00000000e+00,  -4.40508700e+01,  -6.15933405e+01],\n",
       "        [  0.00000000e+00,  -4.28003869e+01,  -5.76999890e+01],\n",
       "        [  0.00000000e+00,  -3.79878625e+01,  -5.24073850e+01],\n",
       "        [  0.00000000e+00,  -3.74032812e+01,  -5.36851061e+01],\n",
       "        [  0.00000000e+00,  -3.82599527e+01,  -5.54298023e+01],\n",
       "        [ -6.21724894e-15,  -3.27019712e+01,  -4.82934105e+01],\n",
       "        [  0.00000000e+00,  -3.92554439e+01,  -5.56035585e+01],\n",
       "        [ -1.11022302e-15,  -3.44179443e+01,  -5.09302471e+01],\n",
       "        [ -6.66133815e-16,  -3.49854914e+01,  -5.18673121e+01],\n",
       "        [  0.00000000e+00,  -4.53524369e+01,  -6.21630580e+01],\n",
       "        [ -1.88369320e-11,  -2.46951950e+01,  -4.25029624e+01],\n",
       "        [ -9.76996262e-15,  -3.22509844e+01,  -4.88549336e+01],\n",
       "        [ -4.44089210e-16,  -3.56240088e+01,  -5.34064744e+01],\n",
       "        [ -1.75415238e-14,  -3.16706208e+01,  -4.92423246e+01],\n",
       "        [  0.00000000e+00,  -3.94504986e+01,  -5.60776068e+01],\n",
       "        [  0.00000000e+00,  -4.00193970e+01,  -5.69598553e+01],\n",
       "        [  0.00000000e+00,  -3.76183937e+01,  -5.50322019e+01],\n",
       "        [  0.00000000e+00,  -3.67922627e+01,  -5.44175592e+01],\n",
       "        [ -2.19824159e-14,  -3.14495987e+01,  -4.88361191e+01],\n",
       "        [  0.00000000e+00,  -4.64777463e+01,  -6.10323244e+01],\n",
       "        [  0.00000000e+00,  -4.48894830e+01,  -5.95103654e+01],\n",
       "        [  0.00000000e+00,  -4.02823057e+01,  -5.74425024e+01],\n",
       "        [  0.00000000e+00,  -4.11737926e+01,  -5.87969507e+01],\n",
       "        [  0.00000000e+00,  -4.01390763e+01,  -5.66409002e+01],\n",
       "        [  0.00000000e+00,  -4.02823057e+01,  -5.74425024e+01],\n",
       "        [  0.00000000e+00,  -4.07096317e+01,  -5.87377123e+01],\n",
       "        [  0.00000000e+00,  -3.91876179e+01,  -5.61142420e+01],\n",
       "        [  0.00000000e+00,  -3.95937603e+01,  -5.68754065e+01],\n",
       "        [ -8.88178420e-16,  -3.48281190e+01,  -5.46456650e+01],\n",
       "        [  0.00000000e+00,  -4.18405880e+01,  -5.94319738e+01],\n",
       "        [ -6.24451602e-11,  -2.34967248e+01,  -4.10128301e+01],\n",
       "        [ -8.14459611e-13,  -2.78361426e+01,  -4.40338704e+01],\n",
       "        [ -2.22044605e-16,  -3.61774145e+01,  -5.45875862e+01],\n",
       "        [  0.00000000e+00,  -4.05725544e+01,  -5.64270855e+01],\n",
       "        [  0.00000000e+00,  -4.06134153e+01,  -5.81878898e+01],\n",
       "        [  0.00000000e+00,  -4.04517469e+01,  -5.65120841e+01],\n",
       "        [  0.00000000e+00,  -4.01653212e+01,  -5.74485852e+01],\n",
       "        [ -2.48052568e+02,  -2.18109163e-01,  -1.62983281e+00],\n",
       "        [ -2.30738394e+02,  -5.63908550e-02,  -2.90351121e+00],\n",
       "        [ -2.80491279e+02,  -7.84930690e-01,  -6.09084226e-01],\n",
       "        [ -1.60415501e+02,  -3.12493439e-05,  -1.03735278e+01],\n",
       "        [ -2.44173908e+02,  -4.87262645e-02,  -3.04580129e+00],\n",
       "        [ -2.06975902e+02,  -8.80760321e-04,  -7.03516537e+00],\n",
       "        [ -2.61492267e+02,  -4.17104153e-01,  -1.07573288e+00],\n",
       "        [ -7.81077843e+01,  -2.33206936e-07,  -1.52713398e+01],\n",
       "        [ -2.24546277e+02,  -9.73088268e-03,  -4.63731216e+00],\n",
       "        [ -1.58620033e+02,  -9.02576814e-05,  -9.31288698e+00],\n",
       "        [ -9.34195242e+01,  -2.35068255e-07,  -1.52633900e+01],\n",
       "        [ -1.98308513e+02,  -3.76880673e-03,  -5.58288066e+00],\n",
       "        [ -1.38601134e+02,  -6.01634294e-06,  -1.20210340e+01],\n",
       "        [ -2.40199046e+02,  -1.40068145e-02,  -4.27520655e+00],\n",
       "        [ -1.26096900e+02,  -2.46129435e-05,  -1.06122504e+01],\n",
       "        [ -2.13966954e+02,  -2.01649503e-02,  -3.91387485e+00],\n",
       "        [ -2.25487740e+02,  -9.35636191e-03,  -4.67637328e+00],\n",
       "        [ -1.44223302e+02,  -1.63374144e-05,  -1.10220609e+01],\n",
       "        [ -2.33161854e+02,  -5.31700240e-03,  -5.23950292e+00],\n",
       "        [ -1.34144688e+02,  -6.99366761e-06,  -1.18705089e+01],\n",
       "        [ -2.95027181e+02,  -1.86759947e+00,  -1.67820115e-01],\n",
       "        [ -1.62730156e+02,  -1.92992469e-04,  -8.55295589e+00],\n",
       "        [ -2.76246088e+02,  -7.57185971e-02,  -2.61835190e+00],\n",
       "        [ -2.21783330e+02,  -1.84518185e-03,  -6.29609989e+00],\n",
       "        [ -1.92417591e+02,  -1.54036992e-03,  -6.47650277e+00],\n",
       "        [ -2.13431507e+02,  -1.26080671e-02,  -4.37971584e+00],\n",
       "        [ -2.58592703e+02,  -9.11897920e-02,  -2.44006076e+00],\n",
       "        [ -3.14700239e+02,  -2.58668517e+00,  -7.82525369e-02],\n",
       "        [ -2.28824133e+02,  -1.36119554e-02,  -4.30360506e+00],\n",
       "        [ -9.51756427e+01,  -1.23794287e-06,  -1.36020601e+01],\n",
       "        [ -1.25622344e+02,  -3.55252462e-06,  -1.25478538e+01],\n",
       "        [ -1.09762853e+02,  -1.34924015e-06,  -1.35159697e+01],\n",
       "        [ -1.43170407e+02,  -2.76527750e-05,  -1.04957983e+01],\n",
       "        [ -3.07586574e+02,  -4.90761846e-01,  -9.47161995e-01],\n",
       "        [ -2.24340564e+02,  -7.55180548e-03,  -4.88974213e+00],\n",
       "        [ -2.37042011e+02,  -1.32266420e-01,  -2.08834144e+00],\n",
       "        [ -2.55530691e+02,  -2.24025500e-01,  -1.60591787e+00],\n",
       "        [ -2.03604220e+02,  -6.14771461e-04,  -7.39456734e+00],\n",
       "        [ -1.66964124e+02,  -2.03750870e-04,  -8.49871441e+00],\n",
       "        [ -1.59751333e+02,  -4.47674653e-05,  -1.00140513e+01],\n",
       "        [ -1.87444075e+02,  -1.26328301e-04,  -8.97668964e+00],\n",
       "        [ -2.29061946e+02,  -1.06854191e-02,  -4.54421312e+00],\n",
       "        [ -1.52155085e+02,  -3.37718907e-05,  -1.02958986e+01],\n",
       "        [ -7.87548415e+01,  -2.02487942e-07,  -1.54125856e+01],\n",
       "        [ -1.77565145e+02,  -1.67685437e-04,  -8.69350458e+00],\n",
       "        [ -1.67627763e+02,  -1.50136407e-04,  -8.80404136e+00],\n",
       "        [ -1.77272780e+02,  -2.85093986e-04,  -8.16283420e+00],\n",
       "        [ -1.90570452e+02,  -1.00814508e-03,  -6.90014722e+00],\n",
       "        [ -6.76595831e+01,  -2.31316924e-07,  -1.52794772e+01],\n",
       "        [ -1.68600092e+02,  -1.52851668e-04,  -8.78611902e+00],\n",
       "        [ -5.76528695e+02,  -2.34793813e+01,  -6.35380637e-11],\n",
       "        [ -3.46079221e+02,  -3.68839303e+00,  -2.53302835e-02],\n",
       "        [ -5.01915316e+02,  -1.55998057e+01,  -1.67915395e-07],\n",
       "        [ -4.02192362e+02,  -6.21729985e+00,  -1.99661565e-03],\n",
       "        [ -4.95383744e+02,  -1.52828267e+01,  -2.30543434e-07],\n",
       "        [ -6.22492812e+02,  -2.21463196e+01,  -2.40977016e-10],\n",
       "        [ -2.47154107e+02,  -2.68427191e-02,  -3.63115200e+00],\n",
       "        [ -5.21888447e+02,  -1.35227055e+01,  -1.34018237e-06],\n",
       "        [ -4.36746429e+02,  -7.61520062e+00,  -4.93023301e-04],\n",
       "        [ -6.03094508e+02,  -2.72904971e+01,  -1.40598644e-12],\n",
       "        [ -3.67126147e+02,  -7.79234360e+00,  -4.12969376e-04],\n",
       "        [ -3.77747570e+02,  -5.88623220e+00,  -2.78128597e-03],\n",
       "        [ -4.40168625e+02,  -1.22454127e+01,  -4.80713017e-06],\n",
       "        [ -3.48586297e+02,  -4.35202467e+00,  -1.29643826e-02],\n",
       "        [ -4.29571255e+02,  -1.37738535e+01,  -1.04253739e-06],\n",
       "        [ -4.41726495e+02,  -1.46119054e+01,  -4.50951887e-07],\n",
       "        [ -3.90421773e+02,  -6.28076617e+00,  -1.87372012e-03],\n",
       "        [ -6.54914190e+02,  -2.71328253e+01,  -1.64490643e-12],\n",
       "        [ -7.12254776e+02,  -2.80658015e+01,  -6.47482068e-13],\n",
       "        [ -2.86083201e+02,  -4.27662147e-02,  -3.17331377e+00],\n",
       "        [ -5.03186707e+02,  -1.82626784e+01,  -1.17116898e-08],\n",
       "        [ -3.35138824e+02,  -4.28580072e+00,  -1.38581796e-02],\n",
       "        [ -6.26187694e+02,  -2.10000206e+01,  -7.58240581e-10],\n",
       "        [ -3.12323599e+02,  -2.04032292e+00,  -1.39246813e-01],\n",
       "        [ -4.65698806e+02,  -1.38441385e+01,  -9.71778424e-07],\n",
       "        [ -4.72166196e+02,  -1.18141630e+01,  -7.39904730e-06],\n",
       "        [ -2.99339133e+02,  -1.60979688e+00,  -2.23053830e-01],\n",
       "        [ -3.09308365e+02,  -2.23041763e+00,  -1.13710314e-01],\n",
       "        [ -4.49376980e+02,  -1.14224651e+01,  -1.09468413e-05],\n",
       "        [ -4.16289573e+02,  -7.26185395e+00,  -7.02052098e-04],\n",
       "        [ -5.06724696e+02,  -1.39139634e+01,  -9.06238851e-07],\n",
       "        [ -5.75425351e+02,  -2.19381967e+01,  -2.96730640e-10],\n",
       "        [ -4.66130391e+02,  -1.34048044e+01,  -1.50788342e-06],\n",
       "        [ -2.98548520e+02,  -3.38771676e-01,  -1.24703740e+00],\n",
       "        [ -3.50990031e+02,  -7.21136687e-01,  -6.65919804e-01],\n",
       "        [ -5.77189946e+02,  -2.31327920e+01,  -8.98578989e-11],\n",
       "        [ -4.98648138e+02,  -1.88379419e+01,  -6.58848798e-09],\n",
       "        [ -3.88867859e+02,  -6.26470421e+00,  -1.90408763e-03],\n",
       "        [ -2.96704559e+02,  -1.64411292e+00,  -2.14659463e-01],\n",
       "        [ -4.27739492e+02,  -1.21608575e+01,  -5.23127826e-06],\n",
       "        [ -5.04811435e+02,  -1.91109390e+01,  -5.01446573e-09],\n",
       "        [ -4.23198845e+02,  -1.45752291e+01,  -4.67798162e-07],\n",
       "        [ -3.46079221e+02,  -3.68839303e+00,  -2.53302835e-02],\n",
       "        [ -5.30964877e+02,  -1.92358690e+01,  -4.42555992e-09],\n",
       "        [ -5.37227545e+02,  -2.25274865e+01,  -1.64602554e-10],\n",
       "        [ -4.33320275e+02,  -1.43507861e+01,  -5.85508133e-07],\n",
       "        [ -3.39139040e+02,  -3.67120606e+00,  -2.57751046e-02],\n",
       "        [ -3.80448261e+02,  -7.90155668e+00,  -3.70235390e-04],\n",
       "        [ -4.51888911e+02,  -1.52178512e+01,  -2.46020464e-07],\n",
       "        [ -3.31662328e+02,  -2.88231414e+00,  -5.76344191e-02]]),\n",
       " 'predict_proba': array([[  1.00000000e+000,   1.38496103e-018,   7.25489025e-026],\n",
       "        [  1.00000000e+000,   1.48206242e-017,   2.29743996e-025],\n",
       "        [  1.00000000e+000,   1.07780639e-018,   2.35065917e-026],\n",
       "        [  1.00000000e+000,   1.43871443e-017,   2.89954283e-025],\n",
       "        [  1.00000000e+000,   4.65192224e-019,   2.95961100e-026],\n",
       "        [  1.00000000e+000,   1.52598944e-014,   1.79883402e-021],\n",
       "        [  1.00000000e+000,   1.13555084e-017,   2.79240943e-025],\n",
       "        [  1.00000000e+000,   6.57615274e-018,   2.79021029e-025],\n",
       "        [  1.00000000e+000,   9.12219356e-018,   1.16607332e-025],\n",
       "        [  1.00000000e+000,   3.20344249e-018,   1.12989524e-025],\n",
       "        [  1.00000000e+000,   4.48944985e-018,   5.19388089e-025],\n",
       "        [  1.00000000e+000,   1.65734172e-017,   7.24605453e-025],\n",
       "        [  1.00000000e+000,   1.19023891e-018,   3.06690017e-026],\n",
       "        [  1.00000000e+000,   7.39520546e-020,   1.77972179e-027],\n",
       "        [  1.00000000e+000,   2.58242749e-019,   8.73399972e-026],\n",
       "        [  1.00000000e+000,   3.17746623e-017,   1.73684833e-023],\n",
       "        [  1.00000000e+000,   5.70113578e-017,   4.84010372e-024],\n",
       "        [  1.00000000e+000,   2.42054769e-017,   8.45556661e-025],\n",
       "        [  1.00000000e+000,   6.27645419e-015,   1.06276762e-021],\n",
       "        [  1.00000000e+000,   8.94493797e-018,   7.10691894e-025],\n",
       "        [  1.00000000e+000,   1.12843548e-015,   7.60807373e-023],\n",
       "        [  1.00000000e+000,   6.39726172e-016,   2.98066089e-023],\n",
       "        [  1.00000000e+000,   2.01227309e-020,   1.00676223e-027],\n",
       "        [  1.00000000e+000,   1.88370574e-011,   3.47694606e-019],\n",
       "        [  1.00000000e+000,   9.85315738e-015,   6.06138600e-022],\n",
       "        [  1.00000000e+000,   3.37823264e-016,   6.39532840e-024],\n",
       "        [  1.00000000e+000,   1.76045187e-014,   4.11462407e-022],\n",
       "        [  1.00000000e+000,   7.35980232e-018,   4.42389485e-025],\n",
       "        [  1.00000000e+000,   4.16674318e-018,   1.83083484e-025],\n",
       "        [  1.00000000e+000,   4.59768498e-017,   1.25839903e-024],\n",
       "        [  1.00000000e+000,   1.05032415e-016,   2.32677467e-024],\n",
       "        [  1.00000000e+000,   2.19590125e-014,   6.17650711e-022],\n",
       "        [  1.00000000e+000,   6.53087316e-021,   3.11887725e-027],\n",
       "        [  1.00000000e+000,   3.19701924e-020,   1.42881733e-026],\n",
       "        [  1.00000000e+000,   3.20344249e-018,   1.12989524e-025],\n",
       "        [  1.00000000e+000,   1.31355747e-018,   2.91614269e-026],\n",
       "        [  1.00000000e+000,   3.69675482e-018,   2.51866027e-025],\n",
       "        [  1.00000000e+000,   3.20344249e-018,   1.12989524e-025],\n",
       "        [  1.00000000e+000,   2.08944813e-018,   3.09410939e-026],\n",
       "        [  1.00000000e+000,   9.57268514e-018,   4.26475768e-025],\n",
       "        [  1.00000000e+000,   6.37746927e-018,   1.99216264e-025],\n",
       "        [  1.00000000e+000,   7.48755609e-016,   1.85220582e-024],\n",
       "        [  1.00000000e+000,   6.74316102e-019,   1.54533175e-026],\n",
       "        [  1.00000000e+000,   6.24456357e-011,   1.54295833e-018],\n",
       "        [  1.00000000e+000,   8.14548341e-013,   7.52199540e-020],\n",
       "        [  1.00000000e+000,   1.94244394e-016,   1.96296487e-024],\n",
       "        [  1.00000000e+000,   2.39642309e-018,   3.11909164e-025],\n",
       "        [  1.00000000e+000,   2.30047669e-018,   5.36192288e-026],\n",
       "        [  1.00000000e+000,   2.70414239e-018,   2.86492790e-025],\n",
       "        [  1.00000000e+000,   3.60099614e-018,   1.12304319e-025],\n",
       "        [  1.87127931e-108,   8.04037666e-001,   1.95962334e-001],\n",
       "        [  6.18854779e-101,   9.45169639e-001,   5.48303606e-002],\n",
       "        [  1.52821825e-122,   4.56151317e-001,   5.43848683e-001],\n",
       "        [  2.14997261e-070,   9.99968751e-001,   3.12488556e-005],\n",
       "        [  9.04938222e-107,   9.52441811e-001,   4.75581888e-002],\n",
       "        [  1.29272979e-090,   9.99119627e-001,   8.80372565e-004],\n",
       "        [  2.72490532e-114,   6.58952285e-001,   3.41047715e-001],\n",
       "        [  1.19734767e-034,   9.99999767e-001,   2.33206910e-007],\n",
       "        [  3.02545627e-098,   9.90316309e-001,   9.68369084e-003],\n",
       "        [  1.29477666e-069,   9.99909746e-001,   9.02536083e-005],\n",
       "        [  2.68173680e-041,   9.99999765e-001,   2.35068227e-007],\n",
       "        [  7.51115851e-087,   9.96238286e-001,   3.76171369e-003],\n",
       "        [  6.40165546e-061,   9.99993984e-001,   6.01632484e-006],\n",
       "        [  4.81814146e-105,   9.86090825e-001,   1.39091754e-002],\n",
       "        [  1.72509107e-055,   9.99975387e-001,   2.46126406e-005],\n",
       "        [  1.18941242e-093,   9.80037003e-001,   1.99629974e-002],\n",
       "        [  1.18009940e-098,   9.90687273e-001,   9.31272734e-003],\n",
       "        [  2.31534504e-063,   9.99983663e-001,   1.63372809e-005],\n",
       "        [  5.48394976e-102,   9.94697108e-001,   5.30289217e-003],\n",
       "        [  5.51699136e-059,   9.99993006e-001,   6.99364316e-006],\n",
       "        [  7.43572418e-129,   1.54494085e-001,   8.45505915e-001],\n",
       "        [  2.12417952e-071,   9.99807026e-001,   1.92973847e-004],\n",
       "        [  1.06622383e-120,   9.27077052e-001,   7.29229479e-002],\n",
       "        [  4.79428037e-097,   9.98156519e-001,   1.84348055e-003],\n",
       "        [  2.71707817e-084,   9.98460816e-001,   1.53918416e-003],\n",
       "        [  2.03176962e-093,   9.87471082e-001,   1.25289184e-002],\n",
       "        [  4.95012220e-113,   9.12844444e-001,   8.71555561e-002],\n",
       "        [  2.12531216e-137,   7.52691316e-002,   9.24730868e-001],\n",
       "        [  4.19702663e-100,   9.86480268e-001,   1.35197316e-002],\n",
       "        [  4.63173354e-042,   9.99998762e-001,   1.23794211e-006],\n",
       "        [  2.77274013e-055,   9.99996447e-001,   3.55251831e-006],\n",
       "        [  2.14091116e-048,   9.99998651e-001,   1.34923924e-006],\n",
       "        [  6.63563094e-063,   9.99972348e-001,   2.76523927e-005],\n",
       "        [  2.61124821e-134,   6.12159845e-001,   3.87840155e-001],\n",
       "        [  3.71647418e-098,   9.92476638e-001,   7.52336224e-003],\n",
       "        [  1.13230275e-103,   8.76107551e-001,   1.23892449e-001],\n",
       "        [  1.05786721e-111,   7.99294752e-001,   2.00705248e-001],\n",
       "        [  3.76539608e-089,   9.99385417e-001,   6.14582528e-004],\n",
       "        [  3.07894878e-073,   9.99796270e-001,   2.03730114e-004],\n",
       "        [  4.17712661e-070,   9.99955234e-001,   4.47664632e-005],\n",
       "        [  3.92710689e-082,   9.99873680e-001,   1.26320322e-004],\n",
       "        [  3.30872742e-100,   9.89371467e-001,   1.06285328e-002],\n",
       "        [  8.31545615e-067,   9.99966229e-001,   3.37713204e-005],\n",
       "        [  6.26912483e-035,   9.99999798e-001,   2.02487922e-007],\n",
       "        [  7.66367658e-078,   9.99832329e-001,   1.67671378e-004],\n",
       "        [  1.58557717e-073,   9.99849875e-001,   1.50125137e-004],\n",
       "        [  1.02662082e-077,   9.99714947e-001,   2.85053350e-004],\n",
       "        [  1.72307593e-083,   9.98992363e-001,   1.00763708e-003],\n",
       "        [  4.12872931e-030,   9.99999769e-001,   2.31316897e-007],\n",
       "        [  5.99667528e-074,   9.99847160e-001,   1.52839987e-004],\n",
       "        [  4.13779546e-251,   6.35381030e-011,   1.00000000e+000],\n",
       "        [  5.00845630e-151,   2.50121636e-002,   9.74987836e-001],\n",
       "        [  1.04941686e-218,   1.67915381e-007,   9.99999832e-001],\n",
       "        [  2.13833836e-175,   1.99462374e-003,   9.98005376e-001],\n",
       "        [  7.20399720e-216,   2.30543407e-007,   9.99999769e-001],\n",
       "        [  4.51654712e-271,   2.40976994e-010,   1.00000000e+000],\n",
       "        [  4.59552511e-108,   9.73514345e-001,   2.64856553e-002],\n",
       "        [  2.22191497e-227,   1.34018147e-006,   9.99998660e-001],\n",
       "        [  2.10589122e-190,   4.92901785e-004,   9.99507098e-001],\n",
       "        [  1.20055778e-262,   1.40568402e-012,   1.00000000e+000],\n",
       "        [  3.62359789e-160,   4.12884115e-004,   9.99587116e-001],\n",
       "        [  8.83719953e-165,   2.77742178e-003,   9.97222578e-001],\n",
       "        [  6.87376950e-192,   4.80711862e-006,   9.99995193e-001],\n",
       "        [  4.08220498e-152,   1.28807070e-002,   9.87119293e-001],\n",
       "        [  2.75153031e-187,   1.04253685e-006,   9.99998957e-001],\n",
       "        [  1.44750671e-192,   4.50951786e-007,   9.99999549e-001],\n",
       "        [  2.76680341e-170,   1.87196580e-003,   9.98128034e-001],\n",
       "        [  3.75302289e-285,   1.64574932e-012,   1.00000000e+000],\n",
       "        [  4.69548986e-310,   6.47406861e-013,   1.00000000e+000],\n",
       "        [  5.69697725e-125,   9.58135362e-001,   4.18646381e-002],\n",
       "        [  2.94299535e-219,   1.17116897e-008,   9.99999988e-001],\n",
       "        [  2.82525894e-146,   1.37625971e-002,   9.86237403e-001],\n",
       "        [  1.12237933e-272,   7.58240410e-010,   9.99999999e-001],\n",
       "        [  2.28867567e-136,   1.29986728e-001,   8.70013272e-001],\n",
       "        [  5.61795825e-203,   9.71777952e-007,   9.99999028e-001],\n",
       "        [  8.72622664e-206,   7.39901993e-006,   9.99992601e-001],\n",
       "        [  9.96933448e-131,   1.99928220e-001,   8.00071780e-001],\n",
       "        [  4.66749613e-135,   1.07483532e-001,   8.92516468e-001],\n",
       "        [  6.88743059e-196,   1.09467814e-005,   9.99989053e-001],\n",
       "        [  1.61337601e-181,   7.01805717e-004,   9.99298194e-001],\n",
       "        [  8.55580252e-221,   9.06238440e-007,   9.99999094e-001],\n",
       "        [  1.24722670e-250,   2.96730515e-010,   1.00000000e+000],\n",
       "        [  3.64874362e-203,   1.50788229e-006,   9.99998492e-001],\n",
       "        [  2.19798649e-130,   7.12645144e-001,   2.87354856e-001],\n",
       "        [  3.68949024e-153,   4.86199285e-001,   5.13800715e-001],\n",
       "        [  2.13595212e-251,   8.98578645e-011,   1.00000000e+000],\n",
       "        [  2.75337356e-217,   6.58848819e-009,   9.99999993e-001],\n",
       "        [  1.30868299e-169,   1.90227600e-003,   9.98097724e-001],\n",
       "        [  1.38946382e-129,   1.93183856e-001,   8.06816144e-001],\n",
       "        [  1.71830037e-186,   5.23126458e-006,   9.99994769e-001],\n",
       "        [  5.79667973e-220,   5.01446575e-009,   9.99999995e-001],\n",
       "        [  1.61093140e-184,   4.67798053e-007,   9.99999532e-001],\n",
       "        [  5.00845630e-151,   2.50121636e-002,   9.74987836e-001],\n",
       "        [  2.54029381e-231,   4.42556022e-009,   9.99999996e-001],\n",
       "        [  4.84219075e-234,   1.64602693e-010,   1.00000000e+000],\n",
       "        [  6.47732320e-189,   5.85507961e-007,   9.99999414e-001],\n",
       "        [  5.17352411e-148,   2.54457623e-002,   9.74554238e-001],\n",
       "        [  5.93498263e-166,   3.70166861e-004,   9.99629833e-001],\n",
       "        [  5.58649523e-197,   2.46020434e-007,   9.99999754e-001],\n",
       "        [  9.13863414e-145,   5.60050091e-002,   9.43994991e-001]])}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pipegraph.adapters import AdapterForFitPredictAdaptee\n",
    "\n",
    "wrapped_classifier = AdapterForFitPredictAdaptee(classifier)\n",
    "y_pred = wrapped_classifier.predict(X=X)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the wrapper provides its output as a dictionary containing the outputs provided by ```predict```, ```predict_proba```, and ```predict_log_proba``` where these methods are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['predict', 'predict_proba', 'predict_log_proba']"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(y_pred.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those sklearn objects following the ```transform``` protocol can be wrapped into the class ```AdapterForFitTransformAdaptee```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predict': array([[ 0.22222222,  0.625     ,  0.06779661,  0.04166667],\n",
       "        [ 0.16666667,  0.41666667,  0.06779661,  0.04166667],\n",
       "        [ 0.11111111,  0.5       ,  0.05084746,  0.04166667],\n",
       "        [ 0.08333333,  0.45833333,  0.08474576,  0.04166667],\n",
       "        [ 0.19444444,  0.66666667,  0.06779661,  0.04166667],\n",
       "        [ 0.30555556,  0.79166667,  0.11864407,  0.125     ],\n",
       "        [ 0.08333333,  0.58333333,  0.06779661,  0.08333333],\n",
       "        [ 0.19444444,  0.58333333,  0.08474576,  0.04166667],\n",
       "        [ 0.02777778,  0.375     ,  0.06779661,  0.04166667],\n",
       "        [ 0.16666667,  0.45833333,  0.08474576,  0.        ],\n",
       "        [ 0.30555556,  0.70833333,  0.08474576,  0.04166667],\n",
       "        [ 0.13888889,  0.58333333,  0.10169492,  0.04166667],\n",
       "        [ 0.13888889,  0.41666667,  0.06779661,  0.        ],\n",
       "        [ 0.        ,  0.41666667,  0.01694915,  0.        ],\n",
       "        [ 0.41666667,  0.83333333,  0.03389831,  0.04166667],\n",
       "        [ 0.38888889,  1.        ,  0.08474576,  0.125     ],\n",
       "        [ 0.30555556,  0.79166667,  0.05084746,  0.125     ],\n",
       "        [ 0.22222222,  0.625     ,  0.06779661,  0.08333333],\n",
       "        [ 0.38888889,  0.75      ,  0.11864407,  0.08333333],\n",
       "        [ 0.22222222,  0.75      ,  0.08474576,  0.08333333],\n",
       "        [ 0.30555556,  0.58333333,  0.11864407,  0.04166667],\n",
       "        [ 0.22222222,  0.70833333,  0.08474576,  0.125     ],\n",
       "        [ 0.08333333,  0.66666667,  0.        ,  0.04166667],\n",
       "        [ 0.22222222,  0.54166667,  0.11864407,  0.16666667],\n",
       "        [ 0.13888889,  0.58333333,  0.15254237,  0.04166667],\n",
       "        [ 0.19444444,  0.41666667,  0.10169492,  0.04166667],\n",
       "        [ 0.19444444,  0.58333333,  0.10169492,  0.125     ],\n",
       "        [ 0.25      ,  0.625     ,  0.08474576,  0.04166667],\n",
       "        [ 0.25      ,  0.58333333,  0.06779661,  0.04166667],\n",
       "        [ 0.11111111,  0.5       ,  0.10169492,  0.04166667],\n",
       "        [ 0.13888889,  0.45833333,  0.10169492,  0.04166667],\n",
       "        [ 0.30555556,  0.58333333,  0.08474576,  0.125     ],\n",
       "        [ 0.25      ,  0.875     ,  0.08474576,  0.        ],\n",
       "        [ 0.33333333,  0.91666667,  0.06779661,  0.04166667],\n",
       "        [ 0.16666667,  0.45833333,  0.08474576,  0.        ],\n",
       "        [ 0.19444444,  0.5       ,  0.03389831,  0.04166667],\n",
       "        [ 0.33333333,  0.625     ,  0.05084746,  0.04166667],\n",
       "        [ 0.16666667,  0.45833333,  0.08474576,  0.        ],\n",
       "        [ 0.02777778,  0.41666667,  0.05084746,  0.04166667],\n",
       "        [ 0.22222222,  0.58333333,  0.08474576,  0.04166667],\n",
       "        [ 0.19444444,  0.625     ,  0.05084746,  0.08333333],\n",
       "        [ 0.05555556,  0.125     ,  0.05084746,  0.08333333],\n",
       "        [ 0.02777778,  0.5       ,  0.05084746,  0.04166667],\n",
       "        [ 0.19444444,  0.625     ,  0.10169492,  0.20833333],\n",
       "        [ 0.22222222,  0.75      ,  0.15254237,  0.125     ],\n",
       "        [ 0.13888889,  0.41666667,  0.06779661,  0.08333333],\n",
       "        [ 0.22222222,  0.75      ,  0.10169492,  0.04166667],\n",
       "        [ 0.08333333,  0.5       ,  0.06779661,  0.04166667],\n",
       "        [ 0.27777778,  0.70833333,  0.08474576,  0.04166667],\n",
       "        [ 0.19444444,  0.54166667,  0.06779661,  0.04166667],\n",
       "        [ 0.75      ,  0.5       ,  0.62711864,  0.54166667],\n",
       "        [ 0.58333333,  0.5       ,  0.59322034,  0.58333333],\n",
       "        [ 0.72222222,  0.45833333,  0.66101695,  0.58333333],\n",
       "        [ 0.33333333,  0.125     ,  0.50847458,  0.5       ],\n",
       "        [ 0.61111111,  0.33333333,  0.61016949,  0.58333333],\n",
       "        [ 0.38888889,  0.33333333,  0.59322034,  0.5       ],\n",
       "        [ 0.55555556,  0.54166667,  0.62711864,  0.625     ],\n",
       "        [ 0.16666667,  0.16666667,  0.38983051,  0.375     ],\n",
       "        [ 0.63888889,  0.375     ,  0.61016949,  0.5       ],\n",
       "        [ 0.25      ,  0.29166667,  0.49152542,  0.54166667],\n",
       "        [ 0.19444444,  0.        ,  0.42372881,  0.375     ],\n",
       "        [ 0.44444444,  0.41666667,  0.54237288,  0.58333333],\n",
       "        [ 0.47222222,  0.08333333,  0.50847458,  0.375     ],\n",
       "        [ 0.5       ,  0.375     ,  0.62711864,  0.54166667],\n",
       "        [ 0.36111111,  0.375     ,  0.44067797,  0.5       ],\n",
       "        [ 0.66666667,  0.45833333,  0.57627119,  0.54166667],\n",
       "        [ 0.36111111,  0.41666667,  0.59322034,  0.58333333],\n",
       "        [ 0.41666667,  0.29166667,  0.52542373,  0.375     ],\n",
       "        [ 0.52777778,  0.08333333,  0.59322034,  0.58333333],\n",
       "        [ 0.36111111,  0.20833333,  0.49152542,  0.41666667],\n",
       "        [ 0.44444444,  0.5       ,  0.6440678 ,  0.70833333],\n",
       "        [ 0.5       ,  0.33333333,  0.50847458,  0.5       ],\n",
       "        [ 0.55555556,  0.20833333,  0.66101695,  0.58333333],\n",
       "        [ 0.5       ,  0.33333333,  0.62711864,  0.45833333],\n",
       "        [ 0.58333333,  0.375     ,  0.55932203,  0.5       ],\n",
       "        [ 0.63888889,  0.41666667,  0.57627119,  0.54166667],\n",
       "        [ 0.69444444,  0.33333333,  0.6440678 ,  0.54166667],\n",
       "        [ 0.66666667,  0.41666667,  0.6779661 ,  0.66666667],\n",
       "        [ 0.47222222,  0.375     ,  0.59322034,  0.58333333],\n",
       "        [ 0.38888889,  0.25      ,  0.42372881,  0.375     ],\n",
       "        [ 0.33333333,  0.16666667,  0.47457627,  0.41666667],\n",
       "        [ 0.33333333,  0.16666667,  0.45762712,  0.375     ],\n",
       "        [ 0.41666667,  0.29166667,  0.49152542,  0.45833333],\n",
       "        [ 0.47222222,  0.29166667,  0.69491525,  0.625     ],\n",
       "        [ 0.30555556,  0.41666667,  0.59322034,  0.58333333],\n",
       "        [ 0.47222222,  0.58333333,  0.59322034,  0.625     ],\n",
       "        [ 0.66666667,  0.45833333,  0.62711864,  0.58333333],\n",
       "        [ 0.55555556,  0.125     ,  0.57627119,  0.5       ],\n",
       "        [ 0.36111111,  0.41666667,  0.52542373,  0.5       ],\n",
       "        [ 0.33333333,  0.20833333,  0.50847458,  0.5       ],\n",
       "        [ 0.33333333,  0.25      ,  0.57627119,  0.45833333],\n",
       "        [ 0.5       ,  0.41666667,  0.61016949,  0.54166667],\n",
       "        [ 0.41666667,  0.25      ,  0.50847458,  0.45833333],\n",
       "        [ 0.19444444,  0.125     ,  0.38983051,  0.375     ],\n",
       "        [ 0.36111111,  0.29166667,  0.54237288,  0.5       ],\n",
       "        [ 0.38888889,  0.41666667,  0.54237288,  0.45833333],\n",
       "        [ 0.38888889,  0.375     ,  0.54237288,  0.5       ],\n",
       "        [ 0.52777778,  0.375     ,  0.55932203,  0.5       ],\n",
       "        [ 0.22222222,  0.20833333,  0.33898305,  0.41666667],\n",
       "        [ 0.38888889,  0.33333333,  0.52542373,  0.5       ],\n",
       "        [ 0.55555556,  0.54166667,  0.84745763,  1.        ],\n",
       "        [ 0.41666667,  0.29166667,  0.69491525,  0.75      ],\n",
       "        [ 0.77777778,  0.41666667,  0.83050847,  0.83333333],\n",
       "        [ 0.55555556,  0.375     ,  0.77966102,  0.70833333],\n",
       "        [ 0.61111111,  0.41666667,  0.81355932,  0.875     ],\n",
       "        [ 0.91666667,  0.41666667,  0.94915254,  0.83333333],\n",
       "        [ 0.16666667,  0.20833333,  0.59322034,  0.66666667],\n",
       "        [ 0.83333333,  0.375     ,  0.89830508,  0.70833333],\n",
       "        [ 0.66666667,  0.20833333,  0.81355932,  0.70833333],\n",
       "        [ 0.80555556,  0.66666667,  0.86440678,  1.        ],\n",
       "        [ 0.61111111,  0.5       ,  0.69491525,  0.79166667],\n",
       "        [ 0.58333333,  0.29166667,  0.72881356,  0.75      ],\n",
       "        [ 0.69444444,  0.41666667,  0.76271186,  0.83333333],\n",
       "        [ 0.38888889,  0.20833333,  0.6779661 ,  0.79166667],\n",
       "        [ 0.41666667,  0.33333333,  0.69491525,  0.95833333],\n",
       "        [ 0.58333333,  0.5       ,  0.72881356,  0.91666667],\n",
       "        [ 0.61111111,  0.41666667,  0.76271186,  0.70833333],\n",
       "        [ 0.94444444,  0.75      ,  0.96610169,  0.875     ],\n",
       "        [ 0.94444444,  0.25      ,  1.        ,  0.91666667],\n",
       "        [ 0.47222222,  0.08333333,  0.6779661 ,  0.58333333],\n",
       "        [ 0.72222222,  0.5       ,  0.79661017,  0.91666667],\n",
       "        [ 0.36111111,  0.33333333,  0.66101695,  0.79166667],\n",
       "        [ 0.94444444,  0.33333333,  0.96610169,  0.79166667],\n",
       "        [ 0.55555556,  0.29166667,  0.66101695,  0.70833333],\n",
       "        [ 0.66666667,  0.54166667,  0.79661017,  0.83333333],\n",
       "        [ 0.80555556,  0.5       ,  0.84745763,  0.70833333],\n",
       "        [ 0.52777778,  0.33333333,  0.6440678 ,  0.70833333],\n",
       "        [ 0.5       ,  0.41666667,  0.66101695,  0.70833333],\n",
       "        [ 0.58333333,  0.33333333,  0.77966102,  0.83333333],\n",
       "        [ 0.80555556,  0.41666667,  0.81355932,  0.625     ],\n",
       "        [ 0.86111111,  0.33333333,  0.86440678,  0.75      ],\n",
       "        [ 1.        ,  0.75      ,  0.91525424,  0.79166667],\n",
       "        [ 0.58333333,  0.33333333,  0.77966102,  0.875     ],\n",
       "        [ 0.55555556,  0.33333333,  0.69491525,  0.58333333],\n",
       "        [ 0.5       ,  0.25      ,  0.77966102,  0.54166667],\n",
       "        [ 0.94444444,  0.41666667,  0.86440678,  0.91666667],\n",
       "        [ 0.55555556,  0.58333333,  0.77966102,  0.95833333],\n",
       "        [ 0.58333333,  0.45833333,  0.76271186,  0.70833333],\n",
       "        [ 0.47222222,  0.41666667,  0.6440678 ,  0.70833333],\n",
       "        [ 0.72222222,  0.45833333,  0.74576271,  0.83333333],\n",
       "        [ 0.66666667,  0.45833333,  0.77966102,  0.95833333],\n",
       "        [ 0.72222222,  0.45833333,  0.69491525,  0.91666667],\n",
       "        [ 0.41666667,  0.29166667,  0.69491525,  0.75      ],\n",
       "        [ 0.69444444,  0.5       ,  0.83050847,  0.91666667],\n",
       "        [ 0.66666667,  0.54166667,  0.79661017,  1.        ],\n",
       "        [ 0.66666667,  0.41666667,  0.71186441,  0.91666667],\n",
       "        [ 0.55555556,  0.20833333,  0.6779661 ,  0.75      ],\n",
       "        [ 0.61111111,  0.41666667,  0.71186441,  0.79166667],\n",
       "        [ 0.52777778,  0.58333333,  0.74576271,  0.91666667],\n",
       "        [ 0.44444444,  0.41666667,  0.69491525,  0.70833333]])}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pipegraph.adapters import AdapterForFitTransformAdaptee\n",
    "\n",
    "wrapped_scaler = AdapterForFitTransformAdaptee(scaler)\n",
    "y_pred=wrapped_scaler.predict(X)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The adapter for transformers doesn't have to provide so many methods' output, only the value provided by calling ```trasform``` method on the adaptee, which for homogeneity is provided as a dictionary with 'predict' as key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['predict']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(y_pred.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those sklearn objects following the ```fit_predict``` protocol can be wrapped into the class ```AdapterForAtomicFitPredictAdaptee```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predict': array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0, -1,  0,  0,  0,  0,  0,  0,  0,  0,  1,\n",
       "         1,  1,  1,  1,  1,  1, -1,  1,  1, -1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        -1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1, -1,  1,  1,  1,  1,  1, -1,  1,  1,  1,  1, -1,  1,  1,  1,\n",
       "         1,  1,  1, -1, -1,  1, -1, -1,  1,  1,  1,  1,  1,  1,  1, -1, -1,\n",
       "         1,  1,  1, -1,  1,  1,  1,  1,  1,  1,  1,  1, -1,  1,  1, -1, -1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1], dtype=int64)}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pipegraph.adapters import AdapterForAtomicFitPredictAdaptee\n",
    "\n",
    "wrapped_dbscanner = AdapterForAtomicFitPredictAdaptee(dbscanner)\n",
    "y_pred = wrapped_dbscanner.predict(X=X)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, this adapter provides a dictionary with the values of calling ```fit_predict``` under the key 'predict'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special wrappers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides of the three families of objects provided by Scikit-Learn, it is sometimes convenient to provide custom objects whose ```predict``` method returns multiple outputs. In this case, a dictionary can be used as well, with the name of the outputs as keys. In order to comply with this kind of output, the class ```AdapterForCustomFitPredictWithDictionaryOutputAdaptee``` is provided:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X_0':       0    1    2    3\n",
       " 0   5.1  3.5  1.4  0.2\n",
       " 1   4.9  3.0  1.4  0.2\n",
       " 2   4.7  3.2  1.3  0.2\n",
       " 3   4.6  3.1  1.5  0.2\n",
       " 4   5.0  3.6  1.4  0.2\n",
       " 5   5.4  3.9  1.7  0.4\n",
       " 6   4.6  3.4  1.4  0.3\n",
       " 7   5.0  3.4  1.5  0.2\n",
       " 8   4.4  2.9  1.4  0.2\n",
       " 9   4.9  3.1  1.5  0.1\n",
       " 10  5.4  3.7  1.5  0.2\n",
       " 11  4.8  3.4  1.6  0.2\n",
       " 12  4.8  3.0  1.4  0.1\n",
       " 13  4.3  3.0  1.1  0.1\n",
       " 14  5.8  4.0  1.2  0.2\n",
       " 15  5.7  4.4  1.5  0.4\n",
       " 16  5.4  3.9  1.3  0.4\n",
       " 17  5.1  3.5  1.4  0.3\n",
       " 18  5.7  3.8  1.7  0.3\n",
       " 19  5.1  3.8  1.5  0.3\n",
       " 20  5.4  3.4  1.7  0.2\n",
       " 21  5.1  3.7  1.5  0.4\n",
       " 22  4.6  3.6  1.0  0.2\n",
       " 23  5.1  3.3  1.7  0.5\n",
       " 24  4.8  3.4  1.9  0.2\n",
       " 25  5.0  3.0  1.6  0.2\n",
       " 26  5.0  3.4  1.6  0.4\n",
       " 27  5.2  3.5  1.5  0.2\n",
       " 28  5.2  3.4  1.4  0.2\n",
       " 29  4.7  3.2  1.6  0.2\n",
       " 30  4.8  3.1  1.6  0.2\n",
       " 31  5.4  3.4  1.5  0.4\n",
       " 32  5.2  4.1  1.5  0.1\n",
       " 33  5.5  4.2  1.4  0.2\n",
       " 34  4.9  3.1  1.5  0.1\n",
       " 35  5.0  3.2  1.2  0.2\n",
       " 36  5.5  3.5  1.3  0.2\n",
       " 37  4.9  3.1  1.5  0.1\n",
       " 38  4.4  3.0  1.3  0.2\n",
       " 39  5.1  3.4  1.5  0.2\n",
       " 40  5.0  3.5  1.3  0.3\n",
       " 41  4.5  2.3  1.3  0.3\n",
       " 42  4.4  3.2  1.3  0.2\n",
       " 43  5.0  3.5  1.6  0.6\n",
       " 44  5.1  3.8  1.9  0.4\n",
       " 45  4.8  3.0  1.4  0.3\n",
       " 46  5.1  3.8  1.6  0.2\n",
       " 47  4.6  3.2  1.4  0.2\n",
       " 48  5.3  3.7  1.5  0.2\n",
       " 49  5.0  3.3  1.4  0.2, 'X_1':       0    1    2    3\n",
       " 50  7.0  3.2  4.7  1.4\n",
       " 51  6.4  3.2  4.5  1.5\n",
       " 52  6.9  3.1  4.9  1.5\n",
       " 53  5.5  2.3  4.0  1.3\n",
       " 54  6.5  2.8  4.6  1.5\n",
       " 55  5.7  2.8  4.5  1.3\n",
       " 56  6.3  3.3  4.7  1.6\n",
       " 57  4.9  2.4  3.3  1.0\n",
       " 58  6.6  2.9  4.6  1.3\n",
       " 59  5.2  2.7  3.9  1.4\n",
       " 60  5.0  2.0  3.5  1.0\n",
       " 61  5.9  3.0  4.2  1.5\n",
       " 62  6.0  2.2  4.0  1.0\n",
       " 63  6.1  2.9  4.7  1.4\n",
       " 64  5.6  2.9  3.6  1.3\n",
       " 65  6.7  3.1  4.4  1.4\n",
       " 66  5.6  3.0  4.5  1.5\n",
       " 67  5.8  2.7  4.1  1.0\n",
       " 68  6.2  2.2  4.5  1.5\n",
       " 69  5.6  2.5  3.9  1.1\n",
       " 70  5.9  3.2  4.8  1.8\n",
       " 71  6.1  2.8  4.0  1.3\n",
       " 72  6.3  2.5  4.9  1.5\n",
       " 73  6.1  2.8  4.7  1.2\n",
       " 74  6.4  2.9  4.3  1.3\n",
       " 75  6.6  3.0  4.4  1.4\n",
       " 76  6.8  2.8  4.8  1.4\n",
       " 77  6.7  3.0  5.0  1.7\n",
       " 78  6.0  2.9  4.5  1.5\n",
       " 79  5.7  2.6  3.5  1.0\n",
       " 80  5.5  2.4  3.8  1.1\n",
       " 81  5.5  2.4  3.7  1.0\n",
       " 82  5.8  2.7  3.9  1.2\n",
       " 83  6.0  2.7  5.1  1.6\n",
       " 84  5.4  3.0  4.5  1.5\n",
       " 85  6.0  3.4  4.5  1.6\n",
       " 86  6.7  3.1  4.7  1.5\n",
       " 87  6.3  2.3  4.4  1.3\n",
       " 88  5.6  3.0  4.1  1.3\n",
       " 89  5.5  2.5  4.0  1.3\n",
       " 90  5.5  2.6  4.4  1.2\n",
       " 91  6.1  3.0  4.6  1.4\n",
       " 92  5.8  2.6  4.0  1.2\n",
       " 93  5.0  2.3  3.3  1.0\n",
       " 94  5.6  2.7  4.2  1.3\n",
       " 95  5.7  3.0  4.2  1.2\n",
       " 96  5.7  2.9  4.2  1.3\n",
       " 97  6.2  2.9  4.3  1.3\n",
       " 98  5.1  2.5  3.0  1.1\n",
       " 99  5.7  2.8  4.1  1.3, 'X_2':        0    1    2    3\n",
       " 100  6.3  3.3  6.0  2.5\n",
       " 101  5.8  2.7  5.1  1.9\n",
       " 102  7.1  3.0  5.9  2.1\n",
       " 103  6.3  2.9  5.6  1.8\n",
       " 104  6.5  3.0  5.8  2.2\n",
       " 105  7.6  3.0  6.6  2.1\n",
       " 106  4.9  2.5  4.5  1.7\n",
       " 107  7.3  2.9  6.3  1.8\n",
       " 108  6.7  2.5  5.8  1.8\n",
       " 109  7.2  3.6  6.1  2.5\n",
       " 110  6.5  3.2  5.1  2.0\n",
       " 111  6.4  2.7  5.3  1.9\n",
       " 112  6.8  3.0  5.5  2.1\n",
       " 113  5.7  2.5  5.0  2.0\n",
       " 114  5.8  2.8  5.1  2.4\n",
       " 115  6.4  3.2  5.3  2.3\n",
       " 116  6.5  3.0  5.5  1.8\n",
       " 117  7.7  3.8  6.7  2.2\n",
       " 118  7.7  2.6  6.9  2.3\n",
       " 119  6.0  2.2  5.0  1.5\n",
       " 120  6.9  3.2  5.7  2.3\n",
       " 121  5.6  2.8  4.9  2.0\n",
       " 122  7.7  2.8  6.7  2.0\n",
       " 123  6.3  2.7  4.9  1.8\n",
       " 124  6.7  3.3  5.7  2.1\n",
       " 125  7.2  3.2  6.0  1.8\n",
       " 126  6.2  2.8  4.8  1.8\n",
       " 127  6.1  3.0  4.9  1.8\n",
       " 128  6.4  2.8  5.6  2.1\n",
       " 129  7.2  3.0  5.8  1.6\n",
       " 130  7.4  2.8  6.1  1.9\n",
       " 131  7.9  3.8  6.4  2.0\n",
       " 132  6.4  2.8  5.6  2.2\n",
       " 133  6.3  2.8  5.1  1.5\n",
       " 134  6.1  2.6  5.6  1.4\n",
       " 135  7.7  3.0  6.1  2.3\n",
       " 136  6.3  3.4  5.6  2.4\n",
       " 137  6.4  3.1  5.5  1.8\n",
       " 138  6.0  3.0  4.8  1.8\n",
       " 139  6.9  3.1  5.4  2.1\n",
       " 140  6.7  3.1  5.6  2.4\n",
       " 141  6.9  3.1  5.1  2.3\n",
       " 142  5.8  2.7  5.1  1.9\n",
       " 143  6.8  3.2  5.9  2.3\n",
       " 144  6.7  3.3  5.7  2.5\n",
       " 145  6.7  3.0  5.2  2.3\n",
       " 146  6.3  2.5  5.0  1.9\n",
       " 147  6.5  3.0  5.2  2.0\n",
       " 148  6.2  3.4  5.4  2.3\n",
       " 149  5.9  3.0  5.1  1.8}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pipegraph.standard_blocks import Demultiplexer\n",
    "from pipegraph.adapters import AdapterForCustomFitPredictWithDictionaryOutputAdaptee\n",
    "\n",
    "demultiplexer = Demultiplexer()\n",
    "wrapped_demultiplexer = AdapterForCustomFitPredictWithDictionaryOutputAdaptee(demultiplexer)\n",
    "output = wrapped_demultiplexer.predict(X=X, selection=y)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X_0', 'X_1', 'X_2']"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(output.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen, this adapter's ```predict``` method provides the dictionary of outputs provided by the adaptee with its original keys."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrapping your custom blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PipeGraph uses the ```wrap_adaptee_in_process(adaptee, strategy_class=None)``` function to wrap the objects passed to its constructor's ```steps``` parameters accordingly to these rules:\n",
    "- If the ```strategy_class``` parameter is passed, this class is used as adapter\n",
    "- Else, if the adaptee's class is in ```pipegraph.base.strategies_for_custom_adaptees``` dictionary, the value class there is used.\n",
    "- Else, if the adaptee has a ```predict``` method, the ```AdapterForFitPredictAdaptee``` class is used.\n",
    "- Else, if the adaptee has a ```transform``` method, the ```AdapterForFitTransformAdaptee``` class is used.\n",
    "- Else, if the adaptee has a ```fit_predict``` method, the ```AdapterForAtomicFitPredictAdaptee```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predict': array([[ 0.22222222,  0.625     ,  0.06779661,  0.04166667],\n",
       "        [ 0.16666667,  0.41666667,  0.06779661,  0.04166667],\n",
       "        [ 0.11111111,  0.5       ,  0.05084746,  0.04166667],\n",
       "        [ 0.08333333,  0.45833333,  0.08474576,  0.04166667],\n",
       "        [ 0.19444444,  0.66666667,  0.06779661,  0.04166667],\n",
       "        [ 0.30555556,  0.79166667,  0.11864407,  0.125     ],\n",
       "        [ 0.08333333,  0.58333333,  0.06779661,  0.08333333],\n",
       "        [ 0.19444444,  0.58333333,  0.08474576,  0.04166667],\n",
       "        [ 0.02777778,  0.375     ,  0.06779661,  0.04166667],\n",
       "        [ 0.16666667,  0.45833333,  0.08474576,  0.        ],\n",
       "        [ 0.30555556,  0.70833333,  0.08474576,  0.04166667],\n",
       "        [ 0.13888889,  0.58333333,  0.10169492,  0.04166667],\n",
       "        [ 0.13888889,  0.41666667,  0.06779661,  0.        ],\n",
       "        [ 0.        ,  0.41666667,  0.01694915,  0.        ],\n",
       "        [ 0.41666667,  0.83333333,  0.03389831,  0.04166667],\n",
       "        [ 0.38888889,  1.        ,  0.08474576,  0.125     ],\n",
       "        [ 0.30555556,  0.79166667,  0.05084746,  0.125     ],\n",
       "        [ 0.22222222,  0.625     ,  0.06779661,  0.08333333],\n",
       "        [ 0.38888889,  0.75      ,  0.11864407,  0.08333333],\n",
       "        [ 0.22222222,  0.75      ,  0.08474576,  0.08333333],\n",
       "        [ 0.30555556,  0.58333333,  0.11864407,  0.04166667],\n",
       "        [ 0.22222222,  0.70833333,  0.08474576,  0.125     ],\n",
       "        [ 0.08333333,  0.66666667,  0.        ,  0.04166667],\n",
       "        [ 0.22222222,  0.54166667,  0.11864407,  0.16666667],\n",
       "        [ 0.13888889,  0.58333333,  0.15254237,  0.04166667],\n",
       "        [ 0.19444444,  0.41666667,  0.10169492,  0.04166667],\n",
       "        [ 0.19444444,  0.58333333,  0.10169492,  0.125     ],\n",
       "        [ 0.25      ,  0.625     ,  0.08474576,  0.04166667],\n",
       "        [ 0.25      ,  0.58333333,  0.06779661,  0.04166667],\n",
       "        [ 0.11111111,  0.5       ,  0.10169492,  0.04166667],\n",
       "        [ 0.13888889,  0.45833333,  0.10169492,  0.04166667],\n",
       "        [ 0.30555556,  0.58333333,  0.08474576,  0.125     ],\n",
       "        [ 0.25      ,  0.875     ,  0.08474576,  0.        ],\n",
       "        [ 0.33333333,  0.91666667,  0.06779661,  0.04166667],\n",
       "        [ 0.16666667,  0.45833333,  0.08474576,  0.        ],\n",
       "        [ 0.19444444,  0.5       ,  0.03389831,  0.04166667],\n",
       "        [ 0.33333333,  0.625     ,  0.05084746,  0.04166667],\n",
       "        [ 0.16666667,  0.45833333,  0.08474576,  0.        ],\n",
       "        [ 0.02777778,  0.41666667,  0.05084746,  0.04166667],\n",
       "        [ 0.22222222,  0.58333333,  0.08474576,  0.04166667],\n",
       "        [ 0.19444444,  0.625     ,  0.05084746,  0.08333333],\n",
       "        [ 0.05555556,  0.125     ,  0.05084746,  0.08333333],\n",
       "        [ 0.02777778,  0.5       ,  0.05084746,  0.04166667],\n",
       "        [ 0.19444444,  0.625     ,  0.10169492,  0.20833333],\n",
       "        [ 0.22222222,  0.75      ,  0.15254237,  0.125     ],\n",
       "        [ 0.13888889,  0.41666667,  0.06779661,  0.08333333],\n",
       "        [ 0.22222222,  0.75      ,  0.10169492,  0.04166667],\n",
       "        [ 0.08333333,  0.5       ,  0.06779661,  0.04166667],\n",
       "        [ 0.27777778,  0.70833333,  0.08474576,  0.04166667],\n",
       "        [ 0.19444444,  0.54166667,  0.06779661,  0.04166667],\n",
       "        [ 0.75      ,  0.5       ,  0.62711864,  0.54166667],\n",
       "        [ 0.58333333,  0.5       ,  0.59322034,  0.58333333],\n",
       "        [ 0.72222222,  0.45833333,  0.66101695,  0.58333333],\n",
       "        [ 0.33333333,  0.125     ,  0.50847458,  0.5       ],\n",
       "        [ 0.61111111,  0.33333333,  0.61016949,  0.58333333],\n",
       "        [ 0.38888889,  0.33333333,  0.59322034,  0.5       ],\n",
       "        [ 0.55555556,  0.54166667,  0.62711864,  0.625     ],\n",
       "        [ 0.16666667,  0.16666667,  0.38983051,  0.375     ],\n",
       "        [ 0.63888889,  0.375     ,  0.61016949,  0.5       ],\n",
       "        [ 0.25      ,  0.29166667,  0.49152542,  0.54166667],\n",
       "        [ 0.19444444,  0.        ,  0.42372881,  0.375     ],\n",
       "        [ 0.44444444,  0.41666667,  0.54237288,  0.58333333],\n",
       "        [ 0.47222222,  0.08333333,  0.50847458,  0.375     ],\n",
       "        [ 0.5       ,  0.375     ,  0.62711864,  0.54166667],\n",
       "        [ 0.36111111,  0.375     ,  0.44067797,  0.5       ],\n",
       "        [ 0.66666667,  0.45833333,  0.57627119,  0.54166667],\n",
       "        [ 0.36111111,  0.41666667,  0.59322034,  0.58333333],\n",
       "        [ 0.41666667,  0.29166667,  0.52542373,  0.375     ],\n",
       "        [ 0.52777778,  0.08333333,  0.59322034,  0.58333333],\n",
       "        [ 0.36111111,  0.20833333,  0.49152542,  0.41666667],\n",
       "        [ 0.44444444,  0.5       ,  0.6440678 ,  0.70833333],\n",
       "        [ 0.5       ,  0.33333333,  0.50847458,  0.5       ],\n",
       "        [ 0.55555556,  0.20833333,  0.66101695,  0.58333333],\n",
       "        [ 0.5       ,  0.33333333,  0.62711864,  0.45833333],\n",
       "        [ 0.58333333,  0.375     ,  0.55932203,  0.5       ],\n",
       "        [ 0.63888889,  0.41666667,  0.57627119,  0.54166667],\n",
       "        [ 0.69444444,  0.33333333,  0.6440678 ,  0.54166667],\n",
       "        [ 0.66666667,  0.41666667,  0.6779661 ,  0.66666667],\n",
       "        [ 0.47222222,  0.375     ,  0.59322034,  0.58333333],\n",
       "        [ 0.38888889,  0.25      ,  0.42372881,  0.375     ],\n",
       "        [ 0.33333333,  0.16666667,  0.47457627,  0.41666667],\n",
       "        [ 0.33333333,  0.16666667,  0.45762712,  0.375     ],\n",
       "        [ 0.41666667,  0.29166667,  0.49152542,  0.45833333],\n",
       "        [ 0.47222222,  0.29166667,  0.69491525,  0.625     ],\n",
       "        [ 0.30555556,  0.41666667,  0.59322034,  0.58333333],\n",
       "        [ 0.47222222,  0.58333333,  0.59322034,  0.625     ],\n",
       "        [ 0.66666667,  0.45833333,  0.62711864,  0.58333333],\n",
       "        [ 0.55555556,  0.125     ,  0.57627119,  0.5       ],\n",
       "        [ 0.36111111,  0.41666667,  0.52542373,  0.5       ],\n",
       "        [ 0.33333333,  0.20833333,  0.50847458,  0.5       ],\n",
       "        [ 0.33333333,  0.25      ,  0.57627119,  0.45833333],\n",
       "        [ 0.5       ,  0.41666667,  0.61016949,  0.54166667],\n",
       "        [ 0.41666667,  0.25      ,  0.50847458,  0.45833333],\n",
       "        [ 0.19444444,  0.125     ,  0.38983051,  0.375     ],\n",
       "        [ 0.36111111,  0.29166667,  0.54237288,  0.5       ],\n",
       "        [ 0.38888889,  0.41666667,  0.54237288,  0.45833333],\n",
       "        [ 0.38888889,  0.375     ,  0.54237288,  0.5       ],\n",
       "        [ 0.52777778,  0.375     ,  0.55932203,  0.5       ],\n",
       "        [ 0.22222222,  0.20833333,  0.33898305,  0.41666667],\n",
       "        [ 0.38888889,  0.33333333,  0.52542373,  0.5       ],\n",
       "        [ 0.55555556,  0.54166667,  0.84745763,  1.        ],\n",
       "        [ 0.41666667,  0.29166667,  0.69491525,  0.75      ],\n",
       "        [ 0.77777778,  0.41666667,  0.83050847,  0.83333333],\n",
       "        [ 0.55555556,  0.375     ,  0.77966102,  0.70833333],\n",
       "        [ 0.61111111,  0.41666667,  0.81355932,  0.875     ],\n",
       "        [ 0.91666667,  0.41666667,  0.94915254,  0.83333333],\n",
       "        [ 0.16666667,  0.20833333,  0.59322034,  0.66666667],\n",
       "        [ 0.83333333,  0.375     ,  0.89830508,  0.70833333],\n",
       "        [ 0.66666667,  0.20833333,  0.81355932,  0.70833333],\n",
       "        [ 0.80555556,  0.66666667,  0.86440678,  1.        ],\n",
       "        [ 0.61111111,  0.5       ,  0.69491525,  0.79166667],\n",
       "        [ 0.58333333,  0.29166667,  0.72881356,  0.75      ],\n",
       "        [ 0.69444444,  0.41666667,  0.76271186,  0.83333333],\n",
       "        [ 0.38888889,  0.20833333,  0.6779661 ,  0.79166667],\n",
       "        [ 0.41666667,  0.33333333,  0.69491525,  0.95833333],\n",
       "        [ 0.58333333,  0.5       ,  0.72881356,  0.91666667],\n",
       "        [ 0.61111111,  0.41666667,  0.76271186,  0.70833333],\n",
       "        [ 0.94444444,  0.75      ,  0.96610169,  0.875     ],\n",
       "        [ 0.94444444,  0.25      ,  1.        ,  0.91666667],\n",
       "        [ 0.47222222,  0.08333333,  0.6779661 ,  0.58333333],\n",
       "        [ 0.72222222,  0.5       ,  0.79661017,  0.91666667],\n",
       "        [ 0.36111111,  0.33333333,  0.66101695,  0.79166667],\n",
       "        [ 0.94444444,  0.33333333,  0.96610169,  0.79166667],\n",
       "        [ 0.55555556,  0.29166667,  0.66101695,  0.70833333],\n",
       "        [ 0.66666667,  0.54166667,  0.79661017,  0.83333333],\n",
       "        [ 0.80555556,  0.5       ,  0.84745763,  0.70833333],\n",
       "        [ 0.52777778,  0.33333333,  0.6440678 ,  0.70833333],\n",
       "        [ 0.5       ,  0.41666667,  0.66101695,  0.70833333],\n",
       "        [ 0.58333333,  0.33333333,  0.77966102,  0.83333333],\n",
       "        [ 0.80555556,  0.41666667,  0.81355932,  0.625     ],\n",
       "        [ 0.86111111,  0.33333333,  0.86440678,  0.75      ],\n",
       "        [ 1.        ,  0.75      ,  0.91525424,  0.79166667],\n",
       "        [ 0.58333333,  0.33333333,  0.77966102,  0.875     ],\n",
       "        [ 0.55555556,  0.33333333,  0.69491525,  0.58333333],\n",
       "        [ 0.5       ,  0.25      ,  0.77966102,  0.54166667],\n",
       "        [ 0.94444444,  0.41666667,  0.86440678,  0.91666667],\n",
       "        [ 0.55555556,  0.58333333,  0.77966102,  0.95833333],\n",
       "        [ 0.58333333,  0.45833333,  0.76271186,  0.70833333],\n",
       "        [ 0.47222222,  0.41666667,  0.6440678 ,  0.70833333],\n",
       "        [ 0.72222222,  0.45833333,  0.74576271,  0.83333333],\n",
       "        [ 0.66666667,  0.45833333,  0.77966102,  0.95833333],\n",
       "        [ 0.72222222,  0.45833333,  0.69491525,  0.91666667],\n",
       "        [ 0.41666667,  0.29166667,  0.69491525,  0.75      ],\n",
       "        [ 0.69444444,  0.5       ,  0.83050847,  0.91666667],\n",
       "        [ 0.66666667,  0.54166667,  0.79661017,  1.        ],\n",
       "        [ 0.66666667,  0.41666667,  0.71186441,  0.91666667],\n",
       "        [ 0.55555556,  0.20833333,  0.6779661 ,  0.75      ],\n",
       "        [ 0.61111111,  0.41666667,  0.71186441,  0.79166667],\n",
       "        [ 0.52777778,  0.58333333,  0.74576271,  0.91666667],\n",
       "        [ 0.44444444,  0.41666667,  0.69491525,  0.70833333]])}"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pipegraph.base import wrap_adaptee_in_process\n",
    "\n",
    "wrapped_scaler = wrap_adaptee_in_process(scaler)\n",
    "wrapped_scaler.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X_0':       0    1    2    3\n",
       " 0   5.1  3.5  1.4  0.2\n",
       " 1   4.9  3.0  1.4  0.2\n",
       " 2   4.7  3.2  1.3  0.2\n",
       " 3   4.6  3.1  1.5  0.2\n",
       " 4   5.0  3.6  1.4  0.2\n",
       " 5   5.4  3.9  1.7  0.4\n",
       " 6   4.6  3.4  1.4  0.3\n",
       " 7   5.0  3.4  1.5  0.2\n",
       " 8   4.4  2.9  1.4  0.2\n",
       " 9   4.9  3.1  1.5  0.1\n",
       " 10  5.4  3.7  1.5  0.2\n",
       " 11  4.8  3.4  1.6  0.2\n",
       " 12  4.8  3.0  1.4  0.1\n",
       " 13  4.3  3.0  1.1  0.1\n",
       " 14  5.8  4.0  1.2  0.2\n",
       " 15  5.7  4.4  1.5  0.4\n",
       " 16  5.4  3.9  1.3  0.4\n",
       " 17  5.1  3.5  1.4  0.3\n",
       " 18  5.7  3.8  1.7  0.3\n",
       " 19  5.1  3.8  1.5  0.3\n",
       " 20  5.4  3.4  1.7  0.2\n",
       " 21  5.1  3.7  1.5  0.4\n",
       " 22  4.6  3.6  1.0  0.2\n",
       " 23  5.1  3.3  1.7  0.5\n",
       " 24  4.8  3.4  1.9  0.2\n",
       " 25  5.0  3.0  1.6  0.2\n",
       " 26  5.0  3.4  1.6  0.4\n",
       " 27  5.2  3.5  1.5  0.2\n",
       " 28  5.2  3.4  1.4  0.2\n",
       " 29  4.7  3.2  1.6  0.2\n",
       " 30  4.8  3.1  1.6  0.2\n",
       " 31  5.4  3.4  1.5  0.4\n",
       " 32  5.2  4.1  1.5  0.1\n",
       " 33  5.5  4.2  1.4  0.2\n",
       " 34  4.9  3.1  1.5  0.1\n",
       " 35  5.0  3.2  1.2  0.2\n",
       " 36  5.5  3.5  1.3  0.2\n",
       " 37  4.9  3.1  1.5  0.1\n",
       " 38  4.4  3.0  1.3  0.2\n",
       " 39  5.1  3.4  1.5  0.2\n",
       " 40  5.0  3.5  1.3  0.3\n",
       " 41  4.5  2.3  1.3  0.3\n",
       " 42  4.4  3.2  1.3  0.2\n",
       " 43  5.0  3.5  1.6  0.6\n",
       " 44  5.1  3.8  1.9  0.4\n",
       " 45  4.8  3.0  1.4  0.3\n",
       " 46  5.1  3.8  1.6  0.2\n",
       " 47  4.6  3.2  1.4  0.2\n",
       " 48  5.3  3.7  1.5  0.2\n",
       " 49  5.0  3.3  1.4  0.2, 'X_1':       0    1    2    3\n",
       " 50  7.0  3.2  4.7  1.4\n",
       " 51  6.4  3.2  4.5  1.5\n",
       " 52  6.9  3.1  4.9  1.5\n",
       " 53  5.5  2.3  4.0  1.3\n",
       " 54  6.5  2.8  4.6  1.5\n",
       " 55  5.7  2.8  4.5  1.3\n",
       " 56  6.3  3.3  4.7  1.6\n",
       " 57  4.9  2.4  3.3  1.0\n",
       " 58  6.6  2.9  4.6  1.3\n",
       " 59  5.2  2.7  3.9  1.4\n",
       " 60  5.0  2.0  3.5  1.0\n",
       " 61  5.9  3.0  4.2  1.5\n",
       " 62  6.0  2.2  4.0  1.0\n",
       " 63  6.1  2.9  4.7  1.4\n",
       " 64  5.6  2.9  3.6  1.3\n",
       " 65  6.7  3.1  4.4  1.4\n",
       " 66  5.6  3.0  4.5  1.5\n",
       " 67  5.8  2.7  4.1  1.0\n",
       " 68  6.2  2.2  4.5  1.5\n",
       " 69  5.6  2.5  3.9  1.1\n",
       " 70  5.9  3.2  4.8  1.8\n",
       " 71  6.1  2.8  4.0  1.3\n",
       " 72  6.3  2.5  4.9  1.5\n",
       " 73  6.1  2.8  4.7  1.2\n",
       " 74  6.4  2.9  4.3  1.3\n",
       " 75  6.6  3.0  4.4  1.4\n",
       " 76  6.8  2.8  4.8  1.4\n",
       " 77  6.7  3.0  5.0  1.7\n",
       " 78  6.0  2.9  4.5  1.5\n",
       " 79  5.7  2.6  3.5  1.0\n",
       " 80  5.5  2.4  3.8  1.1\n",
       " 81  5.5  2.4  3.7  1.0\n",
       " 82  5.8  2.7  3.9  1.2\n",
       " 83  6.0  2.7  5.1  1.6\n",
       " 84  5.4  3.0  4.5  1.5\n",
       " 85  6.0  3.4  4.5  1.6\n",
       " 86  6.7  3.1  4.7  1.5\n",
       " 87  6.3  2.3  4.4  1.3\n",
       " 88  5.6  3.0  4.1  1.3\n",
       " 89  5.5  2.5  4.0  1.3\n",
       " 90  5.5  2.6  4.4  1.2\n",
       " 91  6.1  3.0  4.6  1.4\n",
       " 92  5.8  2.6  4.0  1.2\n",
       " 93  5.0  2.3  3.3  1.0\n",
       " 94  5.6  2.7  4.2  1.3\n",
       " 95  5.7  3.0  4.2  1.2\n",
       " 96  5.7  2.9  4.2  1.3\n",
       " 97  6.2  2.9  4.3  1.3\n",
       " 98  5.1  2.5  3.0  1.1\n",
       " 99  5.7  2.8  4.1  1.3, 'X_2':        0    1    2    3\n",
       " 100  6.3  3.3  6.0  2.5\n",
       " 101  5.8  2.7  5.1  1.9\n",
       " 102  7.1  3.0  5.9  2.1\n",
       " 103  6.3  2.9  5.6  1.8\n",
       " 104  6.5  3.0  5.8  2.2\n",
       " 105  7.6  3.0  6.6  2.1\n",
       " 106  4.9  2.5  4.5  1.7\n",
       " 107  7.3  2.9  6.3  1.8\n",
       " 108  6.7  2.5  5.8  1.8\n",
       " 109  7.2  3.6  6.1  2.5\n",
       " 110  6.5  3.2  5.1  2.0\n",
       " 111  6.4  2.7  5.3  1.9\n",
       " 112  6.8  3.0  5.5  2.1\n",
       " 113  5.7  2.5  5.0  2.0\n",
       " 114  5.8  2.8  5.1  2.4\n",
       " 115  6.4  3.2  5.3  2.3\n",
       " 116  6.5  3.0  5.5  1.8\n",
       " 117  7.7  3.8  6.7  2.2\n",
       " 118  7.7  2.6  6.9  2.3\n",
       " 119  6.0  2.2  5.0  1.5\n",
       " 120  6.9  3.2  5.7  2.3\n",
       " 121  5.6  2.8  4.9  2.0\n",
       " 122  7.7  2.8  6.7  2.0\n",
       " 123  6.3  2.7  4.9  1.8\n",
       " 124  6.7  3.3  5.7  2.1\n",
       " 125  7.2  3.2  6.0  1.8\n",
       " 126  6.2  2.8  4.8  1.8\n",
       " 127  6.1  3.0  4.9  1.8\n",
       " 128  6.4  2.8  5.6  2.1\n",
       " 129  7.2  3.0  5.8  1.6\n",
       " 130  7.4  2.8  6.1  1.9\n",
       " 131  7.9  3.8  6.4  2.0\n",
       " 132  6.4  2.8  5.6  2.2\n",
       " 133  6.3  2.8  5.1  1.5\n",
       " 134  6.1  2.6  5.6  1.4\n",
       " 135  7.7  3.0  6.1  2.3\n",
       " 136  6.3  3.4  5.6  2.4\n",
       " 137  6.4  3.1  5.5  1.8\n",
       " 138  6.0  3.0  4.8  1.8\n",
       " 139  6.9  3.1  5.4  2.1\n",
       " 140  6.7  3.1  5.6  2.4\n",
       " 141  6.9  3.1  5.1  2.3\n",
       " 142  5.8  2.7  5.1  1.9\n",
       " 143  6.8  3.2  5.9  2.3\n",
       " 144  6.7  3.3  5.7  2.5\n",
       " 145  6.7  3.0  5.2  2.3\n",
       " 146  6.3  2.5  5.0  1.9\n",
       " 147  6.5  3.0  5.2  2.0\n",
       " 148  6.2  3.4  5.4  2.3\n",
       " 149  5.9  3.0  5.1  1.8}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrapped_demultiplexer = wrap_adaptee_in_process(demultiplexer)\n",
    "wrapped_demultiplexer.predict(X=X, selection=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those users implementing their own custom blocks may find useful the option of providing their own custom class to th ```wrap_adaptee_in_process```, as in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X_0':       0    1    2    3\n",
       " 0   5.1  3.5  1.4  0.2\n",
       " 1   4.9  3.0  1.4  0.2\n",
       " 2   4.7  3.2  1.3  0.2\n",
       " 3   4.6  3.1  1.5  0.2\n",
       " 4   5.0  3.6  1.4  0.2\n",
       " 5   5.4  3.9  1.7  0.4\n",
       " 6   4.6  3.4  1.4  0.3\n",
       " 7   5.0  3.4  1.5  0.2\n",
       " 8   4.4  2.9  1.4  0.2\n",
       " 9   4.9  3.1  1.5  0.1\n",
       " 10  5.4  3.7  1.5  0.2\n",
       " 11  4.8  3.4  1.6  0.2\n",
       " 12  4.8  3.0  1.4  0.1\n",
       " 13  4.3  3.0  1.1  0.1\n",
       " 14  5.8  4.0  1.2  0.2\n",
       " 15  5.7  4.4  1.5  0.4\n",
       " 16  5.4  3.9  1.3  0.4\n",
       " 17  5.1  3.5  1.4  0.3\n",
       " 18  5.7  3.8  1.7  0.3\n",
       " 19  5.1  3.8  1.5  0.3\n",
       " 20  5.4  3.4  1.7  0.2\n",
       " 21  5.1  3.7  1.5  0.4\n",
       " 22  4.6  3.6  1.0  0.2\n",
       " 23  5.1  3.3  1.7  0.5\n",
       " 24  4.8  3.4  1.9  0.2\n",
       " 25  5.0  3.0  1.6  0.2\n",
       " 26  5.0  3.4  1.6  0.4\n",
       " 27  5.2  3.5  1.5  0.2\n",
       " 28  5.2  3.4  1.4  0.2\n",
       " 29  4.7  3.2  1.6  0.2\n",
       " 30  4.8  3.1  1.6  0.2\n",
       " 31  5.4  3.4  1.5  0.4\n",
       " 32  5.2  4.1  1.5  0.1\n",
       " 33  5.5  4.2  1.4  0.2\n",
       " 34  4.9  3.1  1.5  0.1\n",
       " 35  5.0  3.2  1.2  0.2\n",
       " 36  5.5  3.5  1.3  0.2\n",
       " 37  4.9  3.1  1.5  0.1\n",
       " 38  4.4  3.0  1.3  0.2\n",
       " 39  5.1  3.4  1.5  0.2\n",
       " 40  5.0  3.5  1.3  0.3\n",
       " 41  4.5  2.3  1.3  0.3\n",
       " 42  4.4  3.2  1.3  0.2\n",
       " 43  5.0  3.5  1.6  0.6\n",
       " 44  5.1  3.8  1.9  0.4\n",
       " 45  4.8  3.0  1.4  0.3\n",
       " 46  5.1  3.8  1.6  0.2\n",
       " 47  4.6  3.2  1.4  0.2\n",
       " 48  5.3  3.7  1.5  0.2\n",
       " 49  5.0  3.3  1.4  0.2, 'X_1':       0    1    2    3\n",
       " 50  7.0  3.2  4.7  1.4\n",
       " 51  6.4  3.2  4.5  1.5\n",
       " 52  6.9  3.1  4.9  1.5\n",
       " 53  5.5  2.3  4.0  1.3\n",
       " 54  6.5  2.8  4.6  1.5\n",
       " 55  5.7  2.8  4.5  1.3\n",
       " 56  6.3  3.3  4.7  1.6\n",
       " 57  4.9  2.4  3.3  1.0\n",
       " 58  6.6  2.9  4.6  1.3\n",
       " 59  5.2  2.7  3.9  1.4\n",
       " 60  5.0  2.0  3.5  1.0\n",
       " 61  5.9  3.0  4.2  1.5\n",
       " 62  6.0  2.2  4.0  1.0\n",
       " 63  6.1  2.9  4.7  1.4\n",
       " 64  5.6  2.9  3.6  1.3\n",
       " 65  6.7  3.1  4.4  1.4\n",
       " 66  5.6  3.0  4.5  1.5\n",
       " 67  5.8  2.7  4.1  1.0\n",
       " 68  6.2  2.2  4.5  1.5\n",
       " 69  5.6  2.5  3.9  1.1\n",
       " 70  5.9  3.2  4.8  1.8\n",
       " 71  6.1  2.8  4.0  1.3\n",
       " 72  6.3  2.5  4.9  1.5\n",
       " 73  6.1  2.8  4.7  1.2\n",
       " 74  6.4  2.9  4.3  1.3\n",
       " 75  6.6  3.0  4.4  1.4\n",
       " 76  6.8  2.8  4.8  1.4\n",
       " 77  6.7  3.0  5.0  1.7\n",
       " 78  6.0  2.9  4.5  1.5\n",
       " 79  5.7  2.6  3.5  1.0\n",
       " 80  5.5  2.4  3.8  1.1\n",
       " 81  5.5  2.4  3.7  1.0\n",
       " 82  5.8  2.7  3.9  1.2\n",
       " 83  6.0  2.7  5.1  1.6\n",
       " 84  5.4  3.0  4.5  1.5\n",
       " 85  6.0  3.4  4.5  1.6\n",
       " 86  6.7  3.1  4.7  1.5\n",
       " 87  6.3  2.3  4.4  1.3\n",
       " 88  5.6  3.0  4.1  1.3\n",
       " 89  5.5  2.5  4.0  1.3\n",
       " 90  5.5  2.6  4.4  1.2\n",
       " 91  6.1  3.0  4.6  1.4\n",
       " 92  5.8  2.6  4.0  1.2\n",
       " 93  5.0  2.3  3.3  1.0\n",
       " 94  5.6  2.7  4.2  1.3\n",
       " 95  5.7  3.0  4.2  1.2\n",
       " 96  5.7  2.9  4.2  1.3\n",
       " 97  6.2  2.9  4.3  1.3\n",
       " 98  5.1  2.5  3.0  1.1\n",
       " 99  5.7  2.8  4.1  1.3, 'X_2':        0    1    2    3\n",
       " 100  6.3  3.3  6.0  2.5\n",
       " 101  5.8  2.7  5.1  1.9\n",
       " 102  7.1  3.0  5.9  2.1\n",
       " 103  6.3  2.9  5.6  1.8\n",
       " 104  6.5  3.0  5.8  2.2\n",
       " 105  7.6  3.0  6.6  2.1\n",
       " 106  4.9  2.5  4.5  1.7\n",
       " 107  7.3  2.9  6.3  1.8\n",
       " 108  6.7  2.5  5.8  1.8\n",
       " 109  7.2  3.6  6.1  2.5\n",
       " 110  6.5  3.2  5.1  2.0\n",
       " 111  6.4  2.7  5.3  1.9\n",
       " 112  6.8  3.0  5.5  2.1\n",
       " 113  5.7  2.5  5.0  2.0\n",
       " 114  5.8  2.8  5.1  2.4\n",
       " 115  6.4  3.2  5.3  2.3\n",
       " 116  6.5  3.0  5.5  1.8\n",
       " 117  7.7  3.8  6.7  2.2\n",
       " 118  7.7  2.6  6.9  2.3\n",
       " 119  6.0  2.2  5.0  1.5\n",
       " 120  6.9  3.2  5.7  2.3\n",
       " 121  5.6  2.8  4.9  2.0\n",
       " 122  7.7  2.8  6.7  2.0\n",
       " 123  6.3  2.7  4.9  1.8\n",
       " 124  6.7  3.3  5.7  2.1\n",
       " 125  7.2  3.2  6.0  1.8\n",
       " 126  6.2  2.8  4.8  1.8\n",
       " 127  6.1  3.0  4.9  1.8\n",
       " 128  6.4  2.8  5.6  2.1\n",
       " 129  7.2  3.0  5.8  1.6\n",
       " 130  7.4  2.8  6.1  1.9\n",
       " 131  7.9  3.8  6.4  2.0\n",
       " 132  6.4  2.8  5.6  2.2\n",
       " 133  6.3  2.8  5.1  1.5\n",
       " 134  6.1  2.6  5.6  1.4\n",
       " 135  7.7  3.0  6.1  2.3\n",
       " 136  6.3  3.4  5.6  2.4\n",
       " 137  6.4  3.1  5.5  1.8\n",
       " 138  6.0  3.0  4.8  1.8\n",
       " 139  6.9  3.1  5.4  2.1\n",
       " 140  6.7  3.1  5.6  2.4\n",
       " 141  6.9  3.1  5.1  2.3\n",
       " 142  5.8  2.7  5.1  1.9\n",
       " 143  6.8  3.2  5.9  2.3\n",
       " 144  6.7  3.3  5.7  2.5\n",
       " 145  6.7  3.0  5.2  2.3\n",
       " 146  6.3  2.5  5.0  1.9\n",
       " 147  6.5  3.0  5.2  2.0\n",
       " 148  6.2  3.4  5.4  2.3\n",
       " 149  5.9  3.0  5.1  1.8}"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrapped_demultiplexer = wrap_adaptee_in_process(adaptee=demultiplexer,\n",
    "                                                strategy_class=AdapterForCustomFitPredictWithDictionaryOutputAdaptee)\n",
    "wrapped_demultiplexer.predict(X=X, selection=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing an already wrapped object to PipeGraph's constructor ```steps``` parameter by using the ```wrap_adaptee_in_process``` as describe above may be useful for those custom blocks built by users, thus avoiding the need to modify the ```pipegraph.base.strategies_for_custom_adaptees``` dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using PipeGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourth Example: Combination of classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A set of classifiers is combined as input to a neural network. Additionally, the scaled inputs are injected as well to\n",
    "the neural network. The data is firstly transformed by scaling its features.\n",
    "\n",
    "Steps of the **PipeGraph**:\n",
    "\n",
    "- **scaler**: A :class:`MinMaxScaler` data preprocessor\n",
    "- **gaussian_nb**: A :class:`GaussianNB` classifier\n",
    "- **svc**: A :class:`SVC` classifier\n",
    "- **concat**: A :class:`Concatenator` custom class that appends the outputs of the :class:`GaussianNB`, :class:`SVC` classifiers, and the scaled inputs.\n",
    "- **mlp**: A :class:`MLPClassifier` object\n",
    "\n",
    "![](https://raw.githubusercontent.com/mcasl/PipeGraph/master/examples/images/Diapositiva4.png)\n",
    "\n",
    "    Figure 1. PipeGraph diagram showing the steps and their connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pipegraph.base import PipeGraphClassifier, Concatenator\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "gaussian_nb = GaussianNB()\n",
    "svc = SVC()\n",
    "mlp = MLPClassifier()\n",
    "concatenator = Concatenator()\n",
    "\n",
    "steps = [('scaler', scaler),\n",
    "         ('gaussian_nb', gaussian_nb),\n",
    "         ('svc', svc),\n",
    "         ('concat', concatenator),\n",
    "         ('mlp', mlp)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we use a :class:`PipeGraphClassifier` because the result is a classification and we want to take advantage of Scikit-Learn default scoring method for classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgraph = PipeGraphClassifier(steps=steps)\n",
    "(pgraph.inject(sink='scaler', sink_var='X', source='_External', source_var='X')\n",
    "       .inject('gaussian_nb', 'X', 'scaler')\n",
    "       .inject('gaussian_nb', 'y', source_var='y')\n",
    "       .inject('svc', 'X', 'scaler')\n",
    "       .inject('svc', 'y', source_var='y')\n",
    "       .inject('concat', 'X1', 'scaler')\n",
    "       .inject('concat', 'X2', 'gaussian_nb')\n",
    "       .inject('concat', 'X3', 'svc')\n",
    "       .inject('mlp', 'X', 'concat')\n",
    "       .inject('mlp', 'y', source_var='y')\n",
    ")\n",
    "\n",
    "param_grid = {'svc__C': [0.1, 0.5, 1.0],\n",
    "              'mlp__hidden_layer_sizes': [(3,), (6,), (9,),],\n",
    "              'mlp__max_iter': [5000, 10000]}\n",
    "\n",
    "grid_search_classifier  = GridSearchCV(estimator=pgraph, param_grid=param_grid, refit=True)\n",
    "grid_search_classifier.fit(X, y)\n",
    "y_pred = grid_search_classifier.predict(X)\n",
    "\n",
    "grid_search_classifier.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for plotting the confusion matrix taken from 'Python Data Science Handbook' by Jake VanderPlas\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns; sns.set()  # for plot styling\n",
    "\n",
    "mat = confusion_matrix(y_pred, y)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example displayed complex data injections that are successfully managed by **PipeGraph**.\n",
    "Next example :ref:`on <example5>`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fifth Example: Demultiplexor - multiplexor\n",
    "\n",
    "An imaginative layout using a classifier to predict the cluster labels and fitting a separate model for each cluster.\n",
    "\n",
    "Steps of the **PipeGraph**:\n",
    "\n",
    "- **scaler**: A :class:`MinMaxScaler` data preprocessor\n",
    "- **classifier**: A :class:`GaussianMixture` classifier\n",
    "- **demux**: A custom :class:`Demultiplexer` class in charge of splitting the input arrays accordingly to the selection input vector\n",
    "- **lm_0**: A :class:`LinearRegression` model\n",
    "- **lm_1**: A :class:`LinearRegression` model\n",
    "- **lm_2**: A :class:`LinearRegression` model\n",
    "- **mux**: A custom :class:`Multiplexer` class in charge of combining different input arrays into a single one accordingly to the selection input vector\n",
    "\n",
    "![](https://raw.githubusercontent.com/mcasl/PipeGraph/master/examples/images/Diapositiva5.png)\n",
    "\n",
    "    Figure 1. PipeGraph diagram showing the steps and their connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pipegraph.base import PipeGraphRegressor, Demultiplexer, Multiplexer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "X_first = pd.Series(np.random.rand(100,))\n",
    "y_first = pd.Series(4 * X_first + 0.5*np.random.randn(100,))\n",
    "X_second = pd.Series(np.random.rand(100,) + 3)\n",
    "y_second = pd.Series(-4 * X_second + 0.5*np.random.randn(100,))\n",
    "X_third = pd.Series(np.random.rand(100,) + 6)\n",
    "y_third = pd.Series(2 * X_third + 0.5*np.random.randn(100,))\n",
    "\n",
    "X = pd.concat([X_first, X_second, X_third], axis=0).to_frame()\n",
    "y = pd.concat([y_first, y_second, y_third], axis=0).to_frame()\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "gaussian_mixture = GaussianMixture(n_components=3)\n",
    "demux = Demultiplexer()\n",
    "lm_0 = LinearRegression()\n",
    "lm_1 = LinearRegression()\n",
    "lm_2 = LinearRegression()\n",
    "mux = Multiplexer()\n",
    "\n",
    "\n",
    "steps = [('scaler', scaler),\n",
    "         ('classifier', gaussian_mixture),\n",
    "         ('demux', demux),\n",
    "         ('lm_0', lm_0),\n",
    "         ('lm_1', lm_1),\n",
    "         ('lm_2', lm_2),\n",
    "         ('mux', mux), ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using ``inject`` as in previous example, in this one we are going to pass a dictionary describing the connections to PipeGraph constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Demultiplexer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-5433463d2867>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpipegraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPipeGraphRegressor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDemultiplexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMultiplexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmixture\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGaussianMixture\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Demultiplexer'"
     ]
    }
   ],
   "source": [
    "connections = { 'scaler': {'X': 'X'},\n",
    "                'classifier': {'X': 'scaler'},\n",
    "                'demux': {'X': 'scaler',\n",
    "                          'y': 'y',\n",
    "                          'selection': 'classifier'},\n",
    "                'lm_0': {'X': ('demux', 'X_0'),\n",
    "                         'y': ('demux', 'y_0')},\n",
    "                'lm_1': {'X': ('demux', 'X_1'),\n",
    "                         'y': ('demux', 'y_1')},\n",
    "                'lm_2': {'X': ('demux', 'X_2'),\n",
    "                         'y': ('demux', 'y_2')},\n",
    "                'mux': {'0': 'lm_0',\n",
    "                        '1': 'lm_1',\n",
    "                        '2': 'lm_2',\n",
    "                        'selection': 'classifier'}}\n",
    "\n",
    "pgraph = PipeGraphRegressor(steps=steps, fit_connections=connections)\n",
    "pgraph.fit(X, y)\n",
    "#%%\n",
    "y_pred = pgraph.predict(X)\n",
    "plt.scatter(X, y)\n",
    "plt.scatter(X, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sixth Example: Encapsulating several blocks into a PipeGraph and reusing it\n",
    "\n",
    "A demonstration of several interesting features will be done in the following examples:\n",
    " 1. How the user can choose to encapsulate several blocks into a PipeGraph and use it as a single unit in another PipeGraph\n",
    " 2. How these components can be dynamically built on runtime depending on initialization parameters\n",
    " 3. How these components can be dynamically built on runtime depending on input signal values during fit\n",
    " 4. Using GridSearchCV to explore the best combination of hyperparameters\n",
    "\n",
    "We consider Example number five in which we had the following steps:\n",
    "\n",
    "- **scaler**: A :class:`MinMaxScaler` data preprocessor\n",
    "- **classifier**: A :class:`GaussianMixture` classifier\n",
    "- **demux** in charge of splitting the input arrays accordingly to the selection input vector\n",
    "- **lm_0**: A :class:`LinearRegression` model\n",
    "- **lm_1**: A :class:`LinearRegression` model\n",
    "- **lm_2**: A :class:`LinearRegression` model\n",
    "- **mux**: A custom :class:`Multiplexer` class in charge of combining different input arrays into a single one accordingly to the selection input vector\n",
    "\n",
    "For instance, we can find interesting to encapsulate the Demultiplexer, the linear model collection, and the Multiplexer into a single unit:\n",
    "We prepare the data and build a PipeGraph with these steps alone:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from pipegraph.base import PipeGraph, PipeGraphRegressor, Demultiplexer, Multiplexer\n",
    "\n",
    "X_first = pd.Series(np.random.rand(100,))\n",
    "y_first = pd.Series(4 * X_first + 0.5*np.random.randn(100,))\n",
    "X_second = pd.Series(np.random.rand(100,) + 3)\n",
    "y_second = pd.Series(-4 * X_second + 0.5*np.random.randn(100,))\n",
    "X_third = pd.Series(np.random.rand(100,) + 6)\n",
    "y_third = pd.Series(2 * X_third + 0.5*np.random.randn(100,))\n",
    "\n",
    "X = pd.concat([X_first, X_second, X_third], axis=0).to_frame()\n",
    "y = pd.concat([y_first, y_second, y_third], axis=0).to_frame()\n",
    "\n",
    "\n",
    "demux = Demultiplexer()\n",
    "lm_0 = LinearRegression()\n",
    "lm_1 = LinearRegression()\n",
    "lm_2 = LinearRegression()\n",
    "mux = Multiplexer()\n",
    "\n",
    "three_multiplexed_models_steps = [\n",
    "         ('demux', demux),\n",
    "         ('lm_0', lm_0),\n",
    "         ('lm_1', lm_1),\n",
    "         ('lm_2', lm_2),\n",
    "         ('mux', mux), ]\n",
    "\n",
    "three_multiplexed_models_connections = {\n",
    "                'demux': {'X': 'X',\n",
    "                          'y': 'y',\n",
    "                          'selection': 'selection'},\n",
    "                'lm_0': {'X': ('demux', 'X_0'),\n",
    "                         'y': ('demux', 'y_0')},\n",
    "                'lm_1': {'X': ('demux', 'X_1'),\n",
    "                         'y': ('demux', 'y_1')},\n",
    "                'lm_2': {'X': ('demux', 'X_2'),\n",
    "                         'y': ('demux', 'y_2')},\n",
    "                'mux': {'0': 'lm_0',\n",
    "                        '1': 'lm_1',\n",
    "                        '2': 'lm_2',\n",
    "                        'selection': 'selection'}}\n",
    "\n",
    "three_multiplexed_models = PipeGraph(steps=three_multiplexed_models_steps,\n",
    "                                     fit_connections=three_multiplexed_models_connections )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can treat this PipeGraph as a reusable component and use it as a unitary step in another PipeGraph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Demultiplexer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-2bef3a1c5bf0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmixture\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGaussianMixture\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpipegraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPipeGraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPipeGraphRegressor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDemultiplexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMultiplexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[0mX_first\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Demultiplexer'"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "gaussian_mixture = GaussianMixture(n_components=3)\n",
    "models = three_multiplexed_models\n",
    "\n",
    "steps = [('scaler', scaler),\n",
    "         ('classifier', gaussian_mixture),\n",
    "         ('models', three_multiplexed_models), ]\n",
    "\n",
    "connections = {'scaler': {'X': 'X'},\n",
    "               'classifier': {'X': 'scaler'},\n",
    "               'models': {'X': 'scaler',\n",
    "                          'y': 'y',\n",
    "                          'selection': 'classifier'},\n",
    "               }\n",
    "\n",
    "pgraph = PipeGraphRegressor(steps=steps, fit_connections=connections)\n",
    "pgraph.fit(X, y)\n",
    "y_pred = pgraph.predict(X)\n",
    "plt.scatter(X, y)\n",
    "plt.scatter(X, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seventh Example: Dynamically built component using initialization parameters\n",
    "\n",
    "We continue demonstrating several interesting features:\n",
    " 1. How the user can choose to encapsulate several blocks into a PipeGraph and use it as a single unit in another PipeGraph\n",
    " 2. How these components can be dynamically built on runtime depending on initialization parameters\n",
    " 3. How these components can be dynamically built on runtime depending on input signal values during fit\n",
    " 4. Using GridSearchCV to explore the best combination of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "from pipegraph.base import PipeGraph, PipeGraphRegressor, Demultiplexer, Multiplexer, \\\n",
    "    RegressorsWithParametrizedNumberOfReplicas\n",
    "\n",
    "X_first = pd.Series(np.random.rand(100,))\n",
    "y_first = pd.Series(4 * X_first + 0.5*np.random.randn(100,))\n",
    "X_second = pd.Series(np.random.rand(100,) + 3)\n",
    "y_second = pd.Series(-4 * X_second + 0.5*np.random.randn(100,))\n",
    "X_third = pd.Series(np.random.rand(100,) + 6)\n",
    "y_third = pd.Series(2 * X_third + 0.5*np.random.randn(100,))\n",
    "\n",
    "X = pd.concat([X_first, X_second, X_third], axis=0).to_frame()\n",
    "y = pd.concat([y_first, y_second, y_third], axis=0).to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can think of programatically changing the number of models inside this component.\n",
    "First we do it by using initialization parameters in a :class:``PipeGraph`` subclass we called :class:``pipegraph.standard_blocks.RegressorsWithParametrizedNumberOfReplicas``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "print(inspect.getsource(RegressorsWithParametrizedNumberOfReplicas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this new component we can build a simplified PipeGraph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Demultiplexer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-4e3e42956e58>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmixture\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGaussianMixture\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpipegraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPipeGraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPipeGraphRegressor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDemultiplexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMultiplexer\u001b[0m\u001b[1;33m,\u001b[0m     \u001b[0mRegressorsWithParametrizedNumberOfReplicas\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mX_first\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Demultiplexer'"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "gaussian_mixture = GaussianMixture(n_components=3)\n",
    "models = RegressorsWithParametrizedNumberOfReplicas(number_of_replicas=3,\n",
    "                                                    model_prototype=LinearRegression(),\n",
    "                                                    model_parameters={})\n",
    "\n",
    "steps = [('scaler', scaler),\n",
    "         ('classifier', gaussian_mixture),\n",
    "         ('models', models), ]\n",
    "\n",
    "connections = {'scaler': {'X': 'X'},\n",
    "               'classifier': {'X': 'scaler'},\n",
    "               'models': {'X': 'scaler',\n",
    "                          'y': 'y',\n",
    "                          'selection': 'classifier'},\n",
    "               }\n",
    "\n",
    "pgraph = PipeGraphRegressor(steps=steps, fit_connections=connections)\n",
    "pgraph.fit(X, y)\n",
    "y_pred = pgraph.predict(X)\n",
    "plt.scatter(X, y)\n",
    "plt.scatter(X, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eighth Example: # Dynamically built component using input signal values during the fit stage\n",
    "\n",
    "We continue demonstrating several interesting features:\n",
    " 1. How the user can choose to encapsulate several blocks into a PipeGraph and use it as a single unit in another PipeGraph\n",
    " 2. How these components can be dynamically built on runtime depending on initialization parameters\n",
    " 3. How these components can be dynamically built on runtime depending on input signal values during fit\n",
    " 4. Using GridSearchCV to explore the best combination of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from pipegraph.base import PipeGraphRegressor, RegressorsWithDataDependentNumberOfReplicas\n",
    "\n",
    "X_first = pd.Series(np.random.rand(100,))\n",
    "y_first = pd.Series(4 * X_first + 0.5*np.random.randn(100,))\n",
    "X_second = pd.Series(np.random.rand(100,) + 3)\n",
    "y_second = pd.Series(-4 * X_second + 0.5*np.random.randn(100,))\n",
    "X_third = pd.Series(np.random.rand(100,) + 6)\n",
    "y_third = pd.Series(2 * X_third + 0.5*np.random.randn(100,))\n",
    "\n",
    "X = pd.concat([X_first, X_second, X_third], axis=0).to_frame()\n",
    "y = pd.concat([y_first, y_second, y_third], axis=0).to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we consider the possibility of using the classifier's output to automatically adjust the number of replicas.\n",
    "This can be seen as PipeGraph changing its inner topology to adapt its connections and steps to other components\n",
    "context. This morphing capability opens interesting possibilities to explore indeed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "print(inspect.getsource(RegressorsWithDataDependentNumberOfReplicas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this new component we can build a simplified PipeGraph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RegressorsWithDataDependentNumberOfReplicas' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-13d08e29661a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mgaussian_mixture\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGaussianMixture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRegressorsWithDataDependentNumberOfReplicas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_prototype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m steps = [('scaler', scaler),\n",
      "\u001b[1;31mNameError\u001b[0m: name 'RegressorsWithDataDependentNumberOfReplicas' is not defined"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "gaussian_mixture = GaussianMixture(n_components=3)\n",
    "models = RegressorsWithDataDependentNumberOfReplicas(model_prototype=LinearRegression(), model_parameters={})\n",
    "\n",
    "steps = [('scaler', scaler),\n",
    "         ('classifier', gaussian_mixture),\n",
    "         ('models', models), ]\n",
    "\n",
    "connections = {'scaler': {'X': 'X'},\n",
    "               'classifier': {'X': 'scaler'},\n",
    "               'models': {'X': 'scaler',\n",
    "                          'y': 'y',\n",
    "                          'selection': 'classifier'},\n",
    "               }\n",
    "\n",
    "pgraph = PipeGraphRegressor(steps=steps, fit_connections=connections)\n",
    "pgraph.fit(X, y)\n",
    "y_pred = pgraph.predict(X)\n",
    "plt.scatter(X, y)\n",
    "plt.scatter(X, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ninth Example: # GridSearch on dynamically built component using input signal values\n",
    "\n",
    "We continue demonstrating several interesting features:\n",
    " 1. How the user can choose to encapsulate several blocks into a PipeGraph and use it as a single unit in another PipeGraph\n",
    " 2. How these components can be dynamically built on runtime depending on initialization parameters\n",
    " 3. How these components can be dynamically built on runtime depending on input signal values during fit\n",
    " 4. Using GridSearchCV to explore the best combination of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pipegraph.base import ( PipeGraphRegressor,\n",
    "                             RegressorsWithDataDependentNumberOfReplicas,\n",
    "                             NeutralRegressor,\n",
    "                             )\n",
    "\n",
    "X_first = pd.Series(np.random.rand(100,))\n",
    "y_first = pd.Series(4 * X_first + 0.5*np.random.randn(100,))\n",
    "X_second = pd.Series(np.random.rand(100,) + 3)\n",
    "y_second = pd.Series(-4 * X_second + 0.5*np.random.randn(100,))\n",
    "X_third = pd.Series(np.random.rand(100,) + 6)\n",
    "y_third = pd.Series(2 * X_third + 0.5*np.random.randn(100,))\n",
    "\n",
    "X = pd.concat([X_first, X_second, X_third], axis=0).to_frame()\n",
    "y = pd.concat([y_first, y_second, y_third], axis=0).to_frame()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we consider the possibility of using the classifier's output to automatically adjust the number of replicas.\n",
    "This can be seen as PipeGraph changing its inner topology to adapt its connections and steps to other components\n",
    "context. This morphing capability opens interesting possibilities to explore indeed.\n",
    "To ease the calculation of the score for the GridSearchCV we add a neutral regressor as a last step, capable of\n",
    "calculating the score using a default scoring function. This is much more convenient than worrying about programming\n",
    "a custom scoring function for a block with an arbitrary number of inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "gaussian_mixture = GaussianMixture(n_components=3)\n",
    "models = RegressorsWithDataDependentNumberOfReplicas(model_prototype=LinearRegression(), model_parameters={})\n",
    "neutral_regressor = NeutralRegressor()\n",
    "\n",
    "steps = [('scaler', scaler),\n",
    "         ('classifier', gaussian_mixture),\n",
    "         ('models', models),\n",
    "         ('neutral', neutral_regressor)]\n",
    "\n",
    "connections = {'scaler': {'X': 'X'},\n",
    "               'classifier': {'X': 'scaler'},\n",
    "               'models': {'X': 'scaler',\n",
    "                          'y': 'y',\n",
    "                          'selection': 'classifier'},\n",
    "               'neutral': {'X': 'models'}\n",
    "               }\n",
    "\n",
    "pgraph = PipeGraphRegressor(steps=steps, fit_connections=connections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using GridSearchCV to find the best number of clusters and the best regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-ef628885332e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'classifier__n_components'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrefit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'classifier__n_components': range(2,10)}\n",
    "gs = GridSearchCV(estimator=pgraph, param_grid=param_grid, refit=True)\n",
    "gs.fit(X_train, y_train)\n",
    "y_pred = gs.predict(X_train)\n",
    "plt.scatter(X_train, y_train)\n",
    "plt.scatter(X_train, y_pred)\n",
    "print(\"Score:\" , gs.score(X_test, y_test))\n",
    "print(\"classifier__n_components:\", gs.best_estimator_.get_params()['classifier__n_components'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tenth Example:  Alternative solution to example number 9\n",
    "\n",
    "We continue demonstrating several interesting features:\n",
    " 1. How the user can choose to encapsulate several blocks into a PipeGraph and use it as a single unit in another PipeGraph\n",
    " 2. How these components can be dynamically built on runtime depending on initialization parameters\n",
    " 3. How these components can be dynamically built on runtime depending on input signal values during fit\n",
    " 4. Using GridSearchCV to explore the best combination of hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pipegraph.base import ( PipeGraphRegressor,\n",
    "                             ClassifierAndRegressorsBundle,\n",
    "                             NeutralRegressor\n",
    "                            )\n",
    "\n",
    "X_first = pd.Series(np.random.rand(1000,))\n",
    "y_first = pd.Series(4 * X_first + 0.5*np.random.randn(1000,))\n",
    "X_second = pd.Series(np.random.rand(1000,) + 3)\n",
    "y_second = pd.Series(-4 * X_second + 0.5*np.random.randn(1000,))\n",
    "X_third = pd.Series(np.random.rand(1000,) + 6)\n",
    "y_third = pd.Series(2 * X_third + 0.5*np.random.randn(1000,))\n",
    "\n",
    "X = pd.concat([X_first, X_second, X_third], axis=0).to_frame()\n",
    "y = pd.concat([y_first, y_second, y_third], axis=0).to_frame()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we consider an alternative solution to example number 9. The previous solution showed the potential\n",
    "of being able to morph the graph during fitting. A simpler approach is considered in this example by reusing\n",
    "components and combining the classifier with the demultiplexed models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "print(inspect.getsource(ClassifierAndRegressorsBundle))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this new component we can build a simplified PipeGraph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "classifier_and_models = ClassifierAndRegressorsBundle(number_of_replicas=6)\n",
    "neutral_regressor = NeutralRegressor()\n",
    "\n",
    "steps = [('scaler', scaler),\n",
    "         ('bundle', classifier_and_models),\n",
    "         ('neutral', neutral_regressor)]\n",
    "\n",
    "connections = {'scaler': {'X': 'X'},\n",
    "               'bundle': {'X': 'scaler', 'y': 'y'},\n",
    "               'neutral': {'X': 'bundle'}}\n",
    "\n",
    "pgraph = PipeGraphRegressor(steps=steps, fit_connections=connections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using GridSearchCV to find the best number of clusters and the best regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-a1d94198e9d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'bundle__number_of_replicas'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrefit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'bundle__number_of_replicas': range(3,10)}\n",
    "gs = GridSearchCV(estimator=pgraph, param_grid=param_grid, refit=True)\n",
    "gs.fit(X_train, y_train)\n",
    "y_pred = gs.predict(X_train)\n",
    "plt.scatter(X_train, y_train)\n",
    "plt.scatter(X_train, y_pred)\n",
    "print(\"Score:\" , gs.score(X_test, y_test))\n",
    "print(\"bundle__number_of_replicas:\", gs.best_estimator_.get_params()['bundle__number_of_replicas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipegraph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-22809006348f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mimportlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipegraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pipegraph' is not defined"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(pipegraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pipegraph'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-5727cdd4e600>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpipegraph\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pipegraph'"
     ]
    }
   ],
   "source": [
    "import pipegraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
