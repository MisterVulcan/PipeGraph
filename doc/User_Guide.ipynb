{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pipegraph User Guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rationale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[scikit-learn](http://scikit-learn.org/stable/) provides a useful set of data preprocessors and machine learning models. The `Pipeline` object can effectively encapsulate a chain of transformers followed by final model. Other functions, like `GridSearchCV` can effectively use `Pipeline` objects to find the set of parameters that provide the best estimator.\n",
    "\n",
    "#### Pipeline + GridSearchCV: an awesome combination\n",
    "Let's consider a simple example to illustrate the advantages of using `Pipeline` and `GridSearchCV`.\n",
    "\n",
    "First let's import the libraries we will use and then let's build some artificial data set following a simple polynomial rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = 2*np.random.rand(100,1)-1\n",
    "y = 40 * X**5 + 3*X*2 +  3*X + 3*np.random.randn(100,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have some data ready, we instantiate the transformers and a regressor we want to fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "polynomial_features = PolynomialFeatures()\n",
    "linear_model = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the steps that form the Pipeline object and then we instantiate such a Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [('scaler', scaler),\n",
    "         ('polynomial_features', polynomial_features),\n",
    "         ('linear_model', linear_model)]\n",
    "\n",
    "pipe = Pipeline(steps=steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can pass this pipeline to `GridSearchCV`. When the `GridSearchCV` object is fitted, the search for the best combination for hyperparameters is performed according to the values provided in the `param_grid` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'polynomial_features__degree': range(1, 11),\n",
    "              'linear_model__fit_intercept': [True, False]}\n",
    "\n",
    "grid_search_regressor = GridSearchCV(estimator=pipe, param_grid=param_grid, refit=True)\n",
    "grid_search_regressor.fit(X, y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can check the results of fitting the Pipeline and the values of the hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHkVrHgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x273bc6f9f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = grid_search_regressor.predict(X)\n",
    "plt.scatter(X, y)\n",
    "plt.scatter(X, y_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information about the parameters of the best estimator: \n",
      " degree: 6 \n",
      " coefficients: [[  -46.13066962   343.32162766 -1015.54326464  1304.6951907   -272.53210185\n",
      "   -866.59140176   596.73121328]] \n"
     ]
    }
   ],
   "source": [
    "coef = grid_search_regressor.best_estimator_.get_params()['linear_model'].coef_\n",
    "degree = grid_search_regressor.best_estimator_.get_params()['polynomial_features'].degree\n",
    "\n",
    "print('Information about the parameters of the best estimator: \\n degree: {} \\n coefficients: {} '.format(degree, coef))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline weaknesses:\n",
    "From this example we can learn that `Pipeline` and `GridSearchCV` are very useful tools to consider when attempting to fit models. As far as the needs of the user can be satisfied by a set of transformers followed by a final model, this approach seems to be highly convenient. Additional advantages of such approach are the **parallel computation** and **memoization** capabilities of GridSearchCV.\n",
    "\n",
    "Unfortunately though, current implementation of scikit-learn's `Pipeline`:\n",
    "- Does not allow postprocessors after the final model\n",
    "- Does not allow extracting information about intermediate results\n",
    "- The X is transformed on every transformer but the following step can not have access to X variable values beyond the previous step\n",
    "- Does not allow non linear workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pipegraph goals:\n",
    "[pipegraph](https://github.com/mcasl/PipeGraph) was programmed in order to allow researchers and practitioners to:\n",
    "- Use non linear workflows\n",
    "- Have access to every variable value produced by any step of the workflow\n",
    "- Use an arbitraty number of models and transformers in the way the user prefers\n",
    "- Express the model as a graph consisting of transformers, regressors, classifiers or custom blocks\n",
    "- Build new custom block in an easy way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of the library\n",
    "\n",
    "### Main interface: The PipeGraphRegressor and PipeGraphClassifier classes\n",
    "`pipegraph` provides the user two main classes: `PipeGraphRegressor` and `PipeGraphClassifier`. They both provide a familiar interface to the raw `PipeGraph` class that most users will not need to use. The `PipeGraph` class provides greater versatility allowing an arbitrary number of inputs and outputs and may be the base class for those users facing applications with such special needs. Most users, though, will be happy using just the former two classes provided as main interface to operate the library.\n",
    "\n",
    "As the names intend to imply, `PipeGraphRegressor` is the class to use for regression models and `PipeGraphClassifier` is intended for classification problems. Indeed, the only difference between these two classes is the default scoring function that has been chosen accordingly to scikit-learn defaults for each case. Apart from that, both classes share the same code. It must be noticed though, that any of these classes can comprise a plethora of different regressors or clasiffiers. It is the final step the one that will define whether we are defining a classification or regression problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From a linear workflow to a graph: Understanding connections\n",
    "Theses two classes provide an interface as similar to scikit-learn's `Pipeline` as possible in order to ease their use to those already familiar with scikit-learn. There is a slight but important difference that empowers these two classes: the `PipeGraph` related classes accept extra information about which input variables are needed by each step, thus allowing non linear workflows. \n",
    "\n",
    "To clarify the usage of these connections, let's start using `pipegraph` with a simple example that could be otherwise perfectly expressed using a scikit-learn's `Pipeline` as well. In this simple case, the data is transformed using a `MinMaxScaler` transformer and the preprocessed data is fed to a `LinearRegression` model. Figure 1 shows the steps of this PipeGraphRegressor and the connections between them: which input variables each one accepts and their origin, that is, if they are provided by a previous step, like the output of `scaler`, named `predict`, that is used by `linear_model`'s `X` variable; or `y` which is not calculated by any previous block but is passed by the user in the `fit` or `predict` method calls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/mcasl/PipeGraph/master/doc/images/figure1.png\" width=\"400\" />\n",
    "Figure 1. PipeGraph diagram showing the steps and their connections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first simple example of `pipegraph` the last step is a regressor, and thus the `PipeGraphRegressor` class is the most adequate class to choose. But other than that, we define the steps as usual for a standard `Pipeline`: as a list of tuples (label, sklearn object). We are not introducing yet any information at all about the connections, in which case the `PipeGraphRegressor` object is built considering that the steps follow a linear workflow in the same way as a standard `Pipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PipeGraphRegressor(fit_connections={'scaler': {'X': 'X'}, 'linear_model': {'X': ('scaler', 'predict'), 'y': 'y'}},\n",
       "          log_level=None,\n",
       "          predict_connections={'scaler': {'X': 'X'}, 'linear_model': {'X': ('scaler', 'predict'), 'y': 'y'}},\n",
       "          steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('linear_model', LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pipegraph import PipeGraphRegressor\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "linear_model = LinearRegression()\n",
    "steps = [('scaler', scaler),\n",
    "         ('linear_model', linear_model)]\n",
    "\n",
    "pgraph = PipeGraphRegressor(steps=steps)\n",
    "pgraph.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the printed output shows, the internal links displayed by the `fit_connections` and `predict_connections` parameters are in line with those we saw in Figure 1 and those expected by a linear pipeline. As we did not specify these values, they were created by `PipeGRaphRegressor.__init__()` method as a comodity. We can have a look at these values by directly inspecting the attributes values. As `PipeGraphRegressor` and `PipeGraphClassifier` are wrappers of a `PipeGraph` object stored in the `_pipegraph` attribute, we have to dig a bit deeper to find the `fit_connections`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'linear_model': {'X': ('scaler', 'predict'), 'y': 'y'}, 'scaler': {'X': 'X'}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pgraph._pipegraph.fit_connections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 2 surely will help understading the syntax used by the connections dictionary. It goes like this:\n",
    "- The keys of the top level entries of the dictionary must be the same as those of the previously defined steps.\n",
    "- The values assocciated to these keys define the variables from other steps that are going to be considered as inputs for the current step. They are dictionaries themselves, where:\n",
    "\n",
    "   - The keys of the nested dictionary represent the input variables as named at the current step.\n",
    "   - The values assocciated to these keys define the steps that hold the desired information and the variables as named at that step. This information can be written as:\n",
    "\n",
    "     - A tuple with the label of the step in position 0 followed by the name of the output variable in position 1.\n",
    "     - A string:\n",
    "         - If the string value is one of the labels from the steps, then it is interpreted as tuple, as previously, with the label of the step in position 0 and 'predict' as name of the output variable in position 1.\n",
    "         - Otherwise, it is considered to be a variable from an external source, such as those provided by the user while invoking the ``fit``, ``predict`` or ``fit_predict`` methods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Figure 2. Illustration of the connections of the PipeGraph](https://raw.githubusercontent.com/mcasl/PipeGraph/master/examples/images/Diapositiva1-2.png)\n",
    "\n",
    "Figure 2. Illustration of the connections of the PipeGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The choice of name 'predict' for default output variables was made for convenience reasons as it will be illustrated later on. The developers preferred using always the same word for every block even though it might not be a regressor nor a classifier.\n",
    "\n",
    "Finally, let's get the predicted values from this `PipeGraphRegressor` for illustrative purposes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x273bf165860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = pgraph.predict(X)\n",
    "plt.scatter(X, y, label='Original Data')\n",
    "plt.scatter(X, y_pred, label='Predicted Data')\n",
    "plt.title('Plots of original and predicted data')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True)\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Value of Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `GridSearchCV` compatibility\n",
    "\n",
    "Both `PipeGraphRegressor`and `PipeGraphClassifier` are compatible with `GridSearchCV` provided the last step can be scored, either:\n",
    "- by using `PipeGraphRegressor` or `PipeGraphClassifier` default scoring functions,\n",
    "- by implementing a custom scoring function capable of handling that last step inputs and outputs,\n",
    "- by using a `NeutralRegressor` or `NeutralClassifier` block as final step.\n",
    "\n",
    "Those pipegraphs with a last step from scikit-learn's estimators set will work perfectly well using `PipeGraphRegressor` or `PipeGraphClassifier` default scoring functions. The other two alternative cover those cases in which a custom block with non standard inputs is provided. In that case, choosing a neutral regressor or classifier is usually a much simpler approach than writing customs scoring function. `NeutralRegressor` or `NeutralClassifier` are two classes provided for users convenience so that no special scoring function is needed. They just allow the user to pick some variables from other previous steps as `X` and `y` and provide compatibility to use a default scoring function.  \n",
    "\n",
    "We will show more complex examples in what follows, but let's first illustrate with a simple example how to use `GrisSearchCV` with the default scoring functions.\n",
    "This example shows how to use `GridSearchCv` with **PipeGraph** to effectively fit the best model across a number of hyperparameters. I is equivalent to use `GridSearchCv` with `Pipeline`. More complicated cases are shown in the following examples. In this second example we wanted to show how to fit a `GridSearchCV` in a yet simple scenario.\n",
    "\n",
    "Steps of the **PipeGraph**:\n",
    "\n",
    "- **scaler**: a preprocessing step using a :class:`MinMaxScaler` object\n",
    "- **polynomial_features**: a transformer step\n",
    "- **linear_model**: the :class:`LinearRegression` object we want to fit and use for predict.\n",
    "\n",
    ".. figure:: https://raw.githubusercontent.com/mcasl/PipeGraph/master/examples/images/Diapositiva2.png\n",
    "\n",
    "    Figure 1. PipeGraph diagram showing the steps and their connections\n",
    "\n",
    "Firstly, we import the necessary libraries and create some artificial data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pipegraph.base import PipeGraphRegressor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = 2*np.random.rand(100,1)-1\n",
    "y = 40 * X**5 + 3*X*2 +  3*X + 3*np.random.randn(100,1)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "polynomial_features = PolynomialFeatures()\n",
    "linear_model = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondly, we define the steps and a ``param_grid`` dictionary as specified by :class:`GridSearchCV`.\n",
    "In this case we just want to explore a few possibilities varying the degree of the polynomials and whether to use or not an intercept at the linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [('scaler', scaler),\n",
    "         ('polynomial_features', polynomial_features),\n",
    "         ('linear_model', linear_model)]\n",
    "\n",
    "param_grid = {'polynomial_features__degree': range(1, 11),\n",
    "              'linear_model__fit_intercept': [True, False]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we use ``PipeGraphRegressor`` as estimator for :class:`GridSearchCV` and perform the ``fit`` and ``predict`` operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgraph = PipeGraphRegressor(steps=steps)\n",
    "grid_search_regressor = GridSearchCV(estimator=pgraph, param_grid=param_grid, refit=True)\n",
    "grid_search_regressor.fit(X, y)\n",
    "y_pred = grid_search_regressor.predict(X)\n",
    "\n",
    "plt.scatter(X, y)\n",
    "plt.scatter(X, y_pred)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "coef = grid_search_regressor.best_estimator_.get_params()['linear_model'].coef_\n",
    "degree = grid_search_regressor.best_estimator_.get_params()['polynomial_features'].degree\n",
    "\n",
    "print('Information about the parameters of the best estimator: \\n degree: {} \\n coefficients: {} '.format(degree, coef))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example showed how to use :class:`GridSearchCV` with :class:`PipeGraphRegressor` in a simple linear workflow.\n",
    ":ref:`Next example <example3>` provides detail on how to proceed with a non linear case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrappers for Scikit-Learn standard objects\n",
    "Consider the following Scikit-Learn common objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "classifier = GaussianNB()\n",
    "scaler = MinMaxScaler() \n",
    "dbscanner = DBSCAN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's load some data to run the examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's fit each of the above defined sklearn objects and get the output produced afterwards by using the corresponding method (predict, fit_predict, transform):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DBSCAN(algorithm='auto', eps=0.5, leaf_size=30, metric='euclidean',\n",
       "    metric_params=None, min_samples=5, n_jobs=1, p=None)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X, y)\n",
    "scaler.fit(X);\n",
    "dbscanner.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.00000000e+000,   1.38496103e-018,   7.25489025e-026],\n",
       "       [  1.00000000e+000,   1.48206242e-017,   2.29743996e-025],\n",
       "       [  1.00000000e+000,   1.07780639e-018,   2.35065917e-026],\n",
       "       [  1.00000000e+000,   1.43871443e-017,   2.89954283e-025],\n",
       "       [  1.00000000e+000,   4.65192224e-019,   2.95961100e-026],\n",
       "       [  1.00000000e+000,   1.52598944e-014,   1.79883402e-021],\n",
       "       [  1.00000000e+000,   1.13555084e-017,   2.79240943e-025],\n",
       "       [  1.00000000e+000,   6.57615274e-018,   2.79021029e-025],\n",
       "       [  1.00000000e+000,   9.12219356e-018,   1.16607332e-025],\n",
       "       [  1.00000000e+000,   3.20344249e-018,   1.12989524e-025],\n",
       "       [  1.00000000e+000,   4.48944985e-018,   5.19388089e-025],\n",
       "       [  1.00000000e+000,   1.65734172e-017,   7.24605453e-025],\n",
       "       [  1.00000000e+000,   1.19023891e-018,   3.06690017e-026],\n",
       "       [  1.00000000e+000,   7.39520546e-020,   1.77972179e-027],\n",
       "       [  1.00000000e+000,   2.58242749e-019,   8.73399972e-026],\n",
       "       [  1.00000000e+000,   3.17746623e-017,   1.73684833e-023],\n",
       "       [  1.00000000e+000,   5.70113578e-017,   4.84010372e-024],\n",
       "       [  1.00000000e+000,   2.42054769e-017,   8.45556661e-025],\n",
       "       [  1.00000000e+000,   6.27645419e-015,   1.06276762e-021],\n",
       "       [  1.00000000e+000,   8.94493797e-018,   7.10691894e-025],\n",
       "       [  1.00000000e+000,   1.12843548e-015,   7.60807373e-023],\n",
       "       [  1.00000000e+000,   6.39726172e-016,   2.98066089e-023],\n",
       "       [  1.00000000e+000,   2.01227309e-020,   1.00676223e-027],\n",
       "       [  1.00000000e+000,   1.88370574e-011,   3.47694606e-019],\n",
       "       [  1.00000000e+000,   9.85315738e-015,   6.06138600e-022],\n",
       "       [  1.00000000e+000,   3.37823264e-016,   6.39532840e-024],\n",
       "       [  1.00000000e+000,   1.76045187e-014,   4.11462407e-022],\n",
       "       [  1.00000000e+000,   7.35980232e-018,   4.42389485e-025],\n",
       "       [  1.00000000e+000,   4.16674318e-018,   1.83083484e-025],\n",
       "       [  1.00000000e+000,   4.59768498e-017,   1.25839903e-024],\n",
       "       [  1.00000000e+000,   1.05032415e-016,   2.32677467e-024],\n",
       "       [  1.00000000e+000,   2.19590125e-014,   6.17650711e-022],\n",
       "       [  1.00000000e+000,   6.53087316e-021,   3.11887725e-027],\n",
       "       [  1.00000000e+000,   3.19701924e-020,   1.42881733e-026],\n",
       "       [  1.00000000e+000,   3.20344249e-018,   1.12989524e-025],\n",
       "       [  1.00000000e+000,   1.31355747e-018,   2.91614269e-026],\n",
       "       [  1.00000000e+000,   3.69675482e-018,   2.51866027e-025],\n",
       "       [  1.00000000e+000,   3.20344249e-018,   1.12989524e-025],\n",
       "       [  1.00000000e+000,   2.08944813e-018,   3.09410939e-026],\n",
       "       [  1.00000000e+000,   9.57268514e-018,   4.26475768e-025],\n",
       "       [  1.00000000e+000,   6.37746927e-018,   1.99216264e-025],\n",
       "       [  1.00000000e+000,   7.48755609e-016,   1.85220582e-024],\n",
       "       [  1.00000000e+000,   6.74316102e-019,   1.54533175e-026],\n",
       "       [  1.00000000e+000,   6.24456357e-011,   1.54295833e-018],\n",
       "       [  1.00000000e+000,   8.14548341e-013,   7.52199540e-020],\n",
       "       [  1.00000000e+000,   1.94244394e-016,   1.96296487e-024],\n",
       "       [  1.00000000e+000,   2.39642309e-018,   3.11909164e-025],\n",
       "       [  1.00000000e+000,   2.30047669e-018,   5.36192288e-026],\n",
       "       [  1.00000000e+000,   2.70414239e-018,   2.86492790e-025],\n",
       "       [  1.00000000e+000,   3.60099614e-018,   1.12304319e-025],\n",
       "       [  1.87127931e-108,   8.04037666e-001,   1.95962334e-001],\n",
       "       [  6.18854779e-101,   9.45169639e-001,   5.48303606e-002],\n",
       "       [  1.52821825e-122,   4.56151317e-001,   5.43848683e-001],\n",
       "       [  2.14997261e-070,   9.99968751e-001,   3.12488556e-005],\n",
       "       [  9.04938222e-107,   9.52441811e-001,   4.75581888e-002],\n",
       "       [  1.29272979e-090,   9.99119627e-001,   8.80372565e-004],\n",
       "       [  2.72490532e-114,   6.58952285e-001,   3.41047715e-001],\n",
       "       [  1.19734767e-034,   9.99999767e-001,   2.33206910e-007],\n",
       "       [  3.02545627e-098,   9.90316309e-001,   9.68369084e-003],\n",
       "       [  1.29477666e-069,   9.99909746e-001,   9.02536083e-005],\n",
       "       [  2.68173680e-041,   9.99999765e-001,   2.35068227e-007],\n",
       "       [  7.51115851e-087,   9.96238286e-001,   3.76171369e-003],\n",
       "       [  6.40165546e-061,   9.99993984e-001,   6.01632484e-006],\n",
       "       [  4.81814146e-105,   9.86090825e-001,   1.39091754e-002],\n",
       "       [  1.72509107e-055,   9.99975387e-001,   2.46126406e-005],\n",
       "       [  1.18941242e-093,   9.80037003e-001,   1.99629974e-002],\n",
       "       [  1.18009940e-098,   9.90687273e-001,   9.31272734e-003],\n",
       "       [  2.31534504e-063,   9.99983663e-001,   1.63372809e-005],\n",
       "       [  5.48394976e-102,   9.94697108e-001,   5.30289217e-003],\n",
       "       [  5.51699136e-059,   9.99993006e-001,   6.99364316e-006],\n",
       "       [  7.43572418e-129,   1.54494085e-001,   8.45505915e-001],\n",
       "       [  2.12417952e-071,   9.99807026e-001,   1.92973847e-004],\n",
       "       [  1.06622383e-120,   9.27077052e-001,   7.29229479e-002],\n",
       "       [  4.79428037e-097,   9.98156519e-001,   1.84348055e-003],\n",
       "       [  2.71707817e-084,   9.98460816e-001,   1.53918416e-003],\n",
       "       [  2.03176962e-093,   9.87471082e-001,   1.25289184e-002],\n",
       "       [  4.95012220e-113,   9.12844444e-001,   8.71555561e-002],\n",
       "       [  2.12531216e-137,   7.52691316e-002,   9.24730868e-001],\n",
       "       [  4.19702663e-100,   9.86480268e-001,   1.35197316e-002],\n",
       "       [  4.63173354e-042,   9.99998762e-001,   1.23794211e-006],\n",
       "       [  2.77274013e-055,   9.99996447e-001,   3.55251831e-006],\n",
       "       [  2.14091116e-048,   9.99998651e-001,   1.34923924e-006],\n",
       "       [  6.63563094e-063,   9.99972348e-001,   2.76523927e-005],\n",
       "       [  2.61124821e-134,   6.12159845e-001,   3.87840155e-001],\n",
       "       [  3.71647418e-098,   9.92476638e-001,   7.52336224e-003],\n",
       "       [  1.13230275e-103,   8.76107551e-001,   1.23892449e-001],\n",
       "       [  1.05786721e-111,   7.99294752e-001,   2.00705248e-001],\n",
       "       [  3.76539608e-089,   9.99385417e-001,   6.14582528e-004],\n",
       "       [  3.07894878e-073,   9.99796270e-001,   2.03730114e-004],\n",
       "       [  4.17712661e-070,   9.99955234e-001,   4.47664632e-005],\n",
       "       [  3.92710689e-082,   9.99873680e-001,   1.26320322e-004],\n",
       "       [  3.30872742e-100,   9.89371467e-001,   1.06285328e-002],\n",
       "       [  8.31545615e-067,   9.99966229e-001,   3.37713204e-005],\n",
       "       [  6.26912483e-035,   9.99999798e-001,   2.02487922e-007],\n",
       "       [  7.66367658e-078,   9.99832329e-001,   1.67671378e-004],\n",
       "       [  1.58557717e-073,   9.99849875e-001,   1.50125137e-004],\n",
       "       [  1.02662082e-077,   9.99714947e-001,   2.85053350e-004],\n",
       "       [  1.72307593e-083,   9.98992363e-001,   1.00763708e-003],\n",
       "       [  4.12872931e-030,   9.99999769e-001,   2.31316897e-007],\n",
       "       [  5.99667528e-074,   9.99847160e-001,   1.52839987e-004],\n",
       "       [  4.13779546e-251,   6.35381030e-011,   1.00000000e+000],\n",
       "       [  5.00845630e-151,   2.50121636e-002,   9.74987836e-001],\n",
       "       [  1.04941686e-218,   1.67915381e-007,   9.99999832e-001],\n",
       "       [  2.13833836e-175,   1.99462374e-003,   9.98005376e-001],\n",
       "       [  7.20399720e-216,   2.30543407e-007,   9.99999769e-001],\n",
       "       [  4.51654712e-271,   2.40976994e-010,   1.00000000e+000],\n",
       "       [  4.59552511e-108,   9.73514345e-001,   2.64856553e-002],\n",
       "       [  2.22191497e-227,   1.34018147e-006,   9.99998660e-001],\n",
       "       [  2.10589122e-190,   4.92901785e-004,   9.99507098e-001],\n",
       "       [  1.20055778e-262,   1.40568402e-012,   1.00000000e+000],\n",
       "       [  3.62359789e-160,   4.12884115e-004,   9.99587116e-001],\n",
       "       [  8.83719953e-165,   2.77742178e-003,   9.97222578e-001],\n",
       "       [  6.87376950e-192,   4.80711862e-006,   9.99995193e-001],\n",
       "       [  4.08220498e-152,   1.28807070e-002,   9.87119293e-001],\n",
       "       [  2.75153031e-187,   1.04253685e-006,   9.99998957e-001],\n",
       "       [  1.44750671e-192,   4.50951786e-007,   9.99999549e-001],\n",
       "       [  2.76680341e-170,   1.87196580e-003,   9.98128034e-001],\n",
       "       [  3.75302289e-285,   1.64574932e-012,   1.00000000e+000],\n",
       "       [  4.69548986e-310,   6.47406861e-013,   1.00000000e+000],\n",
       "       [  5.69697725e-125,   9.58135362e-001,   4.18646381e-002],\n",
       "       [  2.94299535e-219,   1.17116897e-008,   9.99999988e-001],\n",
       "       [  2.82525894e-146,   1.37625971e-002,   9.86237403e-001],\n",
       "       [  1.12237933e-272,   7.58240410e-010,   9.99999999e-001],\n",
       "       [  2.28867567e-136,   1.29986728e-001,   8.70013272e-001],\n",
       "       [  5.61795825e-203,   9.71777952e-007,   9.99999028e-001],\n",
       "       [  8.72622664e-206,   7.39901993e-006,   9.99992601e-001],\n",
       "       [  9.96933448e-131,   1.99928220e-001,   8.00071780e-001],\n",
       "       [  4.66749613e-135,   1.07483532e-001,   8.92516468e-001],\n",
       "       [  6.88743059e-196,   1.09467814e-005,   9.99989053e-001],\n",
       "       [  1.61337601e-181,   7.01805717e-004,   9.99298194e-001],\n",
       "       [  8.55580252e-221,   9.06238440e-007,   9.99999094e-001],\n",
       "       [  1.24722670e-250,   2.96730515e-010,   1.00000000e+000],\n",
       "       [  3.64874362e-203,   1.50788229e-006,   9.99998492e-001],\n",
       "       [  2.19798649e-130,   7.12645144e-001,   2.87354856e-001],\n",
       "       [  3.68949024e-153,   4.86199285e-001,   5.13800715e-001],\n",
       "       [  2.13595212e-251,   8.98578645e-011,   1.00000000e+000],\n",
       "       [  2.75337356e-217,   6.58848819e-009,   9.99999993e-001],\n",
       "       [  1.30868299e-169,   1.90227600e-003,   9.98097724e-001],\n",
       "       [  1.38946382e-129,   1.93183856e-001,   8.06816144e-001],\n",
       "       [  1.71830037e-186,   5.23126458e-006,   9.99994769e-001],\n",
       "       [  5.79667973e-220,   5.01446575e-009,   9.99999995e-001],\n",
       "       [  1.61093140e-184,   4.67798053e-007,   9.99999532e-001],\n",
       "       [  5.00845630e-151,   2.50121636e-002,   9.74987836e-001],\n",
       "       [  2.54029381e-231,   4.42556022e-009,   9.99999996e-001],\n",
       "       [  4.84219075e-234,   1.64602693e-010,   1.00000000e+000],\n",
       "       [  6.47732320e-189,   5.85507961e-007,   9.99999414e-001],\n",
       "       [  5.17352411e-148,   2.54457623e-002,   9.74554238e-001],\n",
       "       [  5.93498263e-166,   3.70166861e-004,   9.99629833e-001],\n",
       "       [  5.58649523e-197,   2.46020434e-007,   9.99999754e-001],\n",
       "       [  9.13863414e-145,   5.60050091e-002,   9.43994991e-001]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.00000000e+00,  -4.11208597e+01,  -5.78855367e+01],\n",
       "       [  0.00000000e+00,  -3.87505119e+01,  -5.67328319e+01],\n",
       "       [  0.00000000e+00,  -4.13716038e+01,  -5.90125166e+01],\n",
       "       [  0.00000000e+00,  -3.87801966e+01,  -5.65000742e+01],\n",
       "       [  0.00000000e+00,  -4.22118362e+01,  -5.87821546e+01],\n",
       "       [ -1.50990331e-14,  -3.18135483e+01,  -4.77671483e+01],\n",
       "       [  0.00000000e+00,  -3.90168287e+01,  -5.65377225e+01],\n",
       "       [  0.00000000e+00,  -3.95630818e+01,  -5.65385104e+01],\n",
       "       [  0.00000000e+00,  -3.92358214e+01,  -5.74109854e+01],\n",
       "       [  0.00000000e+00,  -4.02823057e+01,  -5.74425024e+01],\n",
       "       [  0.00000000e+00,  -3.99448015e+01,  -5.59171461e+01],\n",
       "       [  0.00000000e+00,  -3.86387316e+01,  -5.55841702e+01],\n",
       "       [  0.00000000e+00,  -4.12723776e+01,  -5.87465451e+01],\n",
       "       [  0.00000000e+00,  -4.40508700e+01,  -6.15933405e+01],\n",
       "       [  0.00000000e+00,  -4.28003869e+01,  -5.76999890e+01],\n",
       "       [  0.00000000e+00,  -3.79878625e+01,  -5.24073850e+01],\n",
       "       [  0.00000000e+00,  -3.74032812e+01,  -5.36851061e+01],\n",
       "       [  0.00000000e+00,  -3.82599527e+01,  -5.54298023e+01],\n",
       "       [ -6.21724894e-15,  -3.27019712e+01,  -4.82934105e+01],\n",
       "       [  0.00000000e+00,  -3.92554439e+01,  -5.56035585e+01],\n",
       "       [ -1.11022302e-15,  -3.44179443e+01,  -5.09302471e+01],\n",
       "       [ -6.66133815e-16,  -3.49854914e+01,  -5.18673121e+01],\n",
       "       [  0.00000000e+00,  -4.53524369e+01,  -6.21630580e+01],\n",
       "       [ -1.88369320e-11,  -2.46951950e+01,  -4.25029624e+01],\n",
       "       [ -9.76996262e-15,  -3.22509844e+01,  -4.88549336e+01],\n",
       "       [ -4.44089210e-16,  -3.56240088e+01,  -5.34064744e+01],\n",
       "       [ -1.75415238e-14,  -3.16706208e+01,  -4.92423246e+01],\n",
       "       [  0.00000000e+00,  -3.94504986e+01,  -5.60776068e+01],\n",
       "       [  0.00000000e+00,  -4.00193970e+01,  -5.69598553e+01],\n",
       "       [  0.00000000e+00,  -3.76183937e+01,  -5.50322019e+01],\n",
       "       [  0.00000000e+00,  -3.67922627e+01,  -5.44175592e+01],\n",
       "       [ -2.19824159e-14,  -3.14495987e+01,  -4.88361191e+01],\n",
       "       [  0.00000000e+00,  -4.64777463e+01,  -6.10323244e+01],\n",
       "       [  0.00000000e+00,  -4.48894830e+01,  -5.95103654e+01],\n",
       "       [  0.00000000e+00,  -4.02823057e+01,  -5.74425024e+01],\n",
       "       [  0.00000000e+00,  -4.11737926e+01,  -5.87969507e+01],\n",
       "       [  0.00000000e+00,  -4.01390763e+01,  -5.66409002e+01],\n",
       "       [  0.00000000e+00,  -4.02823057e+01,  -5.74425024e+01],\n",
       "       [  0.00000000e+00,  -4.07096317e+01,  -5.87377123e+01],\n",
       "       [  0.00000000e+00,  -3.91876179e+01,  -5.61142420e+01],\n",
       "       [  0.00000000e+00,  -3.95937603e+01,  -5.68754065e+01],\n",
       "       [ -8.88178420e-16,  -3.48281190e+01,  -5.46456650e+01],\n",
       "       [  0.00000000e+00,  -4.18405880e+01,  -5.94319738e+01],\n",
       "       [ -6.24451602e-11,  -2.34967248e+01,  -4.10128301e+01],\n",
       "       [ -8.14459611e-13,  -2.78361426e+01,  -4.40338704e+01],\n",
       "       [ -2.22044605e-16,  -3.61774145e+01,  -5.45875862e+01],\n",
       "       [  0.00000000e+00,  -4.05725544e+01,  -5.64270855e+01],\n",
       "       [  0.00000000e+00,  -4.06134153e+01,  -5.81878898e+01],\n",
       "       [  0.00000000e+00,  -4.04517469e+01,  -5.65120841e+01],\n",
       "       [  0.00000000e+00,  -4.01653212e+01,  -5.74485852e+01],\n",
       "       [ -2.48052568e+02,  -2.18109163e-01,  -1.62983281e+00],\n",
       "       [ -2.30738394e+02,  -5.63908550e-02,  -2.90351121e+00],\n",
       "       [ -2.80491279e+02,  -7.84930690e-01,  -6.09084226e-01],\n",
       "       [ -1.60415501e+02,  -3.12493439e-05,  -1.03735278e+01],\n",
       "       [ -2.44173908e+02,  -4.87262645e-02,  -3.04580129e+00],\n",
       "       [ -2.06975902e+02,  -8.80760321e-04,  -7.03516537e+00],\n",
       "       [ -2.61492267e+02,  -4.17104153e-01,  -1.07573288e+00],\n",
       "       [ -7.81077843e+01,  -2.33206936e-07,  -1.52713398e+01],\n",
       "       [ -2.24546277e+02,  -9.73088268e-03,  -4.63731216e+00],\n",
       "       [ -1.58620033e+02,  -9.02576814e-05,  -9.31288698e+00],\n",
       "       [ -9.34195242e+01,  -2.35068255e-07,  -1.52633900e+01],\n",
       "       [ -1.98308513e+02,  -3.76880673e-03,  -5.58288066e+00],\n",
       "       [ -1.38601134e+02,  -6.01634294e-06,  -1.20210340e+01],\n",
       "       [ -2.40199046e+02,  -1.40068145e-02,  -4.27520655e+00],\n",
       "       [ -1.26096900e+02,  -2.46129435e-05,  -1.06122504e+01],\n",
       "       [ -2.13966954e+02,  -2.01649503e-02,  -3.91387485e+00],\n",
       "       [ -2.25487740e+02,  -9.35636191e-03,  -4.67637328e+00],\n",
       "       [ -1.44223302e+02,  -1.63374144e-05,  -1.10220609e+01],\n",
       "       [ -2.33161854e+02,  -5.31700240e-03,  -5.23950292e+00],\n",
       "       [ -1.34144688e+02,  -6.99366761e-06,  -1.18705089e+01],\n",
       "       [ -2.95027181e+02,  -1.86759947e+00,  -1.67820115e-01],\n",
       "       [ -1.62730156e+02,  -1.92992469e-04,  -8.55295589e+00],\n",
       "       [ -2.76246088e+02,  -7.57185971e-02,  -2.61835190e+00],\n",
       "       [ -2.21783330e+02,  -1.84518185e-03,  -6.29609989e+00],\n",
       "       [ -1.92417591e+02,  -1.54036992e-03,  -6.47650277e+00],\n",
       "       [ -2.13431507e+02,  -1.26080671e-02,  -4.37971584e+00],\n",
       "       [ -2.58592703e+02,  -9.11897920e-02,  -2.44006076e+00],\n",
       "       [ -3.14700239e+02,  -2.58668517e+00,  -7.82525369e-02],\n",
       "       [ -2.28824133e+02,  -1.36119554e-02,  -4.30360506e+00],\n",
       "       [ -9.51756427e+01,  -1.23794287e-06,  -1.36020601e+01],\n",
       "       [ -1.25622344e+02,  -3.55252462e-06,  -1.25478538e+01],\n",
       "       [ -1.09762853e+02,  -1.34924015e-06,  -1.35159697e+01],\n",
       "       [ -1.43170407e+02,  -2.76527750e-05,  -1.04957983e+01],\n",
       "       [ -3.07586574e+02,  -4.90761846e-01,  -9.47161995e-01],\n",
       "       [ -2.24340564e+02,  -7.55180548e-03,  -4.88974213e+00],\n",
       "       [ -2.37042011e+02,  -1.32266420e-01,  -2.08834144e+00],\n",
       "       [ -2.55530691e+02,  -2.24025500e-01,  -1.60591787e+00],\n",
       "       [ -2.03604220e+02,  -6.14771461e-04,  -7.39456734e+00],\n",
       "       [ -1.66964124e+02,  -2.03750870e-04,  -8.49871441e+00],\n",
       "       [ -1.59751333e+02,  -4.47674653e-05,  -1.00140513e+01],\n",
       "       [ -1.87444075e+02,  -1.26328301e-04,  -8.97668964e+00],\n",
       "       [ -2.29061946e+02,  -1.06854191e-02,  -4.54421312e+00],\n",
       "       [ -1.52155085e+02,  -3.37718907e-05,  -1.02958986e+01],\n",
       "       [ -7.87548415e+01,  -2.02487942e-07,  -1.54125856e+01],\n",
       "       [ -1.77565145e+02,  -1.67685437e-04,  -8.69350458e+00],\n",
       "       [ -1.67627763e+02,  -1.50136407e-04,  -8.80404136e+00],\n",
       "       [ -1.77272780e+02,  -2.85093986e-04,  -8.16283420e+00],\n",
       "       [ -1.90570452e+02,  -1.00814508e-03,  -6.90014722e+00],\n",
       "       [ -6.76595831e+01,  -2.31316924e-07,  -1.52794772e+01],\n",
       "       [ -1.68600092e+02,  -1.52851668e-04,  -8.78611902e+00],\n",
       "       [ -5.76528695e+02,  -2.34793813e+01,  -6.35380637e-11],\n",
       "       [ -3.46079221e+02,  -3.68839303e+00,  -2.53302835e-02],\n",
       "       [ -5.01915316e+02,  -1.55998057e+01,  -1.67915395e-07],\n",
       "       [ -4.02192362e+02,  -6.21729985e+00,  -1.99661565e-03],\n",
       "       [ -4.95383744e+02,  -1.52828267e+01,  -2.30543434e-07],\n",
       "       [ -6.22492812e+02,  -2.21463196e+01,  -2.40977016e-10],\n",
       "       [ -2.47154107e+02,  -2.68427191e-02,  -3.63115200e+00],\n",
       "       [ -5.21888447e+02,  -1.35227055e+01,  -1.34018237e-06],\n",
       "       [ -4.36746429e+02,  -7.61520062e+00,  -4.93023301e-04],\n",
       "       [ -6.03094508e+02,  -2.72904971e+01,  -1.40598644e-12],\n",
       "       [ -3.67126147e+02,  -7.79234360e+00,  -4.12969376e-04],\n",
       "       [ -3.77747570e+02,  -5.88623220e+00,  -2.78128597e-03],\n",
       "       [ -4.40168625e+02,  -1.22454127e+01,  -4.80713017e-06],\n",
       "       [ -3.48586297e+02,  -4.35202467e+00,  -1.29643826e-02],\n",
       "       [ -4.29571255e+02,  -1.37738535e+01,  -1.04253739e-06],\n",
       "       [ -4.41726495e+02,  -1.46119054e+01,  -4.50951887e-07],\n",
       "       [ -3.90421773e+02,  -6.28076617e+00,  -1.87372012e-03],\n",
       "       [ -6.54914190e+02,  -2.71328253e+01,  -1.64490643e-12],\n",
       "       [ -7.12254776e+02,  -2.80658015e+01,  -6.47482068e-13],\n",
       "       [ -2.86083201e+02,  -4.27662147e-02,  -3.17331377e+00],\n",
       "       [ -5.03186707e+02,  -1.82626784e+01,  -1.17116898e-08],\n",
       "       [ -3.35138824e+02,  -4.28580072e+00,  -1.38581796e-02],\n",
       "       [ -6.26187694e+02,  -2.10000206e+01,  -7.58240581e-10],\n",
       "       [ -3.12323599e+02,  -2.04032292e+00,  -1.39246813e-01],\n",
       "       [ -4.65698806e+02,  -1.38441385e+01,  -9.71778424e-07],\n",
       "       [ -4.72166196e+02,  -1.18141630e+01,  -7.39904730e-06],\n",
       "       [ -2.99339133e+02,  -1.60979688e+00,  -2.23053830e-01],\n",
       "       [ -3.09308365e+02,  -2.23041763e+00,  -1.13710314e-01],\n",
       "       [ -4.49376980e+02,  -1.14224651e+01,  -1.09468413e-05],\n",
       "       [ -4.16289573e+02,  -7.26185395e+00,  -7.02052098e-04],\n",
       "       [ -5.06724696e+02,  -1.39139634e+01,  -9.06238851e-07],\n",
       "       [ -5.75425351e+02,  -2.19381967e+01,  -2.96730640e-10],\n",
       "       [ -4.66130391e+02,  -1.34048044e+01,  -1.50788342e-06],\n",
       "       [ -2.98548520e+02,  -3.38771676e-01,  -1.24703740e+00],\n",
       "       [ -3.50990031e+02,  -7.21136687e-01,  -6.65919804e-01],\n",
       "       [ -5.77189946e+02,  -2.31327920e+01,  -8.98578989e-11],\n",
       "       [ -4.98648138e+02,  -1.88379419e+01,  -6.58848798e-09],\n",
       "       [ -3.88867859e+02,  -6.26470421e+00,  -1.90408763e-03],\n",
       "       [ -2.96704559e+02,  -1.64411292e+00,  -2.14659463e-01],\n",
       "       [ -4.27739492e+02,  -1.21608575e+01,  -5.23127826e-06],\n",
       "       [ -5.04811435e+02,  -1.91109390e+01,  -5.01446573e-09],\n",
       "       [ -4.23198845e+02,  -1.45752291e+01,  -4.67798162e-07],\n",
       "       [ -3.46079221e+02,  -3.68839303e+00,  -2.53302835e-02],\n",
       "       [ -5.30964877e+02,  -1.92358690e+01,  -4.42555992e-09],\n",
       "       [ -5.37227545e+02,  -2.25274865e+01,  -1.64602554e-10],\n",
       "       [ -4.33320275e+02,  -1.43507861e+01,  -5.85508133e-07],\n",
       "       [ -3.39139040e+02,  -3.67120606e+00,  -2.57751046e-02],\n",
       "       [ -3.80448261e+02,  -7.90155668e+00,  -3.70235390e-04],\n",
       "       [ -4.51888911e+02,  -1.52178512e+01,  -2.46020464e-07],\n",
       "       [ -3.31662328e+02,  -2.88231414e+00,  -5.76344191e-02]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict_log_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.22222222,  0.625     ,  0.06779661,  0.04166667],\n",
       "       [ 0.16666667,  0.41666667,  0.06779661,  0.04166667],\n",
       "       [ 0.11111111,  0.5       ,  0.05084746,  0.04166667],\n",
       "       [ 0.08333333,  0.45833333,  0.08474576,  0.04166667],\n",
       "       [ 0.19444444,  0.66666667,  0.06779661,  0.04166667],\n",
       "       [ 0.30555556,  0.79166667,  0.11864407,  0.125     ],\n",
       "       [ 0.08333333,  0.58333333,  0.06779661,  0.08333333],\n",
       "       [ 0.19444444,  0.58333333,  0.08474576,  0.04166667],\n",
       "       [ 0.02777778,  0.375     ,  0.06779661,  0.04166667],\n",
       "       [ 0.16666667,  0.45833333,  0.08474576,  0.        ],\n",
       "       [ 0.30555556,  0.70833333,  0.08474576,  0.04166667],\n",
       "       [ 0.13888889,  0.58333333,  0.10169492,  0.04166667],\n",
       "       [ 0.13888889,  0.41666667,  0.06779661,  0.        ],\n",
       "       [ 0.        ,  0.41666667,  0.01694915,  0.        ],\n",
       "       [ 0.41666667,  0.83333333,  0.03389831,  0.04166667],\n",
       "       [ 0.38888889,  1.        ,  0.08474576,  0.125     ],\n",
       "       [ 0.30555556,  0.79166667,  0.05084746,  0.125     ],\n",
       "       [ 0.22222222,  0.625     ,  0.06779661,  0.08333333],\n",
       "       [ 0.38888889,  0.75      ,  0.11864407,  0.08333333],\n",
       "       [ 0.22222222,  0.75      ,  0.08474576,  0.08333333],\n",
       "       [ 0.30555556,  0.58333333,  0.11864407,  0.04166667],\n",
       "       [ 0.22222222,  0.70833333,  0.08474576,  0.125     ],\n",
       "       [ 0.08333333,  0.66666667,  0.        ,  0.04166667],\n",
       "       [ 0.22222222,  0.54166667,  0.11864407,  0.16666667],\n",
       "       [ 0.13888889,  0.58333333,  0.15254237,  0.04166667],\n",
       "       [ 0.19444444,  0.41666667,  0.10169492,  0.04166667],\n",
       "       [ 0.19444444,  0.58333333,  0.10169492,  0.125     ],\n",
       "       [ 0.25      ,  0.625     ,  0.08474576,  0.04166667],\n",
       "       [ 0.25      ,  0.58333333,  0.06779661,  0.04166667],\n",
       "       [ 0.11111111,  0.5       ,  0.10169492,  0.04166667],\n",
       "       [ 0.13888889,  0.45833333,  0.10169492,  0.04166667],\n",
       "       [ 0.30555556,  0.58333333,  0.08474576,  0.125     ],\n",
       "       [ 0.25      ,  0.875     ,  0.08474576,  0.        ],\n",
       "       [ 0.33333333,  0.91666667,  0.06779661,  0.04166667],\n",
       "       [ 0.16666667,  0.45833333,  0.08474576,  0.        ],\n",
       "       [ 0.19444444,  0.5       ,  0.03389831,  0.04166667],\n",
       "       [ 0.33333333,  0.625     ,  0.05084746,  0.04166667],\n",
       "       [ 0.16666667,  0.45833333,  0.08474576,  0.        ],\n",
       "       [ 0.02777778,  0.41666667,  0.05084746,  0.04166667],\n",
       "       [ 0.22222222,  0.58333333,  0.08474576,  0.04166667],\n",
       "       [ 0.19444444,  0.625     ,  0.05084746,  0.08333333],\n",
       "       [ 0.05555556,  0.125     ,  0.05084746,  0.08333333],\n",
       "       [ 0.02777778,  0.5       ,  0.05084746,  0.04166667],\n",
       "       [ 0.19444444,  0.625     ,  0.10169492,  0.20833333],\n",
       "       [ 0.22222222,  0.75      ,  0.15254237,  0.125     ],\n",
       "       [ 0.13888889,  0.41666667,  0.06779661,  0.08333333],\n",
       "       [ 0.22222222,  0.75      ,  0.10169492,  0.04166667],\n",
       "       [ 0.08333333,  0.5       ,  0.06779661,  0.04166667],\n",
       "       [ 0.27777778,  0.70833333,  0.08474576,  0.04166667],\n",
       "       [ 0.19444444,  0.54166667,  0.06779661,  0.04166667],\n",
       "       [ 0.75      ,  0.5       ,  0.62711864,  0.54166667],\n",
       "       [ 0.58333333,  0.5       ,  0.59322034,  0.58333333],\n",
       "       [ 0.72222222,  0.45833333,  0.66101695,  0.58333333],\n",
       "       [ 0.33333333,  0.125     ,  0.50847458,  0.5       ],\n",
       "       [ 0.61111111,  0.33333333,  0.61016949,  0.58333333],\n",
       "       [ 0.38888889,  0.33333333,  0.59322034,  0.5       ],\n",
       "       [ 0.55555556,  0.54166667,  0.62711864,  0.625     ],\n",
       "       [ 0.16666667,  0.16666667,  0.38983051,  0.375     ],\n",
       "       [ 0.63888889,  0.375     ,  0.61016949,  0.5       ],\n",
       "       [ 0.25      ,  0.29166667,  0.49152542,  0.54166667],\n",
       "       [ 0.19444444,  0.        ,  0.42372881,  0.375     ],\n",
       "       [ 0.44444444,  0.41666667,  0.54237288,  0.58333333],\n",
       "       [ 0.47222222,  0.08333333,  0.50847458,  0.375     ],\n",
       "       [ 0.5       ,  0.375     ,  0.62711864,  0.54166667],\n",
       "       [ 0.36111111,  0.375     ,  0.44067797,  0.5       ],\n",
       "       [ 0.66666667,  0.45833333,  0.57627119,  0.54166667],\n",
       "       [ 0.36111111,  0.41666667,  0.59322034,  0.58333333],\n",
       "       [ 0.41666667,  0.29166667,  0.52542373,  0.375     ],\n",
       "       [ 0.52777778,  0.08333333,  0.59322034,  0.58333333],\n",
       "       [ 0.36111111,  0.20833333,  0.49152542,  0.41666667],\n",
       "       [ 0.44444444,  0.5       ,  0.6440678 ,  0.70833333],\n",
       "       [ 0.5       ,  0.33333333,  0.50847458,  0.5       ],\n",
       "       [ 0.55555556,  0.20833333,  0.66101695,  0.58333333],\n",
       "       [ 0.5       ,  0.33333333,  0.62711864,  0.45833333],\n",
       "       [ 0.58333333,  0.375     ,  0.55932203,  0.5       ],\n",
       "       [ 0.63888889,  0.41666667,  0.57627119,  0.54166667],\n",
       "       [ 0.69444444,  0.33333333,  0.6440678 ,  0.54166667],\n",
       "       [ 0.66666667,  0.41666667,  0.6779661 ,  0.66666667],\n",
       "       [ 0.47222222,  0.375     ,  0.59322034,  0.58333333],\n",
       "       [ 0.38888889,  0.25      ,  0.42372881,  0.375     ],\n",
       "       [ 0.33333333,  0.16666667,  0.47457627,  0.41666667],\n",
       "       [ 0.33333333,  0.16666667,  0.45762712,  0.375     ],\n",
       "       [ 0.41666667,  0.29166667,  0.49152542,  0.45833333],\n",
       "       [ 0.47222222,  0.29166667,  0.69491525,  0.625     ],\n",
       "       [ 0.30555556,  0.41666667,  0.59322034,  0.58333333],\n",
       "       [ 0.47222222,  0.58333333,  0.59322034,  0.625     ],\n",
       "       [ 0.66666667,  0.45833333,  0.62711864,  0.58333333],\n",
       "       [ 0.55555556,  0.125     ,  0.57627119,  0.5       ],\n",
       "       [ 0.36111111,  0.41666667,  0.52542373,  0.5       ],\n",
       "       [ 0.33333333,  0.20833333,  0.50847458,  0.5       ],\n",
       "       [ 0.33333333,  0.25      ,  0.57627119,  0.45833333],\n",
       "       [ 0.5       ,  0.41666667,  0.61016949,  0.54166667],\n",
       "       [ 0.41666667,  0.25      ,  0.50847458,  0.45833333],\n",
       "       [ 0.19444444,  0.125     ,  0.38983051,  0.375     ],\n",
       "       [ 0.36111111,  0.29166667,  0.54237288,  0.5       ],\n",
       "       [ 0.38888889,  0.41666667,  0.54237288,  0.45833333],\n",
       "       [ 0.38888889,  0.375     ,  0.54237288,  0.5       ],\n",
       "       [ 0.52777778,  0.375     ,  0.55932203,  0.5       ],\n",
       "       [ 0.22222222,  0.20833333,  0.33898305,  0.41666667],\n",
       "       [ 0.38888889,  0.33333333,  0.52542373,  0.5       ],\n",
       "       [ 0.55555556,  0.54166667,  0.84745763,  1.        ],\n",
       "       [ 0.41666667,  0.29166667,  0.69491525,  0.75      ],\n",
       "       [ 0.77777778,  0.41666667,  0.83050847,  0.83333333],\n",
       "       [ 0.55555556,  0.375     ,  0.77966102,  0.70833333],\n",
       "       [ 0.61111111,  0.41666667,  0.81355932,  0.875     ],\n",
       "       [ 0.91666667,  0.41666667,  0.94915254,  0.83333333],\n",
       "       [ 0.16666667,  0.20833333,  0.59322034,  0.66666667],\n",
       "       [ 0.83333333,  0.375     ,  0.89830508,  0.70833333],\n",
       "       [ 0.66666667,  0.20833333,  0.81355932,  0.70833333],\n",
       "       [ 0.80555556,  0.66666667,  0.86440678,  1.        ],\n",
       "       [ 0.61111111,  0.5       ,  0.69491525,  0.79166667],\n",
       "       [ 0.58333333,  0.29166667,  0.72881356,  0.75      ],\n",
       "       [ 0.69444444,  0.41666667,  0.76271186,  0.83333333],\n",
       "       [ 0.38888889,  0.20833333,  0.6779661 ,  0.79166667],\n",
       "       [ 0.41666667,  0.33333333,  0.69491525,  0.95833333],\n",
       "       [ 0.58333333,  0.5       ,  0.72881356,  0.91666667],\n",
       "       [ 0.61111111,  0.41666667,  0.76271186,  0.70833333],\n",
       "       [ 0.94444444,  0.75      ,  0.96610169,  0.875     ],\n",
       "       [ 0.94444444,  0.25      ,  1.        ,  0.91666667],\n",
       "       [ 0.47222222,  0.08333333,  0.6779661 ,  0.58333333],\n",
       "       [ 0.72222222,  0.5       ,  0.79661017,  0.91666667],\n",
       "       [ 0.36111111,  0.33333333,  0.66101695,  0.79166667],\n",
       "       [ 0.94444444,  0.33333333,  0.96610169,  0.79166667],\n",
       "       [ 0.55555556,  0.29166667,  0.66101695,  0.70833333],\n",
       "       [ 0.66666667,  0.54166667,  0.79661017,  0.83333333],\n",
       "       [ 0.80555556,  0.5       ,  0.84745763,  0.70833333],\n",
       "       [ 0.52777778,  0.33333333,  0.6440678 ,  0.70833333],\n",
       "       [ 0.5       ,  0.41666667,  0.66101695,  0.70833333],\n",
       "       [ 0.58333333,  0.33333333,  0.77966102,  0.83333333],\n",
       "       [ 0.80555556,  0.41666667,  0.81355932,  0.625     ],\n",
       "       [ 0.86111111,  0.33333333,  0.86440678,  0.75      ],\n",
       "       [ 1.        ,  0.75      ,  0.91525424,  0.79166667],\n",
       "       [ 0.58333333,  0.33333333,  0.77966102,  0.875     ],\n",
       "       [ 0.55555556,  0.33333333,  0.69491525,  0.58333333],\n",
       "       [ 0.5       ,  0.25      ,  0.77966102,  0.54166667],\n",
       "       [ 0.94444444,  0.41666667,  0.86440678,  0.91666667],\n",
       "       [ 0.55555556,  0.58333333,  0.77966102,  0.95833333],\n",
       "       [ 0.58333333,  0.45833333,  0.76271186,  0.70833333],\n",
       "       [ 0.47222222,  0.41666667,  0.6440678 ,  0.70833333],\n",
       "       [ 0.72222222,  0.45833333,  0.74576271,  0.83333333],\n",
       "       [ 0.66666667,  0.45833333,  0.77966102,  0.95833333],\n",
       "       [ 0.72222222,  0.45833333,  0.69491525,  0.91666667],\n",
       "       [ 0.41666667,  0.29166667,  0.69491525,  0.75      ],\n",
       "       [ 0.69444444,  0.5       ,  0.83050847,  0.91666667],\n",
       "       [ 0.66666667,  0.54166667,  0.79661017,  1.        ],\n",
       "       [ 0.66666667,  0.41666667,  0.71186441,  0.91666667],\n",
       "       [ 0.55555556,  0.20833333,  0.6779661 ,  0.75      ],\n",
       "       [ 0.61111111,  0.41666667,  0.71186441,  0.79166667],\n",
       "       [ 0.52777778,  0.58333333,  0.74576271,  0.91666667],\n",
       "       [ 0.44444444,  0.41666667,  0.69491525,  0.70833333]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0, -1,  0,  0,  0,  0,  0,  0,  0,  0,  1,\n",
       "        1,  1,  1,  1,  1,  1, -1,  1,  1, -1,  1,  1,  1,  1,  1,  1,  1,\n",
       "       -1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1, -1,  1,  1,  1,  1,  1, -1,  1,  1,  1,  1, -1,  1,  1,  1,\n",
       "        1,  1,  1, -1, -1,  1, -1, -1,  1,  1,  1,  1,  1,  1,  1, -1, -1,\n",
       "        1,  1,  1, -1,  1,  1,  1,  1,  1,  1,  1,  1, -1,  1,  1, -1, -1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1], dtype=int64)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbscanner.fit_predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen, in order to have access for each object's output, one needs to call different methods. So as to offer a homogeneous interface a collection of adapters is available in PipeGraph. Them all derive from the ```AdapterForSkLearnLikeAdaptee``` baseclass. This class is an adapter for Scikit-Learn objects in order to provide a common interface based on fit and predict methods irrespectively of whether the adapted object provided a ```transform```, ```fit_predict```, or ```predict interface```.\n",
    "\n",
    "As it can be seen from the following code fragment, the ```fit``` and ```predict``` allow for an arbitrary number of positional and keyword based parameters. These will have to be coherent with the adaptees expectations, but at least we are not imposing hard constrains to the adapter's interface.\n",
    "```\n",
    "class AdapterForSkLearnLikeAdaptee(BaseEstimator):\n",
    "    def fit(self, *pargs, **kwargs):\n",
    "       ...\n",
    "    def predict(self, *pargs, **kwargs):\n",
    "       ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those sklearn objects following the ```predict``` protocol can be wrapped into the class ```AdapterForFitPredictAdaptee```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predict': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'predict_log_proba': array([[  0.00000000e+00,  -4.11208597e+01,  -5.78855367e+01],\n",
       "        [  0.00000000e+00,  -3.87505119e+01,  -5.67328319e+01],\n",
       "        [  0.00000000e+00,  -4.13716038e+01,  -5.90125166e+01],\n",
       "        [  0.00000000e+00,  -3.87801966e+01,  -5.65000742e+01],\n",
       "        [  0.00000000e+00,  -4.22118362e+01,  -5.87821546e+01],\n",
       "        [ -1.50990331e-14,  -3.18135483e+01,  -4.77671483e+01],\n",
       "        [  0.00000000e+00,  -3.90168287e+01,  -5.65377225e+01],\n",
       "        [  0.00000000e+00,  -3.95630818e+01,  -5.65385104e+01],\n",
       "        [  0.00000000e+00,  -3.92358214e+01,  -5.74109854e+01],\n",
       "        [  0.00000000e+00,  -4.02823057e+01,  -5.74425024e+01],\n",
       "        [  0.00000000e+00,  -3.99448015e+01,  -5.59171461e+01],\n",
       "        [  0.00000000e+00,  -3.86387316e+01,  -5.55841702e+01],\n",
       "        [  0.00000000e+00,  -4.12723776e+01,  -5.87465451e+01],\n",
       "        [  0.00000000e+00,  -4.40508700e+01,  -6.15933405e+01],\n",
       "        [  0.00000000e+00,  -4.28003869e+01,  -5.76999890e+01],\n",
       "        [  0.00000000e+00,  -3.79878625e+01,  -5.24073850e+01],\n",
       "        [  0.00000000e+00,  -3.74032812e+01,  -5.36851061e+01],\n",
       "        [  0.00000000e+00,  -3.82599527e+01,  -5.54298023e+01],\n",
       "        [ -6.21724894e-15,  -3.27019712e+01,  -4.82934105e+01],\n",
       "        [  0.00000000e+00,  -3.92554439e+01,  -5.56035585e+01],\n",
       "        [ -1.11022302e-15,  -3.44179443e+01,  -5.09302471e+01],\n",
       "        [ -6.66133815e-16,  -3.49854914e+01,  -5.18673121e+01],\n",
       "        [  0.00000000e+00,  -4.53524369e+01,  -6.21630580e+01],\n",
       "        [ -1.88369320e-11,  -2.46951950e+01,  -4.25029624e+01],\n",
       "        [ -9.76996262e-15,  -3.22509844e+01,  -4.88549336e+01],\n",
       "        [ -4.44089210e-16,  -3.56240088e+01,  -5.34064744e+01],\n",
       "        [ -1.75415238e-14,  -3.16706208e+01,  -4.92423246e+01],\n",
       "        [  0.00000000e+00,  -3.94504986e+01,  -5.60776068e+01],\n",
       "        [  0.00000000e+00,  -4.00193970e+01,  -5.69598553e+01],\n",
       "        [  0.00000000e+00,  -3.76183937e+01,  -5.50322019e+01],\n",
       "        [  0.00000000e+00,  -3.67922627e+01,  -5.44175592e+01],\n",
       "        [ -2.19824159e-14,  -3.14495987e+01,  -4.88361191e+01],\n",
       "        [  0.00000000e+00,  -4.64777463e+01,  -6.10323244e+01],\n",
       "        [  0.00000000e+00,  -4.48894830e+01,  -5.95103654e+01],\n",
       "        [  0.00000000e+00,  -4.02823057e+01,  -5.74425024e+01],\n",
       "        [  0.00000000e+00,  -4.11737926e+01,  -5.87969507e+01],\n",
       "        [  0.00000000e+00,  -4.01390763e+01,  -5.66409002e+01],\n",
       "        [  0.00000000e+00,  -4.02823057e+01,  -5.74425024e+01],\n",
       "        [  0.00000000e+00,  -4.07096317e+01,  -5.87377123e+01],\n",
       "        [  0.00000000e+00,  -3.91876179e+01,  -5.61142420e+01],\n",
       "        [  0.00000000e+00,  -3.95937603e+01,  -5.68754065e+01],\n",
       "        [ -8.88178420e-16,  -3.48281190e+01,  -5.46456650e+01],\n",
       "        [  0.00000000e+00,  -4.18405880e+01,  -5.94319738e+01],\n",
       "        [ -6.24451602e-11,  -2.34967248e+01,  -4.10128301e+01],\n",
       "        [ -8.14459611e-13,  -2.78361426e+01,  -4.40338704e+01],\n",
       "        [ -2.22044605e-16,  -3.61774145e+01,  -5.45875862e+01],\n",
       "        [  0.00000000e+00,  -4.05725544e+01,  -5.64270855e+01],\n",
       "        [  0.00000000e+00,  -4.06134153e+01,  -5.81878898e+01],\n",
       "        [  0.00000000e+00,  -4.04517469e+01,  -5.65120841e+01],\n",
       "        [  0.00000000e+00,  -4.01653212e+01,  -5.74485852e+01],\n",
       "        [ -2.48052568e+02,  -2.18109163e-01,  -1.62983281e+00],\n",
       "        [ -2.30738394e+02,  -5.63908550e-02,  -2.90351121e+00],\n",
       "        [ -2.80491279e+02,  -7.84930690e-01,  -6.09084226e-01],\n",
       "        [ -1.60415501e+02,  -3.12493439e-05,  -1.03735278e+01],\n",
       "        [ -2.44173908e+02,  -4.87262645e-02,  -3.04580129e+00],\n",
       "        [ -2.06975902e+02,  -8.80760321e-04,  -7.03516537e+00],\n",
       "        [ -2.61492267e+02,  -4.17104153e-01,  -1.07573288e+00],\n",
       "        [ -7.81077843e+01,  -2.33206936e-07,  -1.52713398e+01],\n",
       "        [ -2.24546277e+02,  -9.73088268e-03,  -4.63731216e+00],\n",
       "        [ -1.58620033e+02,  -9.02576814e-05,  -9.31288698e+00],\n",
       "        [ -9.34195242e+01,  -2.35068255e-07,  -1.52633900e+01],\n",
       "        [ -1.98308513e+02,  -3.76880673e-03,  -5.58288066e+00],\n",
       "        [ -1.38601134e+02,  -6.01634294e-06,  -1.20210340e+01],\n",
       "        [ -2.40199046e+02,  -1.40068145e-02,  -4.27520655e+00],\n",
       "        [ -1.26096900e+02,  -2.46129435e-05,  -1.06122504e+01],\n",
       "        [ -2.13966954e+02,  -2.01649503e-02,  -3.91387485e+00],\n",
       "        [ -2.25487740e+02,  -9.35636191e-03,  -4.67637328e+00],\n",
       "        [ -1.44223302e+02,  -1.63374144e-05,  -1.10220609e+01],\n",
       "        [ -2.33161854e+02,  -5.31700240e-03,  -5.23950292e+00],\n",
       "        [ -1.34144688e+02,  -6.99366761e-06,  -1.18705089e+01],\n",
       "        [ -2.95027181e+02,  -1.86759947e+00,  -1.67820115e-01],\n",
       "        [ -1.62730156e+02,  -1.92992469e-04,  -8.55295589e+00],\n",
       "        [ -2.76246088e+02,  -7.57185971e-02,  -2.61835190e+00],\n",
       "        [ -2.21783330e+02,  -1.84518185e-03,  -6.29609989e+00],\n",
       "        [ -1.92417591e+02,  -1.54036992e-03,  -6.47650277e+00],\n",
       "        [ -2.13431507e+02,  -1.26080671e-02,  -4.37971584e+00],\n",
       "        [ -2.58592703e+02,  -9.11897920e-02,  -2.44006076e+00],\n",
       "        [ -3.14700239e+02,  -2.58668517e+00,  -7.82525369e-02],\n",
       "        [ -2.28824133e+02,  -1.36119554e-02,  -4.30360506e+00],\n",
       "        [ -9.51756427e+01,  -1.23794287e-06,  -1.36020601e+01],\n",
       "        [ -1.25622344e+02,  -3.55252462e-06,  -1.25478538e+01],\n",
       "        [ -1.09762853e+02,  -1.34924015e-06,  -1.35159697e+01],\n",
       "        [ -1.43170407e+02,  -2.76527750e-05,  -1.04957983e+01],\n",
       "        [ -3.07586574e+02,  -4.90761846e-01,  -9.47161995e-01],\n",
       "        [ -2.24340564e+02,  -7.55180548e-03,  -4.88974213e+00],\n",
       "        [ -2.37042011e+02,  -1.32266420e-01,  -2.08834144e+00],\n",
       "        [ -2.55530691e+02,  -2.24025500e-01,  -1.60591787e+00],\n",
       "        [ -2.03604220e+02,  -6.14771461e-04,  -7.39456734e+00],\n",
       "        [ -1.66964124e+02,  -2.03750870e-04,  -8.49871441e+00],\n",
       "        [ -1.59751333e+02,  -4.47674653e-05,  -1.00140513e+01],\n",
       "        [ -1.87444075e+02,  -1.26328301e-04,  -8.97668964e+00],\n",
       "        [ -2.29061946e+02,  -1.06854191e-02,  -4.54421312e+00],\n",
       "        [ -1.52155085e+02,  -3.37718907e-05,  -1.02958986e+01],\n",
       "        [ -7.87548415e+01,  -2.02487942e-07,  -1.54125856e+01],\n",
       "        [ -1.77565145e+02,  -1.67685437e-04,  -8.69350458e+00],\n",
       "        [ -1.67627763e+02,  -1.50136407e-04,  -8.80404136e+00],\n",
       "        [ -1.77272780e+02,  -2.85093986e-04,  -8.16283420e+00],\n",
       "        [ -1.90570452e+02,  -1.00814508e-03,  -6.90014722e+00],\n",
       "        [ -6.76595831e+01,  -2.31316924e-07,  -1.52794772e+01],\n",
       "        [ -1.68600092e+02,  -1.52851668e-04,  -8.78611902e+00],\n",
       "        [ -5.76528695e+02,  -2.34793813e+01,  -6.35380637e-11],\n",
       "        [ -3.46079221e+02,  -3.68839303e+00,  -2.53302835e-02],\n",
       "        [ -5.01915316e+02,  -1.55998057e+01,  -1.67915395e-07],\n",
       "        [ -4.02192362e+02,  -6.21729985e+00,  -1.99661565e-03],\n",
       "        [ -4.95383744e+02,  -1.52828267e+01,  -2.30543434e-07],\n",
       "        [ -6.22492812e+02,  -2.21463196e+01,  -2.40977016e-10],\n",
       "        [ -2.47154107e+02,  -2.68427191e-02,  -3.63115200e+00],\n",
       "        [ -5.21888447e+02,  -1.35227055e+01,  -1.34018237e-06],\n",
       "        [ -4.36746429e+02,  -7.61520062e+00,  -4.93023301e-04],\n",
       "        [ -6.03094508e+02,  -2.72904971e+01,  -1.40598644e-12],\n",
       "        [ -3.67126147e+02,  -7.79234360e+00,  -4.12969376e-04],\n",
       "        [ -3.77747570e+02,  -5.88623220e+00,  -2.78128597e-03],\n",
       "        [ -4.40168625e+02,  -1.22454127e+01,  -4.80713017e-06],\n",
       "        [ -3.48586297e+02,  -4.35202467e+00,  -1.29643826e-02],\n",
       "        [ -4.29571255e+02,  -1.37738535e+01,  -1.04253739e-06],\n",
       "        [ -4.41726495e+02,  -1.46119054e+01,  -4.50951887e-07],\n",
       "        [ -3.90421773e+02,  -6.28076617e+00,  -1.87372012e-03],\n",
       "        [ -6.54914190e+02,  -2.71328253e+01,  -1.64490643e-12],\n",
       "        [ -7.12254776e+02,  -2.80658015e+01,  -6.47482068e-13],\n",
       "        [ -2.86083201e+02,  -4.27662147e-02,  -3.17331377e+00],\n",
       "        [ -5.03186707e+02,  -1.82626784e+01,  -1.17116898e-08],\n",
       "        [ -3.35138824e+02,  -4.28580072e+00,  -1.38581796e-02],\n",
       "        [ -6.26187694e+02,  -2.10000206e+01,  -7.58240581e-10],\n",
       "        [ -3.12323599e+02,  -2.04032292e+00,  -1.39246813e-01],\n",
       "        [ -4.65698806e+02,  -1.38441385e+01,  -9.71778424e-07],\n",
       "        [ -4.72166196e+02,  -1.18141630e+01,  -7.39904730e-06],\n",
       "        [ -2.99339133e+02,  -1.60979688e+00,  -2.23053830e-01],\n",
       "        [ -3.09308365e+02,  -2.23041763e+00,  -1.13710314e-01],\n",
       "        [ -4.49376980e+02,  -1.14224651e+01,  -1.09468413e-05],\n",
       "        [ -4.16289573e+02,  -7.26185395e+00,  -7.02052098e-04],\n",
       "        [ -5.06724696e+02,  -1.39139634e+01,  -9.06238851e-07],\n",
       "        [ -5.75425351e+02,  -2.19381967e+01,  -2.96730640e-10],\n",
       "        [ -4.66130391e+02,  -1.34048044e+01,  -1.50788342e-06],\n",
       "        [ -2.98548520e+02,  -3.38771676e-01,  -1.24703740e+00],\n",
       "        [ -3.50990031e+02,  -7.21136687e-01,  -6.65919804e-01],\n",
       "        [ -5.77189946e+02,  -2.31327920e+01,  -8.98578989e-11],\n",
       "        [ -4.98648138e+02,  -1.88379419e+01,  -6.58848798e-09],\n",
       "        [ -3.88867859e+02,  -6.26470421e+00,  -1.90408763e-03],\n",
       "        [ -2.96704559e+02,  -1.64411292e+00,  -2.14659463e-01],\n",
       "        [ -4.27739492e+02,  -1.21608575e+01,  -5.23127826e-06],\n",
       "        [ -5.04811435e+02,  -1.91109390e+01,  -5.01446573e-09],\n",
       "        [ -4.23198845e+02,  -1.45752291e+01,  -4.67798162e-07],\n",
       "        [ -3.46079221e+02,  -3.68839303e+00,  -2.53302835e-02],\n",
       "        [ -5.30964877e+02,  -1.92358690e+01,  -4.42555992e-09],\n",
       "        [ -5.37227545e+02,  -2.25274865e+01,  -1.64602554e-10],\n",
       "        [ -4.33320275e+02,  -1.43507861e+01,  -5.85508133e-07],\n",
       "        [ -3.39139040e+02,  -3.67120606e+00,  -2.57751046e-02],\n",
       "        [ -3.80448261e+02,  -7.90155668e+00,  -3.70235390e-04],\n",
       "        [ -4.51888911e+02,  -1.52178512e+01,  -2.46020464e-07],\n",
       "        [ -3.31662328e+02,  -2.88231414e+00,  -5.76344191e-02]]),\n",
       " 'predict_proba': array([[  1.00000000e+000,   1.38496103e-018,   7.25489025e-026],\n",
       "        [  1.00000000e+000,   1.48206242e-017,   2.29743996e-025],\n",
       "        [  1.00000000e+000,   1.07780639e-018,   2.35065917e-026],\n",
       "        [  1.00000000e+000,   1.43871443e-017,   2.89954283e-025],\n",
       "        [  1.00000000e+000,   4.65192224e-019,   2.95961100e-026],\n",
       "        [  1.00000000e+000,   1.52598944e-014,   1.79883402e-021],\n",
       "        [  1.00000000e+000,   1.13555084e-017,   2.79240943e-025],\n",
       "        [  1.00000000e+000,   6.57615274e-018,   2.79021029e-025],\n",
       "        [  1.00000000e+000,   9.12219356e-018,   1.16607332e-025],\n",
       "        [  1.00000000e+000,   3.20344249e-018,   1.12989524e-025],\n",
       "        [  1.00000000e+000,   4.48944985e-018,   5.19388089e-025],\n",
       "        [  1.00000000e+000,   1.65734172e-017,   7.24605453e-025],\n",
       "        [  1.00000000e+000,   1.19023891e-018,   3.06690017e-026],\n",
       "        [  1.00000000e+000,   7.39520546e-020,   1.77972179e-027],\n",
       "        [  1.00000000e+000,   2.58242749e-019,   8.73399972e-026],\n",
       "        [  1.00000000e+000,   3.17746623e-017,   1.73684833e-023],\n",
       "        [  1.00000000e+000,   5.70113578e-017,   4.84010372e-024],\n",
       "        [  1.00000000e+000,   2.42054769e-017,   8.45556661e-025],\n",
       "        [  1.00000000e+000,   6.27645419e-015,   1.06276762e-021],\n",
       "        [  1.00000000e+000,   8.94493797e-018,   7.10691894e-025],\n",
       "        [  1.00000000e+000,   1.12843548e-015,   7.60807373e-023],\n",
       "        [  1.00000000e+000,   6.39726172e-016,   2.98066089e-023],\n",
       "        [  1.00000000e+000,   2.01227309e-020,   1.00676223e-027],\n",
       "        [  1.00000000e+000,   1.88370574e-011,   3.47694606e-019],\n",
       "        [  1.00000000e+000,   9.85315738e-015,   6.06138600e-022],\n",
       "        [  1.00000000e+000,   3.37823264e-016,   6.39532840e-024],\n",
       "        [  1.00000000e+000,   1.76045187e-014,   4.11462407e-022],\n",
       "        [  1.00000000e+000,   7.35980232e-018,   4.42389485e-025],\n",
       "        [  1.00000000e+000,   4.16674318e-018,   1.83083484e-025],\n",
       "        [  1.00000000e+000,   4.59768498e-017,   1.25839903e-024],\n",
       "        [  1.00000000e+000,   1.05032415e-016,   2.32677467e-024],\n",
       "        [  1.00000000e+000,   2.19590125e-014,   6.17650711e-022],\n",
       "        [  1.00000000e+000,   6.53087316e-021,   3.11887725e-027],\n",
       "        [  1.00000000e+000,   3.19701924e-020,   1.42881733e-026],\n",
       "        [  1.00000000e+000,   3.20344249e-018,   1.12989524e-025],\n",
       "        [  1.00000000e+000,   1.31355747e-018,   2.91614269e-026],\n",
       "        [  1.00000000e+000,   3.69675482e-018,   2.51866027e-025],\n",
       "        [  1.00000000e+000,   3.20344249e-018,   1.12989524e-025],\n",
       "        [  1.00000000e+000,   2.08944813e-018,   3.09410939e-026],\n",
       "        [  1.00000000e+000,   9.57268514e-018,   4.26475768e-025],\n",
       "        [  1.00000000e+000,   6.37746927e-018,   1.99216264e-025],\n",
       "        [  1.00000000e+000,   7.48755609e-016,   1.85220582e-024],\n",
       "        [  1.00000000e+000,   6.74316102e-019,   1.54533175e-026],\n",
       "        [  1.00000000e+000,   6.24456357e-011,   1.54295833e-018],\n",
       "        [  1.00000000e+000,   8.14548341e-013,   7.52199540e-020],\n",
       "        [  1.00000000e+000,   1.94244394e-016,   1.96296487e-024],\n",
       "        [  1.00000000e+000,   2.39642309e-018,   3.11909164e-025],\n",
       "        [  1.00000000e+000,   2.30047669e-018,   5.36192288e-026],\n",
       "        [  1.00000000e+000,   2.70414239e-018,   2.86492790e-025],\n",
       "        [  1.00000000e+000,   3.60099614e-018,   1.12304319e-025],\n",
       "        [  1.87127931e-108,   8.04037666e-001,   1.95962334e-001],\n",
       "        [  6.18854779e-101,   9.45169639e-001,   5.48303606e-002],\n",
       "        [  1.52821825e-122,   4.56151317e-001,   5.43848683e-001],\n",
       "        [  2.14997261e-070,   9.99968751e-001,   3.12488556e-005],\n",
       "        [  9.04938222e-107,   9.52441811e-001,   4.75581888e-002],\n",
       "        [  1.29272979e-090,   9.99119627e-001,   8.80372565e-004],\n",
       "        [  2.72490532e-114,   6.58952285e-001,   3.41047715e-001],\n",
       "        [  1.19734767e-034,   9.99999767e-001,   2.33206910e-007],\n",
       "        [  3.02545627e-098,   9.90316309e-001,   9.68369084e-003],\n",
       "        [  1.29477666e-069,   9.99909746e-001,   9.02536083e-005],\n",
       "        [  2.68173680e-041,   9.99999765e-001,   2.35068227e-007],\n",
       "        [  7.51115851e-087,   9.96238286e-001,   3.76171369e-003],\n",
       "        [  6.40165546e-061,   9.99993984e-001,   6.01632484e-006],\n",
       "        [  4.81814146e-105,   9.86090825e-001,   1.39091754e-002],\n",
       "        [  1.72509107e-055,   9.99975387e-001,   2.46126406e-005],\n",
       "        [  1.18941242e-093,   9.80037003e-001,   1.99629974e-002],\n",
       "        [  1.18009940e-098,   9.90687273e-001,   9.31272734e-003],\n",
       "        [  2.31534504e-063,   9.99983663e-001,   1.63372809e-005],\n",
       "        [  5.48394976e-102,   9.94697108e-001,   5.30289217e-003],\n",
       "        [  5.51699136e-059,   9.99993006e-001,   6.99364316e-006],\n",
       "        [  7.43572418e-129,   1.54494085e-001,   8.45505915e-001],\n",
       "        [  2.12417952e-071,   9.99807026e-001,   1.92973847e-004],\n",
       "        [  1.06622383e-120,   9.27077052e-001,   7.29229479e-002],\n",
       "        [  4.79428037e-097,   9.98156519e-001,   1.84348055e-003],\n",
       "        [  2.71707817e-084,   9.98460816e-001,   1.53918416e-003],\n",
       "        [  2.03176962e-093,   9.87471082e-001,   1.25289184e-002],\n",
       "        [  4.95012220e-113,   9.12844444e-001,   8.71555561e-002],\n",
       "        [  2.12531216e-137,   7.52691316e-002,   9.24730868e-001],\n",
       "        [  4.19702663e-100,   9.86480268e-001,   1.35197316e-002],\n",
       "        [  4.63173354e-042,   9.99998762e-001,   1.23794211e-006],\n",
       "        [  2.77274013e-055,   9.99996447e-001,   3.55251831e-006],\n",
       "        [  2.14091116e-048,   9.99998651e-001,   1.34923924e-006],\n",
       "        [  6.63563094e-063,   9.99972348e-001,   2.76523927e-005],\n",
       "        [  2.61124821e-134,   6.12159845e-001,   3.87840155e-001],\n",
       "        [  3.71647418e-098,   9.92476638e-001,   7.52336224e-003],\n",
       "        [  1.13230275e-103,   8.76107551e-001,   1.23892449e-001],\n",
       "        [  1.05786721e-111,   7.99294752e-001,   2.00705248e-001],\n",
       "        [  3.76539608e-089,   9.99385417e-001,   6.14582528e-004],\n",
       "        [  3.07894878e-073,   9.99796270e-001,   2.03730114e-004],\n",
       "        [  4.17712661e-070,   9.99955234e-001,   4.47664632e-005],\n",
       "        [  3.92710689e-082,   9.99873680e-001,   1.26320322e-004],\n",
       "        [  3.30872742e-100,   9.89371467e-001,   1.06285328e-002],\n",
       "        [  8.31545615e-067,   9.99966229e-001,   3.37713204e-005],\n",
       "        [  6.26912483e-035,   9.99999798e-001,   2.02487922e-007],\n",
       "        [  7.66367658e-078,   9.99832329e-001,   1.67671378e-004],\n",
       "        [  1.58557717e-073,   9.99849875e-001,   1.50125137e-004],\n",
       "        [  1.02662082e-077,   9.99714947e-001,   2.85053350e-004],\n",
       "        [  1.72307593e-083,   9.98992363e-001,   1.00763708e-003],\n",
       "        [  4.12872931e-030,   9.99999769e-001,   2.31316897e-007],\n",
       "        [  5.99667528e-074,   9.99847160e-001,   1.52839987e-004],\n",
       "        [  4.13779546e-251,   6.35381030e-011,   1.00000000e+000],\n",
       "        [  5.00845630e-151,   2.50121636e-002,   9.74987836e-001],\n",
       "        [  1.04941686e-218,   1.67915381e-007,   9.99999832e-001],\n",
       "        [  2.13833836e-175,   1.99462374e-003,   9.98005376e-001],\n",
       "        [  7.20399720e-216,   2.30543407e-007,   9.99999769e-001],\n",
       "        [  4.51654712e-271,   2.40976994e-010,   1.00000000e+000],\n",
       "        [  4.59552511e-108,   9.73514345e-001,   2.64856553e-002],\n",
       "        [  2.22191497e-227,   1.34018147e-006,   9.99998660e-001],\n",
       "        [  2.10589122e-190,   4.92901785e-004,   9.99507098e-001],\n",
       "        [  1.20055778e-262,   1.40568402e-012,   1.00000000e+000],\n",
       "        [  3.62359789e-160,   4.12884115e-004,   9.99587116e-001],\n",
       "        [  8.83719953e-165,   2.77742178e-003,   9.97222578e-001],\n",
       "        [  6.87376950e-192,   4.80711862e-006,   9.99995193e-001],\n",
       "        [  4.08220498e-152,   1.28807070e-002,   9.87119293e-001],\n",
       "        [  2.75153031e-187,   1.04253685e-006,   9.99998957e-001],\n",
       "        [  1.44750671e-192,   4.50951786e-007,   9.99999549e-001],\n",
       "        [  2.76680341e-170,   1.87196580e-003,   9.98128034e-001],\n",
       "        [  3.75302289e-285,   1.64574932e-012,   1.00000000e+000],\n",
       "        [  4.69548986e-310,   6.47406861e-013,   1.00000000e+000],\n",
       "        [  5.69697725e-125,   9.58135362e-001,   4.18646381e-002],\n",
       "        [  2.94299535e-219,   1.17116897e-008,   9.99999988e-001],\n",
       "        [  2.82525894e-146,   1.37625971e-002,   9.86237403e-001],\n",
       "        [  1.12237933e-272,   7.58240410e-010,   9.99999999e-001],\n",
       "        [  2.28867567e-136,   1.29986728e-001,   8.70013272e-001],\n",
       "        [  5.61795825e-203,   9.71777952e-007,   9.99999028e-001],\n",
       "        [  8.72622664e-206,   7.39901993e-006,   9.99992601e-001],\n",
       "        [  9.96933448e-131,   1.99928220e-001,   8.00071780e-001],\n",
       "        [  4.66749613e-135,   1.07483532e-001,   8.92516468e-001],\n",
       "        [  6.88743059e-196,   1.09467814e-005,   9.99989053e-001],\n",
       "        [  1.61337601e-181,   7.01805717e-004,   9.99298194e-001],\n",
       "        [  8.55580252e-221,   9.06238440e-007,   9.99999094e-001],\n",
       "        [  1.24722670e-250,   2.96730515e-010,   1.00000000e+000],\n",
       "        [  3.64874362e-203,   1.50788229e-006,   9.99998492e-001],\n",
       "        [  2.19798649e-130,   7.12645144e-001,   2.87354856e-001],\n",
       "        [  3.68949024e-153,   4.86199285e-001,   5.13800715e-001],\n",
       "        [  2.13595212e-251,   8.98578645e-011,   1.00000000e+000],\n",
       "        [  2.75337356e-217,   6.58848819e-009,   9.99999993e-001],\n",
       "        [  1.30868299e-169,   1.90227600e-003,   9.98097724e-001],\n",
       "        [  1.38946382e-129,   1.93183856e-001,   8.06816144e-001],\n",
       "        [  1.71830037e-186,   5.23126458e-006,   9.99994769e-001],\n",
       "        [  5.79667973e-220,   5.01446575e-009,   9.99999995e-001],\n",
       "        [  1.61093140e-184,   4.67798053e-007,   9.99999532e-001],\n",
       "        [  5.00845630e-151,   2.50121636e-002,   9.74987836e-001],\n",
       "        [  2.54029381e-231,   4.42556022e-009,   9.99999996e-001],\n",
       "        [  4.84219075e-234,   1.64602693e-010,   1.00000000e+000],\n",
       "        [  6.47732320e-189,   5.85507961e-007,   9.99999414e-001],\n",
       "        [  5.17352411e-148,   2.54457623e-002,   9.74554238e-001],\n",
       "        [  5.93498263e-166,   3.70166861e-004,   9.99629833e-001],\n",
       "        [  5.58649523e-197,   2.46020434e-007,   9.99999754e-001],\n",
       "        [  9.13863414e-145,   5.60050091e-002,   9.43994991e-001]])}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pipegraph.adapters import AdapterForFitPredictAdaptee\n",
    "\n",
    "wrapped_classifier = AdapterForFitPredictAdaptee(classifier)\n",
    "y_pred = wrapped_classifier.predict(X=X)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the wrapper provides its output as a dictionary containing the outputs provided by ```predict```, ```predict_proba```, and ```predict_log_proba``` where these methods are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['predict', 'predict_proba', 'predict_log_proba']"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(y_pred.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those sklearn objects following the ```transform``` protocol can be wrapped into the class ```AdapterForFitTransformAdaptee```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predict': array([[ 0.22222222,  0.625     ,  0.06779661,  0.04166667],\n",
       "        [ 0.16666667,  0.41666667,  0.06779661,  0.04166667],\n",
       "        [ 0.11111111,  0.5       ,  0.05084746,  0.04166667],\n",
       "        [ 0.08333333,  0.45833333,  0.08474576,  0.04166667],\n",
       "        [ 0.19444444,  0.66666667,  0.06779661,  0.04166667],\n",
       "        [ 0.30555556,  0.79166667,  0.11864407,  0.125     ],\n",
       "        [ 0.08333333,  0.58333333,  0.06779661,  0.08333333],\n",
       "        [ 0.19444444,  0.58333333,  0.08474576,  0.04166667],\n",
       "        [ 0.02777778,  0.375     ,  0.06779661,  0.04166667],\n",
       "        [ 0.16666667,  0.45833333,  0.08474576,  0.        ],\n",
       "        [ 0.30555556,  0.70833333,  0.08474576,  0.04166667],\n",
       "        [ 0.13888889,  0.58333333,  0.10169492,  0.04166667],\n",
       "        [ 0.13888889,  0.41666667,  0.06779661,  0.        ],\n",
       "        [ 0.        ,  0.41666667,  0.01694915,  0.        ],\n",
       "        [ 0.41666667,  0.83333333,  0.03389831,  0.04166667],\n",
       "        [ 0.38888889,  1.        ,  0.08474576,  0.125     ],\n",
       "        [ 0.30555556,  0.79166667,  0.05084746,  0.125     ],\n",
       "        [ 0.22222222,  0.625     ,  0.06779661,  0.08333333],\n",
       "        [ 0.38888889,  0.75      ,  0.11864407,  0.08333333],\n",
       "        [ 0.22222222,  0.75      ,  0.08474576,  0.08333333],\n",
       "        [ 0.30555556,  0.58333333,  0.11864407,  0.04166667],\n",
       "        [ 0.22222222,  0.70833333,  0.08474576,  0.125     ],\n",
       "        [ 0.08333333,  0.66666667,  0.        ,  0.04166667],\n",
       "        [ 0.22222222,  0.54166667,  0.11864407,  0.16666667],\n",
       "        [ 0.13888889,  0.58333333,  0.15254237,  0.04166667],\n",
       "        [ 0.19444444,  0.41666667,  0.10169492,  0.04166667],\n",
       "        [ 0.19444444,  0.58333333,  0.10169492,  0.125     ],\n",
       "        [ 0.25      ,  0.625     ,  0.08474576,  0.04166667],\n",
       "        [ 0.25      ,  0.58333333,  0.06779661,  0.04166667],\n",
       "        [ 0.11111111,  0.5       ,  0.10169492,  0.04166667],\n",
       "        [ 0.13888889,  0.45833333,  0.10169492,  0.04166667],\n",
       "        [ 0.30555556,  0.58333333,  0.08474576,  0.125     ],\n",
       "        [ 0.25      ,  0.875     ,  0.08474576,  0.        ],\n",
       "        [ 0.33333333,  0.91666667,  0.06779661,  0.04166667],\n",
       "        [ 0.16666667,  0.45833333,  0.08474576,  0.        ],\n",
       "        [ 0.19444444,  0.5       ,  0.03389831,  0.04166667],\n",
       "        [ 0.33333333,  0.625     ,  0.05084746,  0.04166667],\n",
       "        [ 0.16666667,  0.45833333,  0.08474576,  0.        ],\n",
       "        [ 0.02777778,  0.41666667,  0.05084746,  0.04166667],\n",
       "        [ 0.22222222,  0.58333333,  0.08474576,  0.04166667],\n",
       "        [ 0.19444444,  0.625     ,  0.05084746,  0.08333333],\n",
       "        [ 0.05555556,  0.125     ,  0.05084746,  0.08333333],\n",
       "        [ 0.02777778,  0.5       ,  0.05084746,  0.04166667],\n",
       "        [ 0.19444444,  0.625     ,  0.10169492,  0.20833333],\n",
       "        [ 0.22222222,  0.75      ,  0.15254237,  0.125     ],\n",
       "        [ 0.13888889,  0.41666667,  0.06779661,  0.08333333],\n",
       "        [ 0.22222222,  0.75      ,  0.10169492,  0.04166667],\n",
       "        [ 0.08333333,  0.5       ,  0.06779661,  0.04166667],\n",
       "        [ 0.27777778,  0.70833333,  0.08474576,  0.04166667],\n",
       "        [ 0.19444444,  0.54166667,  0.06779661,  0.04166667],\n",
       "        [ 0.75      ,  0.5       ,  0.62711864,  0.54166667],\n",
       "        [ 0.58333333,  0.5       ,  0.59322034,  0.58333333],\n",
       "        [ 0.72222222,  0.45833333,  0.66101695,  0.58333333],\n",
       "        [ 0.33333333,  0.125     ,  0.50847458,  0.5       ],\n",
       "        [ 0.61111111,  0.33333333,  0.61016949,  0.58333333],\n",
       "        [ 0.38888889,  0.33333333,  0.59322034,  0.5       ],\n",
       "        [ 0.55555556,  0.54166667,  0.62711864,  0.625     ],\n",
       "        [ 0.16666667,  0.16666667,  0.38983051,  0.375     ],\n",
       "        [ 0.63888889,  0.375     ,  0.61016949,  0.5       ],\n",
       "        [ 0.25      ,  0.29166667,  0.49152542,  0.54166667],\n",
       "        [ 0.19444444,  0.        ,  0.42372881,  0.375     ],\n",
       "        [ 0.44444444,  0.41666667,  0.54237288,  0.58333333],\n",
       "        [ 0.47222222,  0.08333333,  0.50847458,  0.375     ],\n",
       "        [ 0.5       ,  0.375     ,  0.62711864,  0.54166667],\n",
       "        [ 0.36111111,  0.375     ,  0.44067797,  0.5       ],\n",
       "        [ 0.66666667,  0.45833333,  0.57627119,  0.54166667],\n",
       "        [ 0.36111111,  0.41666667,  0.59322034,  0.58333333],\n",
       "        [ 0.41666667,  0.29166667,  0.52542373,  0.375     ],\n",
       "        [ 0.52777778,  0.08333333,  0.59322034,  0.58333333],\n",
       "        [ 0.36111111,  0.20833333,  0.49152542,  0.41666667],\n",
       "        [ 0.44444444,  0.5       ,  0.6440678 ,  0.70833333],\n",
       "        [ 0.5       ,  0.33333333,  0.50847458,  0.5       ],\n",
       "        [ 0.55555556,  0.20833333,  0.66101695,  0.58333333],\n",
       "        [ 0.5       ,  0.33333333,  0.62711864,  0.45833333],\n",
       "        [ 0.58333333,  0.375     ,  0.55932203,  0.5       ],\n",
       "        [ 0.63888889,  0.41666667,  0.57627119,  0.54166667],\n",
       "        [ 0.69444444,  0.33333333,  0.6440678 ,  0.54166667],\n",
       "        [ 0.66666667,  0.41666667,  0.6779661 ,  0.66666667],\n",
       "        [ 0.47222222,  0.375     ,  0.59322034,  0.58333333],\n",
       "        [ 0.38888889,  0.25      ,  0.42372881,  0.375     ],\n",
       "        [ 0.33333333,  0.16666667,  0.47457627,  0.41666667],\n",
       "        [ 0.33333333,  0.16666667,  0.45762712,  0.375     ],\n",
       "        [ 0.41666667,  0.29166667,  0.49152542,  0.45833333],\n",
       "        [ 0.47222222,  0.29166667,  0.69491525,  0.625     ],\n",
       "        [ 0.30555556,  0.41666667,  0.59322034,  0.58333333],\n",
       "        [ 0.47222222,  0.58333333,  0.59322034,  0.625     ],\n",
       "        [ 0.66666667,  0.45833333,  0.62711864,  0.58333333],\n",
       "        [ 0.55555556,  0.125     ,  0.57627119,  0.5       ],\n",
       "        [ 0.36111111,  0.41666667,  0.52542373,  0.5       ],\n",
       "        [ 0.33333333,  0.20833333,  0.50847458,  0.5       ],\n",
       "        [ 0.33333333,  0.25      ,  0.57627119,  0.45833333],\n",
       "        [ 0.5       ,  0.41666667,  0.61016949,  0.54166667],\n",
       "        [ 0.41666667,  0.25      ,  0.50847458,  0.45833333],\n",
       "        [ 0.19444444,  0.125     ,  0.38983051,  0.375     ],\n",
       "        [ 0.36111111,  0.29166667,  0.54237288,  0.5       ],\n",
       "        [ 0.38888889,  0.41666667,  0.54237288,  0.45833333],\n",
       "        [ 0.38888889,  0.375     ,  0.54237288,  0.5       ],\n",
       "        [ 0.52777778,  0.375     ,  0.55932203,  0.5       ],\n",
       "        [ 0.22222222,  0.20833333,  0.33898305,  0.41666667],\n",
       "        [ 0.38888889,  0.33333333,  0.52542373,  0.5       ],\n",
       "        [ 0.55555556,  0.54166667,  0.84745763,  1.        ],\n",
       "        [ 0.41666667,  0.29166667,  0.69491525,  0.75      ],\n",
       "        [ 0.77777778,  0.41666667,  0.83050847,  0.83333333],\n",
       "        [ 0.55555556,  0.375     ,  0.77966102,  0.70833333],\n",
       "        [ 0.61111111,  0.41666667,  0.81355932,  0.875     ],\n",
       "        [ 0.91666667,  0.41666667,  0.94915254,  0.83333333],\n",
       "        [ 0.16666667,  0.20833333,  0.59322034,  0.66666667],\n",
       "        [ 0.83333333,  0.375     ,  0.89830508,  0.70833333],\n",
       "        [ 0.66666667,  0.20833333,  0.81355932,  0.70833333],\n",
       "        [ 0.80555556,  0.66666667,  0.86440678,  1.        ],\n",
       "        [ 0.61111111,  0.5       ,  0.69491525,  0.79166667],\n",
       "        [ 0.58333333,  0.29166667,  0.72881356,  0.75      ],\n",
       "        [ 0.69444444,  0.41666667,  0.76271186,  0.83333333],\n",
       "        [ 0.38888889,  0.20833333,  0.6779661 ,  0.79166667],\n",
       "        [ 0.41666667,  0.33333333,  0.69491525,  0.95833333],\n",
       "        [ 0.58333333,  0.5       ,  0.72881356,  0.91666667],\n",
       "        [ 0.61111111,  0.41666667,  0.76271186,  0.70833333],\n",
       "        [ 0.94444444,  0.75      ,  0.96610169,  0.875     ],\n",
       "        [ 0.94444444,  0.25      ,  1.        ,  0.91666667],\n",
       "        [ 0.47222222,  0.08333333,  0.6779661 ,  0.58333333],\n",
       "        [ 0.72222222,  0.5       ,  0.79661017,  0.91666667],\n",
       "        [ 0.36111111,  0.33333333,  0.66101695,  0.79166667],\n",
       "        [ 0.94444444,  0.33333333,  0.96610169,  0.79166667],\n",
       "        [ 0.55555556,  0.29166667,  0.66101695,  0.70833333],\n",
       "        [ 0.66666667,  0.54166667,  0.79661017,  0.83333333],\n",
       "        [ 0.80555556,  0.5       ,  0.84745763,  0.70833333],\n",
       "        [ 0.52777778,  0.33333333,  0.6440678 ,  0.70833333],\n",
       "        [ 0.5       ,  0.41666667,  0.66101695,  0.70833333],\n",
       "        [ 0.58333333,  0.33333333,  0.77966102,  0.83333333],\n",
       "        [ 0.80555556,  0.41666667,  0.81355932,  0.625     ],\n",
       "        [ 0.86111111,  0.33333333,  0.86440678,  0.75      ],\n",
       "        [ 1.        ,  0.75      ,  0.91525424,  0.79166667],\n",
       "        [ 0.58333333,  0.33333333,  0.77966102,  0.875     ],\n",
       "        [ 0.55555556,  0.33333333,  0.69491525,  0.58333333],\n",
       "        [ 0.5       ,  0.25      ,  0.77966102,  0.54166667],\n",
       "        [ 0.94444444,  0.41666667,  0.86440678,  0.91666667],\n",
       "        [ 0.55555556,  0.58333333,  0.77966102,  0.95833333],\n",
       "        [ 0.58333333,  0.45833333,  0.76271186,  0.70833333],\n",
       "        [ 0.47222222,  0.41666667,  0.6440678 ,  0.70833333],\n",
       "        [ 0.72222222,  0.45833333,  0.74576271,  0.83333333],\n",
       "        [ 0.66666667,  0.45833333,  0.77966102,  0.95833333],\n",
       "        [ 0.72222222,  0.45833333,  0.69491525,  0.91666667],\n",
       "        [ 0.41666667,  0.29166667,  0.69491525,  0.75      ],\n",
       "        [ 0.69444444,  0.5       ,  0.83050847,  0.91666667],\n",
       "        [ 0.66666667,  0.54166667,  0.79661017,  1.        ],\n",
       "        [ 0.66666667,  0.41666667,  0.71186441,  0.91666667],\n",
       "        [ 0.55555556,  0.20833333,  0.6779661 ,  0.75      ],\n",
       "        [ 0.61111111,  0.41666667,  0.71186441,  0.79166667],\n",
       "        [ 0.52777778,  0.58333333,  0.74576271,  0.91666667],\n",
       "        [ 0.44444444,  0.41666667,  0.69491525,  0.70833333]])}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pipegraph.adapters import AdapterForFitTransformAdaptee\n",
    "\n",
    "wrapped_scaler = AdapterForFitTransformAdaptee(scaler)\n",
    "y_pred=wrapped_scaler.predict(X)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The adapter for transformers doesn't have to provide so many methods' output, only the value provided by calling ```trasform``` method on the adaptee, which for homogeneity is provided as a dictionary with 'predict' as key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['predict']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(y_pred.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those sklearn objects following the ```fit_predict``` protocol can be wrapped into the class ```AdapterForAtomicFitPredictAdaptee```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predict': array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0, -1,  0,  0,  0,  0,  0,  0,  0,  0,  1,\n",
       "         1,  1,  1,  1,  1,  1, -1,  1,  1, -1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        -1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1, -1,  1,  1,  1,  1,  1, -1,  1,  1,  1,  1, -1,  1,  1,  1,\n",
       "         1,  1,  1, -1, -1,  1, -1, -1,  1,  1,  1,  1,  1,  1,  1, -1, -1,\n",
       "         1,  1,  1, -1,  1,  1,  1,  1,  1,  1,  1,  1, -1,  1,  1, -1, -1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1], dtype=int64)}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pipegraph.adapters import AdapterForAtomicFitPredictAdaptee\n",
    "\n",
    "wrapped_dbscanner = AdapterForAtomicFitPredictAdaptee(dbscanner)\n",
    "y_pred = wrapped_dbscanner.predict(X=X)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, this adapter provides a dictionary with the values of calling ```fit_predict``` under the key 'predict'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special wrappers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides of the three families of objects provided by Scikit-Learn, it is sometimes convenient to provide custom objects whose ```predict``` method returns multiple outputs. In this case, a dictionary can be used as well, with the name of the outputs as keys. In order to comply with this kind of output, the class ```AdapterForCustomFitPredictWithDictionaryOutputAdaptee``` is provided:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X_0':       0    1    2    3\n",
       " 0   5.1  3.5  1.4  0.2\n",
       " 1   4.9  3.0  1.4  0.2\n",
       " 2   4.7  3.2  1.3  0.2\n",
       " 3   4.6  3.1  1.5  0.2\n",
       " 4   5.0  3.6  1.4  0.2\n",
       " 5   5.4  3.9  1.7  0.4\n",
       " 6   4.6  3.4  1.4  0.3\n",
       " 7   5.0  3.4  1.5  0.2\n",
       " 8   4.4  2.9  1.4  0.2\n",
       " 9   4.9  3.1  1.5  0.1\n",
       " 10  5.4  3.7  1.5  0.2\n",
       " 11  4.8  3.4  1.6  0.2\n",
       " 12  4.8  3.0  1.4  0.1\n",
       " 13  4.3  3.0  1.1  0.1\n",
       " 14  5.8  4.0  1.2  0.2\n",
       " 15  5.7  4.4  1.5  0.4\n",
       " 16  5.4  3.9  1.3  0.4\n",
       " 17  5.1  3.5  1.4  0.3\n",
       " 18  5.7  3.8  1.7  0.3\n",
       " 19  5.1  3.8  1.5  0.3\n",
       " 20  5.4  3.4  1.7  0.2\n",
       " 21  5.1  3.7  1.5  0.4\n",
       " 22  4.6  3.6  1.0  0.2\n",
       " 23  5.1  3.3  1.7  0.5\n",
       " 24  4.8  3.4  1.9  0.2\n",
       " 25  5.0  3.0  1.6  0.2\n",
       " 26  5.0  3.4  1.6  0.4\n",
       " 27  5.2  3.5  1.5  0.2\n",
       " 28  5.2  3.4  1.4  0.2\n",
       " 29  4.7  3.2  1.6  0.2\n",
       " 30  4.8  3.1  1.6  0.2\n",
       " 31  5.4  3.4  1.5  0.4\n",
       " 32  5.2  4.1  1.5  0.1\n",
       " 33  5.5  4.2  1.4  0.2\n",
       " 34  4.9  3.1  1.5  0.1\n",
       " 35  5.0  3.2  1.2  0.2\n",
       " 36  5.5  3.5  1.3  0.2\n",
       " 37  4.9  3.1  1.5  0.1\n",
       " 38  4.4  3.0  1.3  0.2\n",
       " 39  5.1  3.4  1.5  0.2\n",
       " 40  5.0  3.5  1.3  0.3\n",
       " 41  4.5  2.3  1.3  0.3\n",
       " 42  4.4  3.2  1.3  0.2\n",
       " 43  5.0  3.5  1.6  0.6\n",
       " 44  5.1  3.8  1.9  0.4\n",
       " 45  4.8  3.0  1.4  0.3\n",
       " 46  5.1  3.8  1.6  0.2\n",
       " 47  4.6  3.2  1.4  0.2\n",
       " 48  5.3  3.7  1.5  0.2\n",
       " 49  5.0  3.3  1.4  0.2, 'X_1':       0    1    2    3\n",
       " 50  7.0  3.2  4.7  1.4\n",
       " 51  6.4  3.2  4.5  1.5\n",
       " 52  6.9  3.1  4.9  1.5\n",
       " 53  5.5  2.3  4.0  1.3\n",
       " 54  6.5  2.8  4.6  1.5\n",
       " 55  5.7  2.8  4.5  1.3\n",
       " 56  6.3  3.3  4.7  1.6\n",
       " 57  4.9  2.4  3.3  1.0\n",
       " 58  6.6  2.9  4.6  1.3\n",
       " 59  5.2  2.7  3.9  1.4\n",
       " 60  5.0  2.0  3.5  1.0\n",
       " 61  5.9  3.0  4.2  1.5\n",
       " 62  6.0  2.2  4.0  1.0\n",
       " 63  6.1  2.9  4.7  1.4\n",
       " 64  5.6  2.9  3.6  1.3\n",
       " 65  6.7  3.1  4.4  1.4\n",
       " 66  5.6  3.0  4.5  1.5\n",
       " 67  5.8  2.7  4.1  1.0\n",
       " 68  6.2  2.2  4.5  1.5\n",
       " 69  5.6  2.5  3.9  1.1\n",
       " 70  5.9  3.2  4.8  1.8\n",
       " 71  6.1  2.8  4.0  1.3\n",
       " 72  6.3  2.5  4.9  1.5\n",
       " 73  6.1  2.8  4.7  1.2\n",
       " 74  6.4  2.9  4.3  1.3\n",
       " 75  6.6  3.0  4.4  1.4\n",
       " 76  6.8  2.8  4.8  1.4\n",
       " 77  6.7  3.0  5.0  1.7\n",
       " 78  6.0  2.9  4.5  1.5\n",
       " 79  5.7  2.6  3.5  1.0\n",
       " 80  5.5  2.4  3.8  1.1\n",
       " 81  5.5  2.4  3.7  1.0\n",
       " 82  5.8  2.7  3.9  1.2\n",
       " 83  6.0  2.7  5.1  1.6\n",
       " 84  5.4  3.0  4.5  1.5\n",
       " 85  6.0  3.4  4.5  1.6\n",
       " 86  6.7  3.1  4.7  1.5\n",
       " 87  6.3  2.3  4.4  1.3\n",
       " 88  5.6  3.0  4.1  1.3\n",
       " 89  5.5  2.5  4.0  1.3\n",
       " 90  5.5  2.6  4.4  1.2\n",
       " 91  6.1  3.0  4.6  1.4\n",
       " 92  5.8  2.6  4.0  1.2\n",
       " 93  5.0  2.3  3.3  1.0\n",
       " 94  5.6  2.7  4.2  1.3\n",
       " 95  5.7  3.0  4.2  1.2\n",
       " 96  5.7  2.9  4.2  1.3\n",
       " 97  6.2  2.9  4.3  1.3\n",
       " 98  5.1  2.5  3.0  1.1\n",
       " 99  5.7  2.8  4.1  1.3, 'X_2':        0    1    2    3\n",
       " 100  6.3  3.3  6.0  2.5\n",
       " 101  5.8  2.7  5.1  1.9\n",
       " 102  7.1  3.0  5.9  2.1\n",
       " 103  6.3  2.9  5.6  1.8\n",
       " 104  6.5  3.0  5.8  2.2\n",
       " 105  7.6  3.0  6.6  2.1\n",
       " 106  4.9  2.5  4.5  1.7\n",
       " 107  7.3  2.9  6.3  1.8\n",
       " 108  6.7  2.5  5.8  1.8\n",
       " 109  7.2  3.6  6.1  2.5\n",
       " 110  6.5  3.2  5.1  2.0\n",
       " 111  6.4  2.7  5.3  1.9\n",
       " 112  6.8  3.0  5.5  2.1\n",
       " 113  5.7  2.5  5.0  2.0\n",
       " 114  5.8  2.8  5.1  2.4\n",
       " 115  6.4  3.2  5.3  2.3\n",
       " 116  6.5  3.0  5.5  1.8\n",
       " 117  7.7  3.8  6.7  2.2\n",
       " 118  7.7  2.6  6.9  2.3\n",
       " 119  6.0  2.2  5.0  1.5\n",
       " 120  6.9  3.2  5.7  2.3\n",
       " 121  5.6  2.8  4.9  2.0\n",
       " 122  7.7  2.8  6.7  2.0\n",
       " 123  6.3  2.7  4.9  1.8\n",
       " 124  6.7  3.3  5.7  2.1\n",
       " 125  7.2  3.2  6.0  1.8\n",
       " 126  6.2  2.8  4.8  1.8\n",
       " 127  6.1  3.0  4.9  1.8\n",
       " 128  6.4  2.8  5.6  2.1\n",
       " 129  7.2  3.0  5.8  1.6\n",
       " 130  7.4  2.8  6.1  1.9\n",
       " 131  7.9  3.8  6.4  2.0\n",
       " 132  6.4  2.8  5.6  2.2\n",
       " 133  6.3  2.8  5.1  1.5\n",
       " 134  6.1  2.6  5.6  1.4\n",
       " 135  7.7  3.0  6.1  2.3\n",
       " 136  6.3  3.4  5.6  2.4\n",
       " 137  6.4  3.1  5.5  1.8\n",
       " 138  6.0  3.0  4.8  1.8\n",
       " 139  6.9  3.1  5.4  2.1\n",
       " 140  6.7  3.1  5.6  2.4\n",
       " 141  6.9  3.1  5.1  2.3\n",
       " 142  5.8  2.7  5.1  1.9\n",
       " 143  6.8  3.2  5.9  2.3\n",
       " 144  6.7  3.3  5.7  2.5\n",
       " 145  6.7  3.0  5.2  2.3\n",
       " 146  6.3  2.5  5.0  1.9\n",
       " 147  6.5  3.0  5.2  2.0\n",
       " 148  6.2  3.4  5.4  2.3\n",
       " 149  5.9  3.0  5.1  1.8}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pipegraph.standard_blocks import Demultiplexer\n",
    "from pipegraph.adapters import AdapterForCustomFitPredictWithDictionaryOutputAdaptee\n",
    "\n",
    "demultiplexer = Demultiplexer()\n",
    "wrapped_demultiplexer = AdapterForCustomFitPredictWithDictionaryOutputAdaptee(demultiplexer)\n",
    "output = wrapped_demultiplexer.predict(X=X, selection=y)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X_0', 'X_1', 'X_2']"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(output.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen, this adapter's ```predict``` method provides the dictionary of outputs provided by the adaptee with its original keys."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrapping your custom blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PipeGraph uses the ```wrap_adaptee_in_process(adaptee, strategy_class=None)``` function to wrap the objects passed to its constructor's ```steps``` parameters accordingly to these rules:\n",
    "- If the ```strategy_class``` parameter is passed, this class is used as adapter\n",
    "- Else, if the adaptee's class is in ```pipegraph.base.strategies_for_custom_adaptees``` dictionary, the value class there is used.\n",
    "- Else, if the adaptee has a ```predict``` method, the ```AdapterForFitPredictAdaptee``` class is used.\n",
    "- Else, if the adaptee has a ```transform``` method, the ```AdapterForFitTransformAdaptee``` class is used.\n",
    "- Else, if the adaptee has a ```fit_predict``` method, the ```AdapterForAtomicFitPredictAdaptee```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predict': array([[ 0.22222222,  0.625     ,  0.06779661,  0.04166667],\n",
       "        [ 0.16666667,  0.41666667,  0.06779661,  0.04166667],\n",
       "        [ 0.11111111,  0.5       ,  0.05084746,  0.04166667],\n",
       "        [ 0.08333333,  0.45833333,  0.08474576,  0.04166667],\n",
       "        [ 0.19444444,  0.66666667,  0.06779661,  0.04166667],\n",
       "        [ 0.30555556,  0.79166667,  0.11864407,  0.125     ],\n",
       "        [ 0.08333333,  0.58333333,  0.06779661,  0.08333333],\n",
       "        [ 0.19444444,  0.58333333,  0.08474576,  0.04166667],\n",
       "        [ 0.02777778,  0.375     ,  0.06779661,  0.04166667],\n",
       "        [ 0.16666667,  0.45833333,  0.08474576,  0.        ],\n",
       "        [ 0.30555556,  0.70833333,  0.08474576,  0.04166667],\n",
       "        [ 0.13888889,  0.58333333,  0.10169492,  0.04166667],\n",
       "        [ 0.13888889,  0.41666667,  0.06779661,  0.        ],\n",
       "        [ 0.        ,  0.41666667,  0.01694915,  0.        ],\n",
       "        [ 0.41666667,  0.83333333,  0.03389831,  0.04166667],\n",
       "        [ 0.38888889,  1.        ,  0.08474576,  0.125     ],\n",
       "        [ 0.30555556,  0.79166667,  0.05084746,  0.125     ],\n",
       "        [ 0.22222222,  0.625     ,  0.06779661,  0.08333333],\n",
       "        [ 0.38888889,  0.75      ,  0.11864407,  0.08333333],\n",
       "        [ 0.22222222,  0.75      ,  0.08474576,  0.08333333],\n",
       "        [ 0.30555556,  0.58333333,  0.11864407,  0.04166667],\n",
       "        [ 0.22222222,  0.70833333,  0.08474576,  0.125     ],\n",
       "        [ 0.08333333,  0.66666667,  0.        ,  0.04166667],\n",
       "        [ 0.22222222,  0.54166667,  0.11864407,  0.16666667],\n",
       "        [ 0.13888889,  0.58333333,  0.15254237,  0.04166667],\n",
       "        [ 0.19444444,  0.41666667,  0.10169492,  0.04166667],\n",
       "        [ 0.19444444,  0.58333333,  0.10169492,  0.125     ],\n",
       "        [ 0.25      ,  0.625     ,  0.08474576,  0.04166667],\n",
       "        [ 0.25      ,  0.58333333,  0.06779661,  0.04166667],\n",
       "        [ 0.11111111,  0.5       ,  0.10169492,  0.04166667],\n",
       "        [ 0.13888889,  0.45833333,  0.10169492,  0.04166667],\n",
       "        [ 0.30555556,  0.58333333,  0.08474576,  0.125     ],\n",
       "        [ 0.25      ,  0.875     ,  0.08474576,  0.        ],\n",
       "        [ 0.33333333,  0.91666667,  0.06779661,  0.04166667],\n",
       "        [ 0.16666667,  0.45833333,  0.08474576,  0.        ],\n",
       "        [ 0.19444444,  0.5       ,  0.03389831,  0.04166667],\n",
       "        [ 0.33333333,  0.625     ,  0.05084746,  0.04166667],\n",
       "        [ 0.16666667,  0.45833333,  0.08474576,  0.        ],\n",
       "        [ 0.02777778,  0.41666667,  0.05084746,  0.04166667],\n",
       "        [ 0.22222222,  0.58333333,  0.08474576,  0.04166667],\n",
       "        [ 0.19444444,  0.625     ,  0.05084746,  0.08333333],\n",
       "        [ 0.05555556,  0.125     ,  0.05084746,  0.08333333],\n",
       "        [ 0.02777778,  0.5       ,  0.05084746,  0.04166667],\n",
       "        [ 0.19444444,  0.625     ,  0.10169492,  0.20833333],\n",
       "        [ 0.22222222,  0.75      ,  0.15254237,  0.125     ],\n",
       "        [ 0.13888889,  0.41666667,  0.06779661,  0.08333333],\n",
       "        [ 0.22222222,  0.75      ,  0.10169492,  0.04166667],\n",
       "        [ 0.08333333,  0.5       ,  0.06779661,  0.04166667],\n",
       "        [ 0.27777778,  0.70833333,  0.08474576,  0.04166667],\n",
       "        [ 0.19444444,  0.54166667,  0.06779661,  0.04166667],\n",
       "        [ 0.75      ,  0.5       ,  0.62711864,  0.54166667],\n",
       "        [ 0.58333333,  0.5       ,  0.59322034,  0.58333333],\n",
       "        [ 0.72222222,  0.45833333,  0.66101695,  0.58333333],\n",
       "        [ 0.33333333,  0.125     ,  0.50847458,  0.5       ],\n",
       "        [ 0.61111111,  0.33333333,  0.61016949,  0.58333333],\n",
       "        [ 0.38888889,  0.33333333,  0.59322034,  0.5       ],\n",
       "        [ 0.55555556,  0.54166667,  0.62711864,  0.625     ],\n",
       "        [ 0.16666667,  0.16666667,  0.38983051,  0.375     ],\n",
       "        [ 0.63888889,  0.375     ,  0.61016949,  0.5       ],\n",
       "        [ 0.25      ,  0.29166667,  0.49152542,  0.54166667],\n",
       "        [ 0.19444444,  0.        ,  0.42372881,  0.375     ],\n",
       "        [ 0.44444444,  0.41666667,  0.54237288,  0.58333333],\n",
       "        [ 0.47222222,  0.08333333,  0.50847458,  0.375     ],\n",
       "        [ 0.5       ,  0.375     ,  0.62711864,  0.54166667],\n",
       "        [ 0.36111111,  0.375     ,  0.44067797,  0.5       ],\n",
       "        [ 0.66666667,  0.45833333,  0.57627119,  0.54166667],\n",
       "        [ 0.36111111,  0.41666667,  0.59322034,  0.58333333],\n",
       "        [ 0.41666667,  0.29166667,  0.52542373,  0.375     ],\n",
       "        [ 0.52777778,  0.08333333,  0.59322034,  0.58333333],\n",
       "        [ 0.36111111,  0.20833333,  0.49152542,  0.41666667],\n",
       "        [ 0.44444444,  0.5       ,  0.6440678 ,  0.70833333],\n",
       "        [ 0.5       ,  0.33333333,  0.50847458,  0.5       ],\n",
       "        [ 0.55555556,  0.20833333,  0.66101695,  0.58333333],\n",
       "        [ 0.5       ,  0.33333333,  0.62711864,  0.45833333],\n",
       "        [ 0.58333333,  0.375     ,  0.55932203,  0.5       ],\n",
       "        [ 0.63888889,  0.41666667,  0.57627119,  0.54166667],\n",
       "        [ 0.69444444,  0.33333333,  0.6440678 ,  0.54166667],\n",
       "        [ 0.66666667,  0.41666667,  0.6779661 ,  0.66666667],\n",
       "        [ 0.47222222,  0.375     ,  0.59322034,  0.58333333],\n",
       "        [ 0.38888889,  0.25      ,  0.42372881,  0.375     ],\n",
       "        [ 0.33333333,  0.16666667,  0.47457627,  0.41666667],\n",
       "        [ 0.33333333,  0.16666667,  0.45762712,  0.375     ],\n",
       "        [ 0.41666667,  0.29166667,  0.49152542,  0.45833333],\n",
       "        [ 0.47222222,  0.29166667,  0.69491525,  0.625     ],\n",
       "        [ 0.30555556,  0.41666667,  0.59322034,  0.58333333],\n",
       "        [ 0.47222222,  0.58333333,  0.59322034,  0.625     ],\n",
       "        [ 0.66666667,  0.45833333,  0.62711864,  0.58333333],\n",
       "        [ 0.55555556,  0.125     ,  0.57627119,  0.5       ],\n",
       "        [ 0.36111111,  0.41666667,  0.52542373,  0.5       ],\n",
       "        [ 0.33333333,  0.20833333,  0.50847458,  0.5       ],\n",
       "        [ 0.33333333,  0.25      ,  0.57627119,  0.45833333],\n",
       "        [ 0.5       ,  0.41666667,  0.61016949,  0.54166667],\n",
       "        [ 0.41666667,  0.25      ,  0.50847458,  0.45833333],\n",
       "        [ 0.19444444,  0.125     ,  0.38983051,  0.375     ],\n",
       "        [ 0.36111111,  0.29166667,  0.54237288,  0.5       ],\n",
       "        [ 0.38888889,  0.41666667,  0.54237288,  0.45833333],\n",
       "        [ 0.38888889,  0.375     ,  0.54237288,  0.5       ],\n",
       "        [ 0.52777778,  0.375     ,  0.55932203,  0.5       ],\n",
       "        [ 0.22222222,  0.20833333,  0.33898305,  0.41666667],\n",
       "        [ 0.38888889,  0.33333333,  0.52542373,  0.5       ],\n",
       "        [ 0.55555556,  0.54166667,  0.84745763,  1.        ],\n",
       "        [ 0.41666667,  0.29166667,  0.69491525,  0.75      ],\n",
       "        [ 0.77777778,  0.41666667,  0.83050847,  0.83333333],\n",
       "        [ 0.55555556,  0.375     ,  0.77966102,  0.70833333],\n",
       "        [ 0.61111111,  0.41666667,  0.81355932,  0.875     ],\n",
       "        [ 0.91666667,  0.41666667,  0.94915254,  0.83333333],\n",
       "        [ 0.16666667,  0.20833333,  0.59322034,  0.66666667],\n",
       "        [ 0.83333333,  0.375     ,  0.89830508,  0.70833333],\n",
       "        [ 0.66666667,  0.20833333,  0.81355932,  0.70833333],\n",
       "        [ 0.80555556,  0.66666667,  0.86440678,  1.        ],\n",
       "        [ 0.61111111,  0.5       ,  0.69491525,  0.79166667],\n",
       "        [ 0.58333333,  0.29166667,  0.72881356,  0.75      ],\n",
       "        [ 0.69444444,  0.41666667,  0.76271186,  0.83333333],\n",
       "        [ 0.38888889,  0.20833333,  0.6779661 ,  0.79166667],\n",
       "        [ 0.41666667,  0.33333333,  0.69491525,  0.95833333],\n",
       "        [ 0.58333333,  0.5       ,  0.72881356,  0.91666667],\n",
       "        [ 0.61111111,  0.41666667,  0.76271186,  0.70833333],\n",
       "        [ 0.94444444,  0.75      ,  0.96610169,  0.875     ],\n",
       "        [ 0.94444444,  0.25      ,  1.        ,  0.91666667],\n",
       "        [ 0.47222222,  0.08333333,  0.6779661 ,  0.58333333],\n",
       "        [ 0.72222222,  0.5       ,  0.79661017,  0.91666667],\n",
       "        [ 0.36111111,  0.33333333,  0.66101695,  0.79166667],\n",
       "        [ 0.94444444,  0.33333333,  0.96610169,  0.79166667],\n",
       "        [ 0.55555556,  0.29166667,  0.66101695,  0.70833333],\n",
       "        [ 0.66666667,  0.54166667,  0.79661017,  0.83333333],\n",
       "        [ 0.80555556,  0.5       ,  0.84745763,  0.70833333],\n",
       "        [ 0.52777778,  0.33333333,  0.6440678 ,  0.70833333],\n",
       "        [ 0.5       ,  0.41666667,  0.66101695,  0.70833333],\n",
       "        [ 0.58333333,  0.33333333,  0.77966102,  0.83333333],\n",
       "        [ 0.80555556,  0.41666667,  0.81355932,  0.625     ],\n",
       "        [ 0.86111111,  0.33333333,  0.86440678,  0.75      ],\n",
       "        [ 1.        ,  0.75      ,  0.91525424,  0.79166667],\n",
       "        [ 0.58333333,  0.33333333,  0.77966102,  0.875     ],\n",
       "        [ 0.55555556,  0.33333333,  0.69491525,  0.58333333],\n",
       "        [ 0.5       ,  0.25      ,  0.77966102,  0.54166667],\n",
       "        [ 0.94444444,  0.41666667,  0.86440678,  0.91666667],\n",
       "        [ 0.55555556,  0.58333333,  0.77966102,  0.95833333],\n",
       "        [ 0.58333333,  0.45833333,  0.76271186,  0.70833333],\n",
       "        [ 0.47222222,  0.41666667,  0.6440678 ,  0.70833333],\n",
       "        [ 0.72222222,  0.45833333,  0.74576271,  0.83333333],\n",
       "        [ 0.66666667,  0.45833333,  0.77966102,  0.95833333],\n",
       "        [ 0.72222222,  0.45833333,  0.69491525,  0.91666667],\n",
       "        [ 0.41666667,  0.29166667,  0.69491525,  0.75      ],\n",
       "        [ 0.69444444,  0.5       ,  0.83050847,  0.91666667],\n",
       "        [ 0.66666667,  0.54166667,  0.79661017,  1.        ],\n",
       "        [ 0.66666667,  0.41666667,  0.71186441,  0.91666667],\n",
       "        [ 0.55555556,  0.20833333,  0.6779661 ,  0.75      ],\n",
       "        [ 0.61111111,  0.41666667,  0.71186441,  0.79166667],\n",
       "        [ 0.52777778,  0.58333333,  0.74576271,  0.91666667],\n",
       "        [ 0.44444444,  0.41666667,  0.69491525,  0.70833333]])}"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pipegraph.base import wrap_adaptee_in_process\n",
    "\n",
    "wrapped_scaler = wrap_adaptee_in_process(scaler)\n",
    "wrapped_scaler.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X_0':       0    1    2    3\n",
       " 0   5.1  3.5  1.4  0.2\n",
       " 1   4.9  3.0  1.4  0.2\n",
       " 2   4.7  3.2  1.3  0.2\n",
       " 3   4.6  3.1  1.5  0.2\n",
       " 4   5.0  3.6  1.4  0.2\n",
       " 5   5.4  3.9  1.7  0.4\n",
       " 6   4.6  3.4  1.4  0.3\n",
       " 7   5.0  3.4  1.5  0.2\n",
       " 8   4.4  2.9  1.4  0.2\n",
       " 9   4.9  3.1  1.5  0.1\n",
       " 10  5.4  3.7  1.5  0.2\n",
       " 11  4.8  3.4  1.6  0.2\n",
       " 12  4.8  3.0  1.4  0.1\n",
       " 13  4.3  3.0  1.1  0.1\n",
       " 14  5.8  4.0  1.2  0.2\n",
       " 15  5.7  4.4  1.5  0.4\n",
       " 16  5.4  3.9  1.3  0.4\n",
       " 17  5.1  3.5  1.4  0.3\n",
       " 18  5.7  3.8  1.7  0.3\n",
       " 19  5.1  3.8  1.5  0.3\n",
       " 20  5.4  3.4  1.7  0.2\n",
       " 21  5.1  3.7  1.5  0.4\n",
       " 22  4.6  3.6  1.0  0.2\n",
       " 23  5.1  3.3  1.7  0.5\n",
       " 24  4.8  3.4  1.9  0.2\n",
       " 25  5.0  3.0  1.6  0.2\n",
       " 26  5.0  3.4  1.6  0.4\n",
       " 27  5.2  3.5  1.5  0.2\n",
       " 28  5.2  3.4  1.4  0.2\n",
       " 29  4.7  3.2  1.6  0.2\n",
       " 30  4.8  3.1  1.6  0.2\n",
       " 31  5.4  3.4  1.5  0.4\n",
       " 32  5.2  4.1  1.5  0.1\n",
       " 33  5.5  4.2  1.4  0.2\n",
       " 34  4.9  3.1  1.5  0.1\n",
       " 35  5.0  3.2  1.2  0.2\n",
       " 36  5.5  3.5  1.3  0.2\n",
       " 37  4.9  3.1  1.5  0.1\n",
       " 38  4.4  3.0  1.3  0.2\n",
       " 39  5.1  3.4  1.5  0.2\n",
       " 40  5.0  3.5  1.3  0.3\n",
       " 41  4.5  2.3  1.3  0.3\n",
       " 42  4.4  3.2  1.3  0.2\n",
       " 43  5.0  3.5  1.6  0.6\n",
       " 44  5.1  3.8  1.9  0.4\n",
       " 45  4.8  3.0  1.4  0.3\n",
       " 46  5.1  3.8  1.6  0.2\n",
       " 47  4.6  3.2  1.4  0.2\n",
       " 48  5.3  3.7  1.5  0.2\n",
       " 49  5.0  3.3  1.4  0.2, 'X_1':       0    1    2    3\n",
       " 50  7.0  3.2  4.7  1.4\n",
       " 51  6.4  3.2  4.5  1.5\n",
       " 52  6.9  3.1  4.9  1.5\n",
       " 53  5.5  2.3  4.0  1.3\n",
       " 54  6.5  2.8  4.6  1.5\n",
       " 55  5.7  2.8  4.5  1.3\n",
       " 56  6.3  3.3  4.7  1.6\n",
       " 57  4.9  2.4  3.3  1.0\n",
       " 58  6.6  2.9  4.6  1.3\n",
       " 59  5.2  2.7  3.9  1.4\n",
       " 60  5.0  2.0  3.5  1.0\n",
       " 61  5.9  3.0  4.2  1.5\n",
       " 62  6.0  2.2  4.0  1.0\n",
       " 63  6.1  2.9  4.7  1.4\n",
       " 64  5.6  2.9  3.6  1.3\n",
       " 65  6.7  3.1  4.4  1.4\n",
       " 66  5.6  3.0  4.5  1.5\n",
       " 67  5.8  2.7  4.1  1.0\n",
       " 68  6.2  2.2  4.5  1.5\n",
       " 69  5.6  2.5  3.9  1.1\n",
       " 70  5.9  3.2  4.8  1.8\n",
       " 71  6.1  2.8  4.0  1.3\n",
       " 72  6.3  2.5  4.9  1.5\n",
       " 73  6.1  2.8  4.7  1.2\n",
       " 74  6.4  2.9  4.3  1.3\n",
       " 75  6.6  3.0  4.4  1.4\n",
       " 76  6.8  2.8  4.8  1.4\n",
       " 77  6.7  3.0  5.0  1.7\n",
       " 78  6.0  2.9  4.5  1.5\n",
       " 79  5.7  2.6  3.5  1.0\n",
       " 80  5.5  2.4  3.8  1.1\n",
       " 81  5.5  2.4  3.7  1.0\n",
       " 82  5.8  2.7  3.9  1.2\n",
       " 83  6.0  2.7  5.1  1.6\n",
       " 84  5.4  3.0  4.5  1.5\n",
       " 85  6.0  3.4  4.5  1.6\n",
       " 86  6.7  3.1  4.7  1.5\n",
       " 87  6.3  2.3  4.4  1.3\n",
       " 88  5.6  3.0  4.1  1.3\n",
       " 89  5.5  2.5  4.0  1.3\n",
       " 90  5.5  2.6  4.4  1.2\n",
       " 91  6.1  3.0  4.6  1.4\n",
       " 92  5.8  2.6  4.0  1.2\n",
       " 93  5.0  2.3  3.3  1.0\n",
       " 94  5.6  2.7  4.2  1.3\n",
       " 95  5.7  3.0  4.2  1.2\n",
       " 96  5.7  2.9  4.2  1.3\n",
       " 97  6.2  2.9  4.3  1.3\n",
       " 98  5.1  2.5  3.0  1.1\n",
       " 99  5.7  2.8  4.1  1.3, 'X_2':        0    1    2    3\n",
       " 100  6.3  3.3  6.0  2.5\n",
       " 101  5.8  2.7  5.1  1.9\n",
       " 102  7.1  3.0  5.9  2.1\n",
       " 103  6.3  2.9  5.6  1.8\n",
       " 104  6.5  3.0  5.8  2.2\n",
       " 105  7.6  3.0  6.6  2.1\n",
       " 106  4.9  2.5  4.5  1.7\n",
       " 107  7.3  2.9  6.3  1.8\n",
       " 108  6.7  2.5  5.8  1.8\n",
       " 109  7.2  3.6  6.1  2.5\n",
       " 110  6.5  3.2  5.1  2.0\n",
       " 111  6.4  2.7  5.3  1.9\n",
       " 112  6.8  3.0  5.5  2.1\n",
       " 113  5.7  2.5  5.0  2.0\n",
       " 114  5.8  2.8  5.1  2.4\n",
       " 115  6.4  3.2  5.3  2.3\n",
       " 116  6.5  3.0  5.5  1.8\n",
       " 117  7.7  3.8  6.7  2.2\n",
       " 118  7.7  2.6  6.9  2.3\n",
       " 119  6.0  2.2  5.0  1.5\n",
       " 120  6.9  3.2  5.7  2.3\n",
       " 121  5.6  2.8  4.9  2.0\n",
       " 122  7.7  2.8  6.7  2.0\n",
       " 123  6.3  2.7  4.9  1.8\n",
       " 124  6.7  3.3  5.7  2.1\n",
       " 125  7.2  3.2  6.0  1.8\n",
       " 126  6.2  2.8  4.8  1.8\n",
       " 127  6.1  3.0  4.9  1.8\n",
       " 128  6.4  2.8  5.6  2.1\n",
       " 129  7.2  3.0  5.8  1.6\n",
       " 130  7.4  2.8  6.1  1.9\n",
       " 131  7.9  3.8  6.4  2.0\n",
       " 132  6.4  2.8  5.6  2.2\n",
       " 133  6.3  2.8  5.1  1.5\n",
       " 134  6.1  2.6  5.6  1.4\n",
       " 135  7.7  3.0  6.1  2.3\n",
       " 136  6.3  3.4  5.6  2.4\n",
       " 137  6.4  3.1  5.5  1.8\n",
       " 138  6.0  3.0  4.8  1.8\n",
       " 139  6.9  3.1  5.4  2.1\n",
       " 140  6.7  3.1  5.6  2.4\n",
       " 141  6.9  3.1  5.1  2.3\n",
       " 142  5.8  2.7  5.1  1.9\n",
       " 143  6.8  3.2  5.9  2.3\n",
       " 144  6.7  3.3  5.7  2.5\n",
       " 145  6.7  3.0  5.2  2.3\n",
       " 146  6.3  2.5  5.0  1.9\n",
       " 147  6.5  3.0  5.2  2.0\n",
       " 148  6.2  3.4  5.4  2.3\n",
       " 149  5.9  3.0  5.1  1.8}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrapped_demultiplexer = wrap_adaptee_in_process(demultiplexer)\n",
    "wrapped_demultiplexer.predict(X=X, selection=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those users implementing their own custom blocks may find useful the option of providing their own custom class to th ```wrap_adaptee_in_process```, as in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X_0':       0    1    2    3\n",
       " 0   5.1  3.5  1.4  0.2\n",
       " 1   4.9  3.0  1.4  0.2\n",
       " 2   4.7  3.2  1.3  0.2\n",
       " 3   4.6  3.1  1.5  0.2\n",
       " 4   5.0  3.6  1.4  0.2\n",
       " 5   5.4  3.9  1.7  0.4\n",
       " 6   4.6  3.4  1.4  0.3\n",
       " 7   5.0  3.4  1.5  0.2\n",
       " 8   4.4  2.9  1.4  0.2\n",
       " 9   4.9  3.1  1.5  0.1\n",
       " 10  5.4  3.7  1.5  0.2\n",
       " 11  4.8  3.4  1.6  0.2\n",
       " 12  4.8  3.0  1.4  0.1\n",
       " 13  4.3  3.0  1.1  0.1\n",
       " 14  5.8  4.0  1.2  0.2\n",
       " 15  5.7  4.4  1.5  0.4\n",
       " 16  5.4  3.9  1.3  0.4\n",
       " 17  5.1  3.5  1.4  0.3\n",
       " 18  5.7  3.8  1.7  0.3\n",
       " 19  5.1  3.8  1.5  0.3\n",
       " 20  5.4  3.4  1.7  0.2\n",
       " 21  5.1  3.7  1.5  0.4\n",
       " 22  4.6  3.6  1.0  0.2\n",
       " 23  5.1  3.3  1.7  0.5\n",
       " 24  4.8  3.4  1.9  0.2\n",
       " 25  5.0  3.0  1.6  0.2\n",
       " 26  5.0  3.4  1.6  0.4\n",
       " 27  5.2  3.5  1.5  0.2\n",
       " 28  5.2  3.4  1.4  0.2\n",
       " 29  4.7  3.2  1.6  0.2\n",
       " 30  4.8  3.1  1.6  0.2\n",
       " 31  5.4  3.4  1.5  0.4\n",
       " 32  5.2  4.1  1.5  0.1\n",
       " 33  5.5  4.2  1.4  0.2\n",
       " 34  4.9  3.1  1.5  0.1\n",
       " 35  5.0  3.2  1.2  0.2\n",
       " 36  5.5  3.5  1.3  0.2\n",
       " 37  4.9  3.1  1.5  0.1\n",
       " 38  4.4  3.0  1.3  0.2\n",
       " 39  5.1  3.4  1.5  0.2\n",
       " 40  5.0  3.5  1.3  0.3\n",
       " 41  4.5  2.3  1.3  0.3\n",
       " 42  4.4  3.2  1.3  0.2\n",
       " 43  5.0  3.5  1.6  0.6\n",
       " 44  5.1  3.8  1.9  0.4\n",
       " 45  4.8  3.0  1.4  0.3\n",
       " 46  5.1  3.8  1.6  0.2\n",
       " 47  4.6  3.2  1.4  0.2\n",
       " 48  5.3  3.7  1.5  0.2\n",
       " 49  5.0  3.3  1.4  0.2, 'X_1':       0    1    2    3\n",
       " 50  7.0  3.2  4.7  1.4\n",
       " 51  6.4  3.2  4.5  1.5\n",
       " 52  6.9  3.1  4.9  1.5\n",
       " 53  5.5  2.3  4.0  1.3\n",
       " 54  6.5  2.8  4.6  1.5\n",
       " 55  5.7  2.8  4.5  1.3\n",
       " 56  6.3  3.3  4.7  1.6\n",
       " 57  4.9  2.4  3.3  1.0\n",
       " 58  6.6  2.9  4.6  1.3\n",
       " 59  5.2  2.7  3.9  1.4\n",
       " 60  5.0  2.0  3.5  1.0\n",
       " 61  5.9  3.0  4.2  1.5\n",
       " 62  6.0  2.2  4.0  1.0\n",
       " 63  6.1  2.9  4.7  1.4\n",
       " 64  5.6  2.9  3.6  1.3\n",
       " 65  6.7  3.1  4.4  1.4\n",
       " 66  5.6  3.0  4.5  1.5\n",
       " 67  5.8  2.7  4.1  1.0\n",
       " 68  6.2  2.2  4.5  1.5\n",
       " 69  5.6  2.5  3.9  1.1\n",
       " 70  5.9  3.2  4.8  1.8\n",
       " 71  6.1  2.8  4.0  1.3\n",
       " 72  6.3  2.5  4.9  1.5\n",
       " 73  6.1  2.8  4.7  1.2\n",
       " 74  6.4  2.9  4.3  1.3\n",
       " 75  6.6  3.0  4.4  1.4\n",
       " 76  6.8  2.8  4.8  1.4\n",
       " 77  6.7  3.0  5.0  1.7\n",
       " 78  6.0  2.9  4.5  1.5\n",
       " 79  5.7  2.6  3.5  1.0\n",
       " 80  5.5  2.4  3.8  1.1\n",
       " 81  5.5  2.4  3.7  1.0\n",
       " 82  5.8  2.7  3.9  1.2\n",
       " 83  6.0  2.7  5.1  1.6\n",
       " 84  5.4  3.0  4.5  1.5\n",
       " 85  6.0  3.4  4.5  1.6\n",
       " 86  6.7  3.1  4.7  1.5\n",
       " 87  6.3  2.3  4.4  1.3\n",
       " 88  5.6  3.0  4.1  1.3\n",
       " 89  5.5  2.5  4.0  1.3\n",
       " 90  5.5  2.6  4.4  1.2\n",
       " 91  6.1  3.0  4.6  1.4\n",
       " 92  5.8  2.6  4.0  1.2\n",
       " 93  5.0  2.3  3.3  1.0\n",
       " 94  5.6  2.7  4.2  1.3\n",
       " 95  5.7  3.0  4.2  1.2\n",
       " 96  5.7  2.9  4.2  1.3\n",
       " 97  6.2  2.9  4.3  1.3\n",
       " 98  5.1  2.5  3.0  1.1\n",
       " 99  5.7  2.8  4.1  1.3, 'X_2':        0    1    2    3\n",
       " 100  6.3  3.3  6.0  2.5\n",
       " 101  5.8  2.7  5.1  1.9\n",
       " 102  7.1  3.0  5.9  2.1\n",
       " 103  6.3  2.9  5.6  1.8\n",
       " 104  6.5  3.0  5.8  2.2\n",
       " 105  7.6  3.0  6.6  2.1\n",
       " 106  4.9  2.5  4.5  1.7\n",
       " 107  7.3  2.9  6.3  1.8\n",
       " 108  6.7  2.5  5.8  1.8\n",
       " 109  7.2  3.6  6.1  2.5\n",
       " 110  6.5  3.2  5.1  2.0\n",
       " 111  6.4  2.7  5.3  1.9\n",
       " 112  6.8  3.0  5.5  2.1\n",
       " 113  5.7  2.5  5.0  2.0\n",
       " 114  5.8  2.8  5.1  2.4\n",
       " 115  6.4  3.2  5.3  2.3\n",
       " 116  6.5  3.0  5.5  1.8\n",
       " 117  7.7  3.8  6.7  2.2\n",
       " 118  7.7  2.6  6.9  2.3\n",
       " 119  6.0  2.2  5.0  1.5\n",
       " 120  6.9  3.2  5.7  2.3\n",
       " 121  5.6  2.8  4.9  2.0\n",
       " 122  7.7  2.8  6.7  2.0\n",
       " 123  6.3  2.7  4.9  1.8\n",
       " 124  6.7  3.3  5.7  2.1\n",
       " 125  7.2  3.2  6.0  1.8\n",
       " 126  6.2  2.8  4.8  1.8\n",
       " 127  6.1  3.0  4.9  1.8\n",
       " 128  6.4  2.8  5.6  2.1\n",
       " 129  7.2  3.0  5.8  1.6\n",
       " 130  7.4  2.8  6.1  1.9\n",
       " 131  7.9  3.8  6.4  2.0\n",
       " 132  6.4  2.8  5.6  2.2\n",
       " 133  6.3  2.8  5.1  1.5\n",
       " 134  6.1  2.6  5.6  1.4\n",
       " 135  7.7  3.0  6.1  2.3\n",
       " 136  6.3  3.4  5.6  2.4\n",
       " 137  6.4  3.1  5.5  1.8\n",
       " 138  6.0  3.0  4.8  1.8\n",
       " 139  6.9  3.1  5.4  2.1\n",
       " 140  6.7  3.1  5.6  2.4\n",
       " 141  6.9  3.1  5.1  2.3\n",
       " 142  5.8  2.7  5.1  1.9\n",
       " 143  6.8  3.2  5.9  2.3\n",
       " 144  6.7  3.3  5.7  2.5\n",
       " 145  6.7  3.0  5.2  2.3\n",
       " 146  6.3  2.5  5.0  1.9\n",
       " 147  6.5  3.0  5.2  2.0\n",
       " 148  6.2  3.4  5.4  2.3\n",
       " 149  5.9  3.0  5.1  1.8}"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrapped_demultiplexer = wrap_adaptee_in_process(adaptee=demultiplexer,\n",
    "                                                strategy_class=AdapterForCustomFitPredictWithDictionaryOutputAdaptee)\n",
    "wrapped_demultiplexer.predict(X=X, selection=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing an already wrapped object to PipeGraph's constructor ```steps``` parameter by using the ```wrap_adaptee_in_process``` as describe above may be useful for those custom blocks built by users, thus avoiding the need to modify the ```pipegraph.base.strategies_for_custom_adaptees``` dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using PipeGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third Example: Injecting varying ``sample_weight`` vectors to a linear regression model for GridSearchCV\n",
    "\n",
    "This example illustrates a case in which a varying vector is injected to a linear regression model as ``sample_weight`` in order to evaluate them and obtain the sample_weight that generates the best results.\n",
    "Let's imagine we have a sample_weight vector and different powers of the vector are needed to be evaluated. To perform such experiment, the following issues appear:\n",
    "\n",
    "- The shape of the graph is not a linear sequence as those that can be implemented using Pipeline.\n",
    "- More than two variables (typically: ``X`` and ``y``) need to be accordingly split in order to perform the cross validation with GridSearchCV, in this case: ``X``, ``y`` and ``sample_weight``.\n",
    "- The information provided to the  ``sample_weight`` parameter of the LinearRegression step varies on the different scenarios explored by GridSearchCV. In a GridSearchCV with Pipeline, ``sample_weight`` can't vary because it is treated as a ``fit_param`` instead of a variable.\n",
    "\n",
    "Steps of the **PipeGraph**:\n",
    "\n",
    "- **selector**: Featuring a :class:`ColumnSelector` custom step. This is not a sklearn original object but a custom class that allows to split an array into columns. In this case, ``X`` augmented data is column-wise divided as specified in a mapping dictionary. We previously created an augmented ``X`` in which all data but ``y`` is concatenated and it will be used by :class:`GridSearchCV` to make the cross validation splits. **selector** step de-concatenates such data.\n",
    "- **custom_power**: Featuring a :class:`CustomPower` custom class. A simple transformation of the input data that is powered to a specified power as indicated in ``param_grid``.\n",
    "- **scaler**: implements :class:`MinMaxScaler` class\n",
    "- **polynomial_features**: Contains a :class:`PolynomialFeatures` object\n",
    "- **linear_model**: Contains a :class:`LinearRegression` model\n",
    "\n",
    "![](https://raw.githubusercontent.com/mcasl/PipeGraph/master/examples/images/Diapositiva3.png)\n",
    "\n",
    "    Figure 1. PipeGraph diagram showing the steps and their connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pipegraph.base import PipeGraphRegressor, ColumnSelector, Reshape\n",
    "from pipegraph.demo_blocks import CustomPower\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create an augmented ``X`` in which all data but ``y`` is concatenated. In this case, we concatenate ``X`` and ``sample_weight`` vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(dict(X=np.array([   1,    2,    3,    4,    5,    6,    7,    8,    9,   10,   11]),\n",
    "          sample_weight=np.array([0.01, 0.95, 0.10, 0.95, 0.95, 0.10, 0.10, 0.95, 0.95, 0.95, 0.01])))\n",
    "y = np.array(                    [  10,    4,   20,   16,   25 , -60,   85,   64,   81,  100,  150])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define the steps and we use :class:`PipeGraphRegressor` as estimator for :class:`GridSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "polynomial_features = PolynomialFeatures()\n",
    "linear_model = LinearRegression()\n",
    "custom_power = CustomPower()\n",
    "selector = ColumnSelector(mapping={'X': slice(0, 1),\n",
    "                                   'sample_weight': slice(1,2)})\n",
    "\n",
    "steps = [('selector', selector),\n",
    "         ('custom_power', custom_power),\n",
    "         ('scaler', scaler),\n",
    "         ('polynomial_features', polynomial_features),\n",
    "         ('linear_model', linear_model)]\n",
    "\n",
    "pgraph = PipeGraphRegressor(steps=steps)\n",
    "\n",
    "(pgraph.inject(sink='selector', sink_var='X', source='_External', source_var='X')\n",
    "       .inject('custom_power', 'X', 'selector', 'sample_weight')\n",
    "       .inject('scaler', 'X', 'selector', 'X')\n",
    "       .inject('polynomial_features', 'X', 'scaler')\n",
    "       .inject('linear_model', 'X',  'polynomial_features')\n",
    "       .inject('linear_model', 'y', source_var='y')\n",
    "       .inject('linear_model', 'sample_weight', 'custom_power'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we define ``param_grid`` as expected by :class:`GridSearchCV` exploring a few possibilities of varying parameters.\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'polynomial_features__degree': range(1, 3),\n",
    "              'linear_model__fit_intercept': [True, False],\n",
    "              'custom_power__power': [1, 5, 10, 20, 30]}\n",
    "\n",
    "\n",
    "\n",
    "grid_search_regressor = GridSearchCV(estimator=pgraph, param_grid=param_grid, refit=True)\n",
    "grid_search_regressor.fit(X, y)\n",
    "y_pred = grid_search_regressor.predict(X)\n",
    "\n",
    "plt.scatter(X.loc[:,'X'], y)\n",
    "plt.scatter(X.loc[:,'X'], y_pred)\n",
    "plt.show()\n",
    "\n",
    "power = grid_search_regressor.best_estimator_.get_params()['custom_power']\n",
    "print('Power that obtains the best results in the linear model: \\n {}'.format(power))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example displayed a non linear workflow successfully implemented by **PipeGraph**, while at the same time showing a way to circumvent current limitations of standard :class:`GridSearchCV`, in particular, the retriction on the number of input parameters.\n",
    ":ref:`Next examples <example4>` show more elaborated examples in increasing complexity order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourth Example: Combination of classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A set of classifiers is combined as input to a neural network. Additionally, the scaled inputs are injected as well to\n",
    "the neural network. The data is firstly transformed by scaling its features.\n",
    "\n",
    "Steps of the **PipeGraph**:\n",
    "\n",
    "- **scaler**: A :class:`MinMaxScaler` data preprocessor\n",
    "- **gaussian_nb**: A :class:`GaussianNB` classifier\n",
    "- **svc**: A :class:`SVC` classifier\n",
    "- **concat**: A :class:`Concatenator` custom class that appends the outputs of the :class:`GaussianNB`, :class:`SVC` classifiers, and the scaled inputs.\n",
    "- **mlp**: A :class:`MLPClassifier` object\n",
    "\n",
    "![](https://raw.githubusercontent.com/mcasl/PipeGraph/master/examples/images/Diapositiva4.png)\n",
    "\n",
    "    Figure 1. PipeGraph diagram showing the steps and their connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pipegraph.base import PipeGraphClassifier, Concatenator\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "gaussian_nb = GaussianNB()\n",
    "svc = SVC()\n",
    "mlp = MLPClassifier()\n",
    "concatenator = Concatenator()\n",
    "\n",
    "steps = [('scaler', scaler),\n",
    "         ('gaussian_nb', gaussian_nb),\n",
    "         ('svc', svc),\n",
    "         ('concat', concatenator),\n",
    "         ('mlp', mlp)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we use a :class:`PipeGraphClassifier` because the result is a classification and we want to take advantage of Scikit-Learn default scoring method for classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgraph = PipeGraphClassifier(steps=steps)\n",
    "(pgraph.inject(sink='scaler', sink_var='X', source='_External', source_var='X')\n",
    "       .inject('gaussian_nb', 'X', 'scaler')\n",
    "       .inject('gaussian_nb', 'y', source_var='y')\n",
    "       .inject('svc', 'X', 'scaler')\n",
    "       .inject('svc', 'y', source_var='y')\n",
    "       .inject('concat', 'X1', 'scaler')\n",
    "       .inject('concat', 'X2', 'gaussian_nb')\n",
    "       .inject('concat', 'X3', 'svc')\n",
    "       .inject('mlp', 'X', 'concat')\n",
    "       .inject('mlp', 'y', source_var='y')\n",
    ")\n",
    "\n",
    "param_grid = {'svc__C': [0.1, 0.5, 1.0],\n",
    "              'mlp__hidden_layer_sizes': [(3,), (6,), (9,),],\n",
    "              'mlp__max_iter': [5000, 10000]}\n",
    "\n",
    "grid_search_classifier  = GridSearchCV(estimator=pgraph, param_grid=param_grid, refit=True)\n",
    "grid_search_classifier.fit(X, y)\n",
    "y_pred = grid_search_classifier.predict(X)\n",
    "\n",
    "grid_search_classifier.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for plotting the confusion matrix taken from 'Python Data Science Handbook' by Jake VanderPlas\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns; sns.set()  # for plot styling\n",
    "\n",
    "mat = confusion_matrix(y_pred, y)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example displayed complex data injections that are successfully managed by **PipeGraph**.\n",
    "Next example :ref:`on <example5>`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fifth Example: Demultiplexor - multiplexor\n",
    "\n",
    "An imaginative layout using a classifier to predict the cluster labels and fitting a separate model for each cluster.\n",
    "\n",
    "Steps of the **PipeGraph**:\n",
    "\n",
    "- **scaler**: A :class:`MinMaxScaler` data preprocessor\n",
    "- **classifier**: A :class:`GaussianMixture` classifier\n",
    "- **demux**: A custom :class:`Demultiplexer` class in charge of splitting the input arrays accordingly to the selection input vector\n",
    "- **lm_0**: A :class:`LinearRegression` model\n",
    "- **lm_1**: A :class:`LinearRegression` model\n",
    "- **lm_2**: A :class:`LinearRegression` model\n",
    "- **mux**: A custom :class:`Multiplexer` class in charge of combining different input arrays into a single one accordingly to the selection input vector\n",
    "\n",
    "![](https://raw.githubusercontent.com/mcasl/PipeGraph/master/examples/images/Diapositiva5.png)\n",
    "\n",
    "    Figure 1. PipeGraph diagram showing the steps and their connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pipegraph.base import PipeGraphRegressor, Demultiplexer, Multiplexer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "X_first = pd.Series(np.random.rand(100,))\n",
    "y_first = pd.Series(4 * X_first + 0.5*np.random.randn(100,))\n",
    "X_second = pd.Series(np.random.rand(100,) + 3)\n",
    "y_second = pd.Series(-4 * X_second + 0.5*np.random.randn(100,))\n",
    "X_third = pd.Series(np.random.rand(100,) + 6)\n",
    "y_third = pd.Series(2 * X_third + 0.5*np.random.randn(100,))\n",
    "\n",
    "X = pd.concat([X_first, X_second, X_third], axis=0).to_frame()\n",
    "y = pd.concat([y_first, y_second, y_third], axis=0).to_frame()\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "gaussian_mixture = GaussianMixture(n_components=3)\n",
    "demux = Demultiplexer()\n",
    "lm_0 = LinearRegression()\n",
    "lm_1 = LinearRegression()\n",
    "lm_2 = LinearRegression()\n",
    "mux = Multiplexer()\n",
    "\n",
    "\n",
    "steps = [('scaler', scaler),\n",
    "         ('classifier', gaussian_mixture),\n",
    "         ('demux', demux),\n",
    "         ('lm_0', lm_0),\n",
    "         ('lm_1', lm_1),\n",
    "         ('lm_2', lm_2),\n",
    "         ('mux', mux), ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using ``inject`` as in previous example, in this one we are going to pass a dictionary describing the connections to PipeGraph constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Demultiplexer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-5433463d2867>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpipegraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPipeGraphRegressor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDemultiplexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMultiplexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmixture\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGaussianMixture\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Demultiplexer'"
     ]
    }
   ],
   "source": [
    "connections = { 'scaler': {'X': 'X'},\n",
    "                'classifier': {'X': 'scaler'},\n",
    "                'demux': {'X': 'scaler',\n",
    "                          'y': 'y',\n",
    "                          'selection': 'classifier'},\n",
    "                'lm_0': {'X': ('demux', 'X_0'),\n",
    "                         'y': ('demux', 'y_0')},\n",
    "                'lm_1': {'X': ('demux', 'X_1'),\n",
    "                         'y': ('demux', 'y_1')},\n",
    "                'lm_2': {'X': ('demux', 'X_2'),\n",
    "                         'y': ('demux', 'y_2')},\n",
    "                'mux': {'0': 'lm_0',\n",
    "                        '1': 'lm_1',\n",
    "                        '2': 'lm_2',\n",
    "                        'selection': 'classifier'}}\n",
    "\n",
    "pgraph = PipeGraphRegressor(steps=steps, fit_connections=connections)\n",
    "pgraph.fit(X, y)\n",
    "#%%\n",
    "y_pred = pgraph.predict(X)\n",
    "plt.scatter(X, y)\n",
    "plt.scatter(X, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sixth Example: Encapsulating several blocks into a PipeGraph and reusing it\n",
    "\n",
    "A demonstration of several interesting features will be done in the following examples:\n",
    " 1. How the user can choose to encapsulate several blocks into a PipeGraph and use it as a single unit in another PipeGraph\n",
    " 2. How these components can be dynamically built on runtime depending on initialization parameters\n",
    " 3. How these components can be dynamically built on runtime depending on input signal values during fit\n",
    " 4. Using GridSearchCV to explore the best combination of hyperparameters\n",
    "\n",
    "We consider Example number five in which we had the following steps:\n",
    "\n",
    "- **scaler**: A :class:`MinMaxScaler` data preprocessor\n",
    "- **classifier**: A :class:`GaussianMixture` classifier\n",
    "- **demux** in charge of splitting the input arrays accordingly to the selection input vector\n",
    "- **lm_0**: A :class:`LinearRegression` model\n",
    "- **lm_1**: A :class:`LinearRegression` model\n",
    "- **lm_2**: A :class:`LinearRegression` model\n",
    "- **mux**: A custom :class:`Multiplexer` class in charge of combining different input arrays into a single one accordingly to the selection input vector\n",
    "\n",
    "For instance, we can find interesting to encapsulate the Demultiplexer, the linear model collection, and the Multiplexer into a single unit:\n",
    "We prepare the data and build a PipeGraph with these steps alone:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from pipegraph.base import PipeGraph, PipeGraphRegressor, Demultiplexer, Multiplexer\n",
    "\n",
    "X_first = pd.Series(np.random.rand(100,))\n",
    "y_first = pd.Series(4 * X_first + 0.5*np.random.randn(100,))\n",
    "X_second = pd.Series(np.random.rand(100,) + 3)\n",
    "y_second = pd.Series(-4 * X_second + 0.5*np.random.randn(100,))\n",
    "X_third = pd.Series(np.random.rand(100,) + 6)\n",
    "y_third = pd.Series(2 * X_third + 0.5*np.random.randn(100,))\n",
    "\n",
    "X = pd.concat([X_first, X_second, X_third], axis=0).to_frame()\n",
    "y = pd.concat([y_first, y_second, y_third], axis=0).to_frame()\n",
    "\n",
    "\n",
    "demux = Demultiplexer()\n",
    "lm_0 = LinearRegression()\n",
    "lm_1 = LinearRegression()\n",
    "lm_2 = LinearRegression()\n",
    "mux = Multiplexer()\n",
    "\n",
    "three_multiplexed_models_steps = [\n",
    "         ('demux', demux),\n",
    "         ('lm_0', lm_0),\n",
    "         ('lm_1', lm_1),\n",
    "         ('lm_2', lm_2),\n",
    "         ('mux', mux), ]\n",
    "\n",
    "three_multiplexed_models_connections = {\n",
    "                'demux': {'X': 'X',\n",
    "                          'y': 'y',\n",
    "                          'selection': 'selection'},\n",
    "                'lm_0': {'X': ('demux', 'X_0'),\n",
    "                         'y': ('demux', 'y_0')},\n",
    "                'lm_1': {'X': ('demux', 'X_1'),\n",
    "                         'y': ('demux', 'y_1')},\n",
    "                'lm_2': {'X': ('demux', 'X_2'),\n",
    "                         'y': ('demux', 'y_2')},\n",
    "                'mux': {'0': 'lm_0',\n",
    "                        '1': 'lm_1',\n",
    "                        '2': 'lm_2',\n",
    "                        'selection': 'selection'}}\n",
    "\n",
    "three_multiplexed_models = PipeGraph(steps=three_multiplexed_models_steps,\n",
    "                                     fit_connections=three_multiplexed_models_connections )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can treat this PipeGraph as a reusable component and use it as a unitary step in another PipeGraph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Demultiplexer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-2bef3a1c5bf0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmixture\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGaussianMixture\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpipegraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPipeGraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPipeGraphRegressor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDemultiplexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMultiplexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[0mX_first\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Demultiplexer'"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "gaussian_mixture = GaussianMixture(n_components=3)\n",
    "models = three_multiplexed_models\n",
    "\n",
    "steps = [('scaler', scaler),\n",
    "         ('classifier', gaussian_mixture),\n",
    "         ('models', three_multiplexed_models), ]\n",
    "\n",
    "connections = {'scaler': {'X': 'X'},\n",
    "               'classifier': {'X': 'scaler'},\n",
    "               'models': {'X': 'scaler',\n",
    "                          'y': 'y',\n",
    "                          'selection': 'classifier'},\n",
    "               }\n",
    "\n",
    "pgraph = PipeGraphRegressor(steps=steps, fit_connections=connections)\n",
    "pgraph.fit(X, y)\n",
    "y_pred = pgraph.predict(X)\n",
    "plt.scatter(X, y)\n",
    "plt.scatter(X, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seventh Example: Dynamically built component using initialization parameters\n",
    "\n",
    "We continue demonstrating several interesting features:\n",
    " 1. How the user can choose to encapsulate several blocks into a PipeGraph and use it as a single unit in another PipeGraph\n",
    " 2. How these components can be dynamically built on runtime depending on initialization parameters\n",
    " 3. How these components can be dynamically built on runtime depending on input signal values during fit\n",
    " 4. Using GridSearchCV to explore the best combination of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "from pipegraph.base import PipeGraph, PipeGraphRegressor, Demultiplexer, Multiplexer, \\\n",
    "    RegressorsWithParametrizedNumberOfReplicas\n",
    "\n",
    "X_first = pd.Series(np.random.rand(100,))\n",
    "y_first = pd.Series(4 * X_first + 0.5*np.random.randn(100,))\n",
    "X_second = pd.Series(np.random.rand(100,) + 3)\n",
    "y_second = pd.Series(-4 * X_second + 0.5*np.random.randn(100,))\n",
    "X_third = pd.Series(np.random.rand(100,) + 6)\n",
    "y_third = pd.Series(2 * X_third + 0.5*np.random.randn(100,))\n",
    "\n",
    "X = pd.concat([X_first, X_second, X_third], axis=0).to_frame()\n",
    "y = pd.concat([y_first, y_second, y_third], axis=0).to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can think of programatically changing the number of models inside this component.\n",
    "First we do it by using initialization parameters in a :class:``PipeGraph`` subclass we called :class:``pipegraph.standard_blocks.RegressorsWithParametrizedNumberOfReplicas``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "print(inspect.getsource(RegressorsWithParametrizedNumberOfReplicas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this new component we can build a simplified PipeGraph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Demultiplexer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-4e3e42956e58>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmixture\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGaussianMixture\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpipegraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPipeGraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPipeGraphRegressor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDemultiplexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMultiplexer\u001b[0m\u001b[1;33m,\u001b[0m     \u001b[0mRegressorsWithParametrizedNumberOfReplicas\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mX_first\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Demultiplexer'"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "gaussian_mixture = GaussianMixture(n_components=3)\n",
    "models = RegressorsWithParametrizedNumberOfReplicas(number_of_replicas=3,\n",
    "                                                    model_prototype=LinearRegression(),\n",
    "                                                    model_parameters={})\n",
    "\n",
    "steps = [('scaler', scaler),\n",
    "         ('classifier', gaussian_mixture),\n",
    "         ('models', models), ]\n",
    "\n",
    "connections = {'scaler': {'X': 'X'},\n",
    "               'classifier': {'X': 'scaler'},\n",
    "               'models': {'X': 'scaler',\n",
    "                          'y': 'y',\n",
    "                          'selection': 'classifier'},\n",
    "               }\n",
    "\n",
    "pgraph = PipeGraphRegressor(steps=steps, fit_connections=connections)\n",
    "pgraph.fit(X, y)\n",
    "y_pred = pgraph.predict(X)\n",
    "plt.scatter(X, y)\n",
    "plt.scatter(X, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eighth Example: # Dynamically built component using input signal values during the fit stage\n",
    "\n",
    "We continue demonstrating several interesting features:\n",
    " 1. How the user can choose to encapsulate several blocks into a PipeGraph and use it as a single unit in another PipeGraph\n",
    " 2. How these components can be dynamically built on runtime depending on initialization parameters\n",
    " 3. How these components can be dynamically built on runtime depending on input signal values during fit\n",
    " 4. Using GridSearchCV to explore the best combination of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from pipegraph.base import PipeGraphRegressor, RegressorsWithDataDependentNumberOfReplicas\n",
    "\n",
    "X_first = pd.Series(np.random.rand(100,))\n",
    "y_first = pd.Series(4 * X_first + 0.5*np.random.randn(100,))\n",
    "X_second = pd.Series(np.random.rand(100,) + 3)\n",
    "y_second = pd.Series(-4 * X_second + 0.5*np.random.randn(100,))\n",
    "X_third = pd.Series(np.random.rand(100,) + 6)\n",
    "y_third = pd.Series(2 * X_third + 0.5*np.random.randn(100,))\n",
    "\n",
    "X = pd.concat([X_first, X_second, X_third], axis=0).to_frame()\n",
    "y = pd.concat([y_first, y_second, y_third], axis=0).to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we consider the possibility of using the classifier's output to automatically adjust the number of replicas.\n",
    "This can be seen as PipeGraph changing its inner topology to adapt its connections and steps to other components\n",
    "context. This morphing capability opens interesting possibilities to explore indeed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "print(inspect.getsource(RegressorsWithDataDependentNumberOfReplicas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this new component we can build a simplified PipeGraph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RegressorsWithDataDependentNumberOfReplicas' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-13d08e29661a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mgaussian_mixture\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGaussianMixture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRegressorsWithDataDependentNumberOfReplicas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_prototype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m steps = [('scaler', scaler),\n",
      "\u001b[1;31mNameError\u001b[0m: name 'RegressorsWithDataDependentNumberOfReplicas' is not defined"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "gaussian_mixture = GaussianMixture(n_components=3)\n",
    "models = RegressorsWithDataDependentNumberOfReplicas(model_prototype=LinearRegression(), model_parameters={})\n",
    "\n",
    "steps = [('scaler', scaler),\n",
    "         ('classifier', gaussian_mixture),\n",
    "         ('models', models), ]\n",
    "\n",
    "connections = {'scaler': {'X': 'X'},\n",
    "               'classifier': {'X': 'scaler'},\n",
    "               'models': {'X': 'scaler',\n",
    "                          'y': 'y',\n",
    "                          'selection': 'classifier'},\n",
    "               }\n",
    "\n",
    "pgraph = PipeGraphRegressor(steps=steps, fit_connections=connections)\n",
    "pgraph.fit(X, y)\n",
    "y_pred = pgraph.predict(X)\n",
    "plt.scatter(X, y)\n",
    "plt.scatter(X, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ninth Example: # GridSearch on dynamically built component using input signal values\n",
    "\n",
    "We continue demonstrating several interesting features:\n",
    " 1. How the user can choose to encapsulate several blocks into a PipeGraph and use it as a single unit in another PipeGraph\n",
    " 2. How these components can be dynamically built on runtime depending on initialization parameters\n",
    " 3. How these components can be dynamically built on runtime depending on input signal values during fit\n",
    " 4. Using GridSearchCV to explore the best combination of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pipegraph.base import ( PipeGraphRegressor,\n",
    "                             RegressorsWithDataDependentNumberOfReplicas,\n",
    "                             NeutralRegressor,\n",
    "                             )\n",
    "\n",
    "X_first = pd.Series(np.random.rand(100,))\n",
    "y_first = pd.Series(4 * X_first + 0.5*np.random.randn(100,))\n",
    "X_second = pd.Series(np.random.rand(100,) + 3)\n",
    "y_second = pd.Series(-4 * X_second + 0.5*np.random.randn(100,))\n",
    "X_third = pd.Series(np.random.rand(100,) + 6)\n",
    "y_third = pd.Series(2 * X_third + 0.5*np.random.randn(100,))\n",
    "\n",
    "X = pd.concat([X_first, X_second, X_third], axis=0).to_frame()\n",
    "y = pd.concat([y_first, y_second, y_third], axis=0).to_frame()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we consider the possibility of using the classifier's output to automatically adjust the number of replicas.\n",
    "This can be seen as PipeGraph changing its inner topology to adapt its connections and steps to other components\n",
    "context. This morphing capability opens interesting possibilities to explore indeed.\n",
    "To ease the calculation of the score for the GridSearchCV we add a neutral regressor as a last step, capable of\n",
    "calculating the score using a default scoring function. This is much more convenient than worrying about programming\n",
    "a custom scoring function for a block with an arbitrary number of inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "gaussian_mixture = GaussianMixture(n_components=3)\n",
    "models = RegressorsWithDataDependentNumberOfReplicas(model_prototype=LinearRegression(), model_parameters={})\n",
    "neutral_regressor = NeutralRegressor()\n",
    "\n",
    "steps = [('scaler', scaler),\n",
    "         ('classifier', gaussian_mixture),\n",
    "         ('models', models),\n",
    "         ('neutral', neutral_regressor)]\n",
    "\n",
    "connections = {'scaler': {'X': 'X'},\n",
    "               'classifier': {'X': 'scaler'},\n",
    "               'models': {'X': 'scaler',\n",
    "                          'y': 'y',\n",
    "                          'selection': 'classifier'},\n",
    "               'neutral': {'X': 'models'}\n",
    "               }\n",
    "\n",
    "pgraph = PipeGraphRegressor(steps=steps, fit_connections=connections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using GridSearchCV to find the best number of clusters and the best regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-ef628885332e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'classifier__n_components'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrefit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'classifier__n_components': range(2,10)}\n",
    "gs = GridSearchCV(estimator=pgraph, param_grid=param_grid, refit=True)\n",
    "gs.fit(X_train, y_train)\n",
    "y_pred = gs.predict(X_train)\n",
    "plt.scatter(X_train, y_train)\n",
    "plt.scatter(X_train, y_pred)\n",
    "print(\"Score:\" , gs.score(X_test, y_test))\n",
    "print(\"classifier__n_components:\", gs.best_estimator_.get_params()['classifier__n_components'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tenth Example:  Alternative solution to example number 9\n",
    "\n",
    "We continue demonstrating several interesting features:\n",
    " 1. How the user can choose to encapsulate several blocks into a PipeGraph and use it as a single unit in another PipeGraph\n",
    " 2. How these components can be dynamically built on runtime depending on initialization parameters\n",
    " 3. How these components can be dynamically built on runtime depending on input signal values during fit\n",
    " 4. Using GridSearchCV to explore the best combination of hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pipegraph.base import ( PipeGraphRegressor,\n",
    "                             ClassifierAndRegressorsBundle,\n",
    "                             NeutralRegressor\n",
    "                            )\n",
    "\n",
    "X_first = pd.Series(np.random.rand(1000,))\n",
    "y_first = pd.Series(4 * X_first + 0.5*np.random.randn(1000,))\n",
    "X_second = pd.Series(np.random.rand(1000,) + 3)\n",
    "y_second = pd.Series(-4 * X_second + 0.5*np.random.randn(1000,))\n",
    "X_third = pd.Series(np.random.rand(1000,) + 6)\n",
    "y_third = pd.Series(2 * X_third + 0.5*np.random.randn(1000,))\n",
    "\n",
    "X = pd.concat([X_first, X_second, X_third], axis=0).to_frame()\n",
    "y = pd.concat([y_first, y_second, y_third], axis=0).to_frame()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we consider an alternative solution to example number 9. The previous solution showed the potential\n",
    "of being able to morph the graph during fitting. A simpler approach is considered in this example by reusing\n",
    "components and combining the classifier with the demultiplexed models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "print(inspect.getsource(ClassifierAndRegressorsBundle))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this new component we can build a simplified PipeGraph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "classifier_and_models = ClassifierAndRegressorsBundle(number_of_replicas=6)\n",
    "neutral_regressor = NeutralRegressor()\n",
    "\n",
    "steps = [('scaler', scaler),\n",
    "         ('bundle', classifier_and_models),\n",
    "         ('neutral', neutral_regressor)]\n",
    "\n",
    "connections = {'scaler': {'X': 'X'},\n",
    "               'bundle': {'X': 'scaler', 'y': 'y'},\n",
    "               'neutral': {'X': 'bundle'}}\n",
    "\n",
    "pgraph = PipeGraphRegressor(steps=steps, fit_connections=connections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using GridSearchCV to find the best number of clusters and the best regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-a1d94198e9d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'bundle__number_of_replicas'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrefit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'bundle__number_of_replicas': range(3,10)}\n",
    "gs = GridSearchCV(estimator=pgraph, param_grid=param_grid, refit=True)\n",
    "gs.fit(X_train, y_train)\n",
    "y_pred = gs.predict(X_train)\n",
    "plt.scatter(X_train, y_train)\n",
    "plt.scatter(X_train, y_pred)\n",
    "print(\"Score:\" , gs.score(X_test, y_test))\n",
    "print(\"bundle__number_of_replicas:\", gs.best_estimator_.get_params()['bundle__number_of_replicas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipegraph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-22809006348f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mimportlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipegraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pipegraph' is not defined"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(pipegraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pipegraph'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-5727cdd4e600>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpipegraph\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pipegraph'"
     ]
    }
   ],
   "source": [
    "import pipegraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
